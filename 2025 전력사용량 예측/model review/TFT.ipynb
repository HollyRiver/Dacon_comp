{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e06945",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "328b9b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning import Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495a9075",
   "metadata": {},
   "source": [
    "## Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320af9f5",
   "metadata": {},
   "source": [
    "1. Static Metadata, Time-varying Past Inputs, Time-varying Future Inputs을 Input Data로 활용\n",
    "2. 모든 Inputs은 변수 선택 단계(VSN)를 거쳐 정적 공변량과 Time-varying Inputs들이 함께 LSTM layer에 입력됨\n",
    "3. Time-varying Past Inputs은 Encoder에, Time-varying Future Inputs은 Decoder에 입력\n",
    "4. LSTM total layer outputs과 정적 공변량 데이터를 GRN layer에 합께 입력한 후, Masked Interpretable Multi-head attention layer에 입력\n",
    "5. 최종적으로 LSTM decoder 산출 값과 GRN을 거친 attention layer의 산출 값을 결합하여 quantile forecase를 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27b817",
   "metadata": {},
   "source": [
    "## 사용법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5161add1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install tensorboard\n",
    "#!pip install optuna statsmodels\n",
    "#!pip install optuna-integration[pytorch_lightning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e7cd63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "from pytorch_forecasting.data.examples import get_stallion_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be9561a",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76cb7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.data.examples import get_stallion_data\n",
    "\n",
    "data = get_stallion_data() ## pandas df\n",
    "\n",
    "## add time index\n",
    "data[\"time_idx\"] = data[\"date\"].dt.year*12 + data[\"date\"].dt.month\n",
    "data[\"time_idx\"] -= data[\"time_idx\"].min() ## monto 단위, 0 to fin, 시점 당 350개 데이터\n",
    "\n",
    "## add additional features\n",
    "data[\"month\"] = data.date.dt.month.astype(str).astype(\"category\")\n",
    "data[\"log_volume\"] = np.log(data.volume + 1e-8)\n",
    "data[\"avg_volume_by_sku\"] = data.groupby([\"time_idx\", \"sku\"], observed=True).volume.transform(\"mean\")\n",
    "data[\"avg_volume_by_agency\"] = data.groupby([\"time_idx\", \"sku\"], observed=True).volume.transform(\"mean\")\n",
    "\n",
    "## special days encoding\n",
    "special_days = [\n",
    "    \"easter_day\",\n",
    "    \"good_friday\",\n",
    "    \"new_year\",\n",
    "    \"christmas\",\n",
    "    \"labor_day\",\n",
    "    \"independence_day\",\n",
    "    \"revolution_day_memorial\",\n",
    "    \"regional_games\",\n",
    "    \"fifa_u_17_world_cup\",\n",
    "    \"football_gold_cup\",\n",
    "    \"beer_capital\",\n",
    "    \"music_fest\",\n",
    "]\n",
    "\n",
    "## 이게 뭐임? 데이터프레임에 들어간 게 아니네?\n",
    "data[special_days] = (\n",
    "    data[special_days].apply(lambda x: x.map({0: \"-\", 1: x.name})).astype(\"category\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63470505",
   "metadata": {},
   "source": [
    "### Create dataset and dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9508d139",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 6   ## validation length\n",
    "max_encoder_length = 24     ## encoding length\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length ## 훈련 데이터 종료 시점\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x : x.time_idx <= training_cutoff],\n",
    "    time_idx = \"time_idx\", ## integer. 0 >=\n",
    "    target = \"volume\",\n",
    "    group_ids = [\"agency\", \"sku\"], ## TimeSeries Group\n",
    "    min_encoder_length = max_encoder_length // 2, ## 인코더 길이 길게 유지\n",
    "    max_encoder_length = max_encoder_length,\n",
    "    min_prediction_length = 1,\n",
    "    max_prediction_length = max_prediction_length,\n",
    "    static_categoricals = [\"agency\", \"sku\"], ## 분리되는 요소만 시점에 불변\n",
    "    static_reals = [\"avg_population_2017\", \"avg_yearly_household_income_2017\"], ## 수치형 중에선 평균값만 불변\n",
    "    time_varying_known_categoricals = [\"special_days\", \"month\"], ## 시간에 따라 바뀌는 카테고리\n",
    "    variable_groups = {\n",
    "        \"special_days\" : special_days\n",
    "    }, ## 한 개의 변수로 설명 가능\n",
    "    time_varying_known_reals = [\"time_idx\", \"price_regular\", \"discount_in_percent\"],\n",
    "    time_varying_unknown_categoricals = [],\n",
    "    time_varying_unknown_reals = [\n",
    "        \"volume\",\n",
    "        \"log_volume\",\n",
    "        \"industry_volume\",\n",
    "        \"soda_volume\",\n",
    "        \"avg_max_temp\",\n",
    "        \"avg_volume_by_agency\",\n",
    "        \"avg_volume_by_sku\",\n",
    "    ], ## 정보 유출?\n",
    "    target_normalizer = GroupNormalizer(\n",
    "        groups=[\"agency\", \"sku\"], transformation=\"softplus\"\n",
    "    ),  ## use softplus and normalize by group -> ReLU랑 비슷함\n",
    "    add_relative_time_idx = True,\n",
    "    add_target_scales = True,\n",
    "    add_encoder_length = True\n",
    ")\n",
    "\n",
    "## create validation set\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training, data, predict = True, stop_randomization = True\n",
    ")\n",
    "\n",
    "## create dataloaders for model\n",
    "batch_size = 32\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train = True, batch_size = batch_size, num_workers = 0\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train = False, batch_size = batch_size * 10, num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555a8846",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1bd6eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB MIG 7g.80gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 16:22:00.584750: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754983320.602240    1207 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754983320.607877    1207 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754983320.622003    1207 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754983320.622016    1207 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754983320.622018    1207 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754983320.622019    1207 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-12 16:22:00.626661: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4709, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_predictions = Baseline().predict(val_dataloader, return_y = True)\n",
    "SMAPE()(baseline_predictions.output, baseline_predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c391fa80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 13.5k\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42) ## setting pytorch lightning seed\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator = \"gpu\",\n",
    "    gradient_clip_val = 0.1\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate = 0.03,\n",
    "    hidden_size = 8,\n",
    "    attention_head_size = 1,\n",
    "    dropout = 0.1, ## 0.1 to 0.3\n",
    "    hidden_continuous_size = 8, ## <= hidden_size\n",
    "    loss = QuantileLoss(),\n",
    "    optimizer = \"ranger\",\n",
    "    # reduce_on_plateau_patience = 1000 ## 에폭 이후에도 validation loss 미감소시 사용\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5483df98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py:73: `max_epochs` was not set. Setting it to 1000 epochs. To train without an epoch limit, set `max_epochs=-1`.\n",
      "You are using a CUDA device ('NVIDIA A100-SXM4-80GB MIG 7g.80gb') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-12 20:12:01.645077: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754997121.663897   38413 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754997121.670316   38413 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754997121.686391   38413 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754997121.686406   38413 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754997121.686408   38413 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754997121.686410   38413 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-12 20:12:01.691866: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n",
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53c94ae408840a7a89eababa7dec4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:992\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n\u001b[0;32m--> 992\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_callback_hooks\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_fit_start\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    993\u001b[0m     call\u001b[38;5;241m.\u001b[39m_call_lightning_module_hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_fit_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:227\u001b[0m, in \u001b[0;36m_call_callback_hooks\u001b[0;34m(trainer, hook_name, monitoring_callbacks, *args, **kwargs)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Callback]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcallback\u001b[38;5;241m.\u001b[39mstate_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 227\u001b[0m             \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pl_module:\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/callbacks/lr_finder.py:130\u001b[0m, in \u001b[0;36mLearningRateFinder.on_fit_start\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_fit_start\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.Trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m, pl_module: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/callbacks/lr_finder.py:113\u001b[0m, in \u001b[0;36mLearningRateFinder.lr_find\u001b[0;34m(self, trainer, pl_module)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimal_lr \u001b[38;5;241m=\u001b[39m \u001b[43m_lr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpl_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_min_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_lr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_training\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_training_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mearly_stop_threshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_early_stop_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mupdate_attr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_attr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattr_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attr_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_early_exit:\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/tuner/lr_finder.py:278\u001b[0m, in \u001b[0;36m_lr_find\u001b[0;34m(trainer, model, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m# Fit, lr & loss logged in callback\u001b[39;00m\n\u001b[0;32m--> 278\u001b[0m \u001b[43m_try_loop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;66;03m# Prompt if we stopped early\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/tuner/lr_finder.py:523\u001b[0m, in \u001b[0;36m_try_loop_run\u001b[0;34m(trainer, params)\u001b[0m\n\u001b[1;32m    522\u001b[0m loop\u001b[38;5;241m.\u001b[39mrestarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:152\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:344\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1328\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \n\u001b[1;32m   1327\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1328\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:137\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/pytorch_optimizer/optimizer/ranger21.py:200\u001b[0m, in \u001b[0;36mRanger21.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 200\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m param_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:241\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:213\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    211\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[0;32m--> 213\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:73\u001b[0m, in \u001b[0;36mPrecision.backward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m \n\u001b[1;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1097\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1097\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/autograd/graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m## find optimal learning rate\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightning\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuner\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuner\n\u001b[0;32m----> 4\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mTuner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlr_find\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_lr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmin_lr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1e-6\u001b[39;49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuggested learning rate: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39msuggestion()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m fig \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39mplot(show\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, suggest\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/tuner/tuning.py:180\u001b[0m, in \u001b[0;36mTuner.lr_find\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, dataloaders, datamodule, method, min_lr, max_lr, num_training, mode, early_stop_threshold, update_attr, attr_name)\u001b[0m\n\u001b[1;32m    177\u001b[0m lr_finder_callback\u001b[38;5;241m.\u001b[39m_early_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [lr_finder_callback] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks\n\u001b[0;32m--> 180\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;241m=\u001b[39m [cb \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39mcallbacks \u001b[38;5;28;01mif\u001b[39;00m cb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lr_finder_callback]\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lr_finder_callback\u001b[38;5;241m.\u001b[39moptimal_lr\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "## find optimal learning rate\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "res = Tuner(trainer).lr_find(\n",
    "    tft,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader,\n",
    "    max_lr = 10.0,\n",
    "    min_lr = 1e-6\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0e34f",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "337ef9af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 29.4k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    }
   ],
   "source": [
    "early_stop_callback = EarlyStopping(\n",
    "    monitor = \"val_loss\", min_delta = 1e-4, patience = 10, verbose = False, mode = \"min\"\n",
    ")\n",
    "lr_logger = LearningRateMonitor() ## log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\") ## logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = 50,\n",
    "    accelerator = \"gpu\",\n",
    "    enable_model_summary = True,\n",
    "    gradient_clip_val = 0.1,\n",
    "    limit_train_batches = 50, ## comment in for training, running validation every 30 batches\n",
    "    callbacks = [lr_logger, early_stop_callback],\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate = 0.03,\n",
    "    hidden_size = 16,\n",
    "    attention_head_size = 2,\n",
    "    dropout = 0.1,\n",
    "    hidden_continuous_size = 8,\n",
    "    loss = QuantileLoss(),\n",
    "    log_interval = 10, ## 10 batchs마다 로그\n",
    "    optimizer = \"ranger\",\n",
    "    reduce_on_plateau_patience = 4\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c647611",
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders = train_dataloader,\n",
    "    val_dataloaders = val_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd456c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.6430, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = trainer.model.predict(val_dataloader, return_y = True, trainer_kwargs = dict(accelerator = \"gpu\"))\n",
    "SMAPE()(predictions.output, predictions.y) ## Baseline보다 못한데요...? 아직 덜됐나..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b43dc9",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "\n",
    "## create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=200,\n",
    "    max_epochs=50,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "## save study results\n",
    "# with open(\"test_study.pkl\", \"wb\") as f :\n",
    "#     pickle.dump(study, f)\n",
    "    \n",
    "## show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e4422",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "821f71e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/root/Dacon_comp/2025 전력사용량 예측/train.csv\")\n",
    "df_test = pd.read_csv(\"/root/Dacon_comp/2025 전력사용량 예측/test.csv\")\n",
    "building_info = pd.read_csv(\"/root/Dacon_comp/2025 전력사용량 예측/building_info.csv\")\n",
    "\n",
    "df_train = df_train.rename({pre:new for pre, new in zip(df_train.columns, [\"num_date_time\", \"build_num\", \"date\", \"temp\", \"precip\", \"wind\", \"humidity\", \"sunhour\", \"sunweight\", \"power\"])}, axis = 1)\n",
    "df_test = df_test.rename({pre:new for pre, new in zip(df_test.columns, [\"num_date_time\", \"build_num\", \"date\", \"temp\", \"precip\", \"wind\", \"humidity\", \"sunhour\", \"sunweight\"])}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a977ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## information processing\n",
    "building_info = building_info.replace(\"-\", \"0\").rename({c:n for c, n in zip(building_info.columns, [\"build_num\", \"build_type\", \"GFA\", \"CA\", \"solar_gen\", \"ESS\", \"PCS\"])}, axis = 1)\\\n",
    "    .assign(solar_gen = lambda _df : _df.solar_gen.astype(\"float64\"))\\\n",
    "    .assign(ESS = lambda _df : _df.ESS.astype(\"float64\"))\\\n",
    "    .assign(PCS = lambda _df : _df.PCS.astype(\"float64\"))\n",
    "    \n",
    "## one-hot encoding -> 안해도 됨\n",
    "# building_info = pd.get_dummies(building_info, dtype = int)\n",
    "# building_info = building_info.rename({c:f\"type_{i}\" for i, c in enumerate(building_info.columns[6:])}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7cf500d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## dttm으로 타입 변경\n",
    "df_train[\"date\"] = pd.to_datetime(df_train.date)\n",
    "df_test[\"date\"] = pd.to_datetime(df_test.date)\n",
    "holilist = [\"06-06\", \"08-15\"] ## 2024 추석은 9월 17일\n",
    "start_date = df_train.date.min()\n",
    "\n",
    "## train data\n",
    "del_time = df_train.date - start_date\n",
    "df_train[\"time_idx\"] = del_time.dt.days*24 + del_time.dt.seconds//3600\n",
    "df_train[\"month\"] = df_train.date.dt.month.astype(str).astype(\"category\")\n",
    "df_train[\"wday\"] = df_train.date.dt.weekday.astype(str).astype(\"category\")\n",
    "df_train[\"is_holiday\"] = df_train.date.astype(str).str[5:10].map(lambda x : 1 if x in holilist else 0)\n",
    "df_train = df_train.drop([\"num_date_time\", \"date\"], axis = 1)\n",
    "df_train = pd.merge(df_train, building_info, on = \"build_num\")\n",
    "df_train[\"build_num\"] = df_train[\"build_num\"].astype(str).astype(\"category\")\n",
    "\n",
    "## 일단 국경일 이외 special day는 다루지 않기로 함\n",
    "\n",
    "## test data\n",
    "del_time = df_test.date - start_date\n",
    "df_test[\"time_idx\"] = del_time.dt.days*24 + del_time.dt.seconds//3600\n",
    "df_test[\"month\"] = df_test.date.dt.month.astype(str).astype(\"category\")\n",
    "df_test[\"wday\"] = df_test.date.dt.weekday.astype(str).astype(\"category\")\n",
    "df_test[\"is_holiday\"] = 0 ## 8.25 이후 휴일 없음\n",
    "df_test = df_test.drop([\"num_date_time\", \"date\"], axis = 1)\n",
    "df_test = pd.merge(df_test, building_info, on = \"build_num\")\n",
    "df_test[\"build_num\"] = df_test[\"build_num\"].astype(str).astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd43269a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['1', '10', '100', '11', '12', '13', '14', '15', '16', '17', '18', '19',\n",
       "       '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3',\n",
       "       '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40',\n",
       "       '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51',\n",
       "       '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '62',\n",
       "       '63', '64', '65', '66', '67', '68', '69', '7', '70', '71', '72', '73',\n",
       "       '74', '75', '76', '77', '78', '79', '8', '80', '81', '82', '83', '84',\n",
       "       '85', '86', '87', '88', '89', '9', '90', '91', '92', '93', '94', '95',\n",
       "       '96', '97', '98', '99'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.build_num.cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f34201fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'power', 'sunhour', 'sunweight'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df_train.columns) - set(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c673669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 120     ## validation length\n",
    "max_encoder_length = 336        ## lookback (14일)\n",
    "training_cutoff = 1919          ## 0 to 1919 (1920 periods)\n",
    "\n",
    "training = TimeSeriesDataSet(\n",
    "    df_train[df_train.time_idx <= training_cutoff],\n",
    "    time_idx = \"time_idx\",\n",
    "    target = \"power\",\n",
    "    group_ids = [\"build_num\"],\n",
    "    min_encoder_length = max_encoder_length // 2,\n",
    "    max_encoder_length = max_encoder_length,\n",
    "    min_prediction_length = 1,\n",
    "    max_prediction_length = max_prediction_length,\n",
    "    static_categoricals = [\"build_num\", \"build_type\"],\n",
    "    static_reals = [\"GFA\", \"CA\", \"solar_gen\", \"ESS\", \"PCS\"],\n",
    "    # variable_groups = {}, ## 아직은 없는듯?\n",
    "    time_varying_known_categoricals = [\"wday\", \"month\"],\n",
    "    time_varying_known_reals = [\"temp\", \"precip\", \"wind\", \"humidity\", \"is_holiday\"],\n",
    "    time_varying_unknown_reals = [\"sunhour\", \"sunweight\"],\n",
    "    target_normalizer = GroupNormalizer(groups = [\"build_num\"], transformation = \"softplus\"),\n",
    "    add_relative_time_idx = True,\n",
    "    add_target_scales = True, ## 정규화되지 않은 시계열의 중심과 스케일을 피쳐로\n",
    "    add_encoder_length = True ## 인코더의 길이를 static feature에 추가\n",
    ")\n",
    "\n",
    "## create validation set\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training, df_train, predict = True, stop_randomization = True\n",
    ")\n",
    "\n",
    "## create dataloaders\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train = True, batch_size = batch_size, num_workers = 8\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train = False, batch_size = batch_size, num_workers = 0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3d53f1",
   "metadata": {},
   "source": [
    "> 이거 임배딩 할 때, 입력순이 아닌 알파벳 순으로 이뤄지므로, 주의할 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87c3f586",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(31.7957, device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_predictions = Baseline().predict(val_dataloader, return_y = True)\n",
    "SMAPE()(baseline_predictions.output, baseline_predictions.y[0])*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c9a50",
   "metadata": {},
   "source": [
    "## Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c854484d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n",
      "💡 Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 284.1k\n"
     ]
    }
   ],
   "source": [
    "pl.seed_everything(42)\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate = 0.03,\n",
    "    hidden_size = 128,\n",
    "    attention_head_size = 4,\n",
    "    dropout = 0.2,\n",
    "    hidden_continuous_size = 16,\n",
    "    loss = QuantileLoss(),\n",
    "    log_interval = 10,\n",
    "    optimizer = \"ranger\",\n",
    "    # reduce_on_plateau_patience = 1000\n",
    ")\n",
    "\n",
    "\n",
    "## Trainer setting\n",
    "early_stop_callback = EarlyStopping(\n",
    "    monitor = \"val_loss\", min_delta = 1e-4, patience = 10, verbose = False, mode = \"min\"\n",
    ")\n",
    "lr_logger = LearningRateMonitor() ## log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\") ## logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs = 100,\n",
    "    accelerator = \"gpu\",\n",
    "    enable_model_summary = True,\n",
    "    gradient_clip_val = 1.0,\n",
    "    limit_train_batches = 50, ## comment in for training, running validation every 30 batches\n",
    "    callbacks = [lr_logger, early_stop_callback],\n",
    "    logger = logger\n",
    ")\n",
    "\n",
    "print(f\"Number of parameters in network: {tft.size() / 1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5f944ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 2.2 K  | train\n",
      "3  | prescalers                         | ModuleDict                      | 512    | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 26.9 K | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 27.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 20.4 K | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 16.8 K | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 16.8 K | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 16.8 K | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 16.8 K | train\n",
      "11 | lstm_encoder                       | LSTM                            | 33.3 K | train\n",
      "12 | lstm_decoder                       | LSTM                            | 33.3 K | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 8.3 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 128    | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 20.9 K | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 10.4 K | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 8.4 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 16.8 K | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 8.4 K  | train\n",
      "20 | output_layer                       | Linear                          | 455    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "284 K     Trainable params\n",
      "0         Non-trainable params\n",
      "284 K     Total params\n",
      "1.137     Total estimated model params size (MB)\n",
      "513       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61fcbf8ca91d4e1caf941bc15410732f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=127` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e42447f36b146d39eb12602cf402f09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0399ea79e0c541eaa13ed61a7a2f0825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bc2deb50a4468498cb2b8c63c072bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469fd7aafc3f444ca303bac851b5010f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7cad1eda50451cb615e4c43385a9f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6afeef86d68d4a0884d10e6bc51eb886",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abccac6764bf4dfa8e49ab0c5dda5aac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104fe2928b4d4936aafa315bc6c0b3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5f032a851a44620914a51964ad76efc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10a0233f85f4f6ea7b7d2537b9b077a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "632e53a1cb4d4a83a1cfb599aa718b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242c2d0c611e48e29435c0245ee153cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d032b6293b41bea118efc958f58c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83175d2394414ef5be434034ebe89700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "333bec41bf094650aaf9bce03aec463b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:152\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/training_epoch_loop.py:344\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 344\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/core/module.py:1328\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \n\u001b[1;32m   1327\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1328\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/pytorch_optimizer/optimizer/ranger21.py:200\u001b[0m, in \u001b[0;36mRanger21.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 200\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m param_size: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/loops/optimization/automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/pytorch_forecasting/models/base/_base_model.py:716\u001b[0m, in \u001b[0;36mBaseModel.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    715\u001b[0m x, y \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m--> 716\u001b[0m log, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step_outputs\u001b[38;5;241m.\u001b[39mappend(log)\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/pytorch_forecasting/models/base/_base_model.py:911\u001b[0m, in \u001b[0;36mBaseModel.step\u001b[0;34m(self, x, y, batch_idx, **kwargs)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 911\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;66;03m# calculate loss\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/_tft.py:601\u001b[0m, in \u001b[0;36mTemporalFusionTransformer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# run local encoder\u001b[39;00m\n\u001b[0;32m--> 601\u001b[0m encoder_output, (hidden, cell) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm_encoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43membeddings_varying_encoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_cell\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_lengths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m    \u001b[49m\u001b[43menforce_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;66;03m# run local decoder\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/pytorch_forecasting/models/nn/rnn.py:126\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, x, hx, lengths, enforce_sorted)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     pack_lengths \u001b[38;5;241m=\u001b[39m lengths\u001b[38;5;241m.\u001b[39mwhere(lengths \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlengths\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    127\u001b[0m     packed_out, hidden_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(\n\u001b[1;32m    128\u001b[0m         rnn\u001b[38;5;241m.\u001b[39mpack_padded_sequence(\n\u001b[1;32m    129\u001b[0m             x,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m         hx\u001b[38;5;241m=\u001b[39mhx,\n\u001b[1;32m    135\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/trch/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "trainer.fit(tft, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc64f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trainer, \"TFT_trainer.trch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "10d30321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"TFT_trainer.trch\", weights_only = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a31e3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_52069/3565293027.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  trainer = torch.load(\".lr_find_8cb93e1c-284d-4a94-ad02-fa42882c201e.ckpt\")\n"
     ]
    }
   ],
   "source": [
    "trainer = torch.load(\".lr_find_8cb93e1c-284d-4a94-ad02-fa42882c201e.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3209be96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters', 'dataset_parameters', '__special_save__'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2855f0de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('input_embeddings.embeddings.agency.weight',\n",
       "              tensor([[ 1.9269e+00,  1.4873e+00,  9.0072e-01, -2.1055e+00,  6.7842e-01,\n",
       "                       -1.2345e+00, -4.3067e-02, -1.6047e+00],\n",
       "                      [-7.5214e-01,  1.6487e+00, -3.9248e-01, -1.4036e+00, -7.2788e-01,\n",
       "                       -5.5943e-01, -7.6884e-01,  7.6245e-01],\n",
       "                      [ 1.6423e+00, -1.5960e-01, -4.9740e-01,  4.3959e-01, -7.5813e-01,\n",
       "                        1.0783e+00,  8.0080e-01,  1.6806e+00],\n",
       "                      [ 1.2791e+00,  1.2964e+00,  6.1047e-01,  1.3347e+00, -2.3162e-01,\n",
       "                        4.1759e-02, -2.5158e-01,  8.5986e-01],\n",
       "                      [-1.3847e+00, -8.7124e-01, -2.2337e-01,  1.7174e+00,  3.1888e-01,\n",
       "                       -4.2452e-01,  3.0572e-01, -7.7459e-01],\n",
       "                      [-1.5576e+00,  9.9564e-01, -8.7979e-01, -6.0114e-01, -1.2742e+00,\n",
       "                        2.1228e+00, -1.2347e+00, -4.8791e-01],\n",
       "                      [-9.1382e-01, -6.5814e-01,  7.8024e-02,  5.2581e-01, -4.8799e-01,\n",
       "                        1.1914e+00, -8.1401e-01, -7.3599e-01],\n",
       "                      [-1.4032e+00,  3.6004e-02, -6.3477e-02,  6.7561e-01, -9.7807e-02,\n",
       "                        1.8446e+00, -1.1845e+00,  1.3835e+00],\n",
       "                      [ 1.4451e+00,  8.5641e-01,  2.2181e+00,  5.2317e-01,  3.4665e-01,\n",
       "                       -1.9733e-01, -1.0546e+00,  1.2780e+00],\n",
       "                      [-1.7219e-01,  5.2379e-01,  5.6622e-02,  4.2630e-01,  5.7501e-01,\n",
       "                       -6.4172e-01, -2.2064e+00, -7.5080e-01],\n",
       "                      [ 1.0868e-02, -3.3874e-01, -1.3407e+00, -5.8537e-01,  5.3619e-01,\n",
       "                        5.2462e-01,  1.1412e+00,  5.1644e-02],\n",
       "                      [ 7.4395e-01, -4.8158e-01, -1.0495e+00,  6.0390e-01, -1.7223e+00,\n",
       "                       -8.2777e-01,  1.3347e+00,  4.8354e-01],\n",
       "                      [-2.5095e+00,  4.8800e-01,  7.8459e-01,  2.8647e-02,  6.4076e-01,\n",
       "                        5.8325e-01,  1.0669e+00, -4.5015e-01],\n",
       "                      [-1.8527e-01,  7.5276e-01,  4.0476e-01,  1.7847e-01,  2.6491e-01,\n",
       "                        1.2732e+00, -1.3109e-03, -3.0360e-01],\n",
       "                      [-1.4570e+00, -1.0234e-01, -5.9915e-01,  4.7706e-01,  7.2618e-01,\n",
       "                        9.1152e-02, -3.8907e-01,  5.2792e-01],\n",
       "                      [-1.2685e-02,  2.4084e-01,  1.3254e-01,  7.6424e-01,  1.0950e+00,\n",
       "                        3.3989e-01,  7.1997e-01,  4.1141e-01],\n",
       "                      [ 1.9312e+00,  1.0119e+00, -1.4364e+00, -1.1299e+00, -1.3603e-01,\n",
       "                        1.6354e+00,  6.5474e-01,  5.7600e-01],\n",
       "                      [ 1.1415e+00,  1.8565e-02, -1.8058e+00,  9.2543e-01, -3.7534e-01,\n",
       "                        1.0331e+00, -6.8665e-01,  6.3681e-01],\n",
       "                      [-9.7267e-01,  9.5846e-01,  1.6192e+00,  1.4506e+00,  2.6948e-01,\n",
       "                       -2.1038e-01, -7.3280e-01,  1.0430e-01],\n",
       "                      [ 3.4875e-01,  9.6759e-01, -4.6569e-01,  1.6048e+00, -2.4801e+00,\n",
       "                       -4.1754e-01, -1.1955e+00,  8.1234e-01],\n",
       "                      [-1.9006e+00,  2.2858e-01,  2.4859e-02, -3.4595e-01,  2.8683e-01,\n",
       "                       -7.3084e-01,  1.7482e-01, -1.0939e+00],\n",
       "                      [-1.6022e+00,  1.3529e+00,  1.2888e+00,  5.2295e-02, -1.5469e+00,\n",
       "                        7.5671e-01,  7.7552e-01,  2.0265e+00],\n",
       "                      [ 3.5818e-02,  1.2059e-01, -8.0566e-01, -2.0758e-01, -9.3195e-01,\n",
       "                       -1.5910e+00, -1.1360e+00, -5.2260e-01],\n",
       "                      [-5.1877e-01, -1.5013e+00, -1.9267e+00,  1.2785e-01,  1.0229e+00,\n",
       "                       -5.5580e-01,  7.0427e-01,  7.0988e-01],\n",
       "                      [ 1.7744e+00, -9.2155e-01,  9.6245e-01, -3.3702e-01, -1.1753e+00,\n",
       "                        3.5806e-01,  4.7877e-01,  1.3537e+00],\n",
       "                      [ 5.2606e-01,  2.1120e+00, -5.2076e-01, -9.3201e-01,  1.8516e-01,\n",
       "                        1.0687e+00,  1.3065e+00,  4.5983e-01],\n",
       "                      [-8.1463e-01, -1.0212e+00, -4.9492e-01, -5.9225e-01,  1.5432e-01,\n",
       "                        4.4077e-01, -1.4829e-01, -2.3184e+00],\n",
       "                      [-3.9800e-01,  1.0805e+00, -1.7809e+00,  1.5080e+00,  3.0943e-01,\n",
       "                       -5.0031e-01,  1.0350e+00,  1.6896e+00],\n",
       "                      [-4.5051e-03,  1.6668e+00,  1.5392e-01, -1.0603e+00, -5.7266e-01,\n",
       "                        8.3568e-02,  3.9991e-01,  1.9892e+00],\n",
       "                      [-7.1988e-02, -9.0609e-01, -2.0487e+00, -1.0811e+00,  1.7623e-02,\n",
       "                        7.8226e-02,  1.9316e-01,  4.0967e-01],\n",
       "                      [-9.2913e-01,  2.7619e-01, -5.3888e-01,  4.6258e-01, -8.7189e-01,\n",
       "                       -2.7118e-02, -3.5325e-01,  1.4639e+00],\n",
       "                      [ 1.2554e+00, -7.1496e-01,  8.5392e-01,  5.1299e-01,  5.3973e-01,\n",
       "                        5.6551e-01,  5.0579e-01,  2.2245e-01],\n",
       "                      [-6.8548e-01,  5.6356e-01, -1.5072e+00, -1.6107e+00, -1.4790e+00,\n",
       "                        4.3227e-01, -1.2503e-01,  7.8212e-01],\n",
       "                      [-1.5988e+00, -1.0913e-01,  7.1520e-01,  3.9139e-02,  1.3059e+00,\n",
       "                        2.4659e-01, -1.9776e+00,  1.7896e-02],\n",
       "                      [-1.3793e+00,  6.2580e-01, -2.5850e+00, -2.4000e-02, -1.2219e-01,\n",
       "                       -7.4700e-01,  1.7093e+00,  5.7923e-02],\n",
       "                      [ 1.1930e+00,  1.9373e+00,  7.2871e-01,  9.8089e-01,  4.1459e-01,\n",
       "                        1.1566e+00,  2.6905e-01, -3.6629e-02],\n",
       "                      [ 9.7329e-01, -1.0151e+00, -5.4192e-01, -4.4102e-01, -3.1362e-01,\n",
       "                       -1.2925e-01, -7.1496e-01, -4.7562e-02],\n",
       "                      [ 2.0207e+00,  2.5392e-01,  9.3644e-01,  7.1224e-01, -3.1766e-02,\n",
       "                        1.0164e-01,  1.3433e+00,  7.1327e-01],\n",
       "                      [ 4.0380e-01, -7.1398e-01,  8.3373e-01, -9.5855e-01,  4.5363e-01,\n",
       "                        1.2461e+00, -2.3065e+00, -1.2869e+00],\n",
       "                      [ 1.7989e-01, -2.1268e+00, -1.3408e-01, -1.0408e+00, -7.6472e-01,\n",
       "                       -5.5283e-02,  1.2049e+00, -9.8247e-01],\n",
       "                      [ 4.3344e-01, -7.1719e-01,  1.0554e+00, -1.4534e+00,  4.6515e-01,\n",
       "                        3.7139e-01, -4.6568e-03,  7.9549e-02],\n",
       "                      [ 3.7818e-01,  7.0511e-01, -1.7237e+00, -8.4348e-01,  4.3514e-01,\n",
       "                        2.6589e-01, -5.8710e-01,  8.2689e-02],\n",
       "                      [ 8.8538e-01,  1.8244e-01,  7.8638e-01, -5.7920e-02,  5.6667e-01,\n",
       "                       -7.0976e-01, -4.8751e-01,  5.0096e-02],\n",
       "                      [ 6.0841e-01,  1.6309e+00, -8.4723e-02,  1.0844e+00,  9.4777e-01,\n",
       "                       -6.7663e-01, -5.7302e-01, -3.3032e-01],\n",
       "                      [-7.9394e-01,  3.7523e-01,  8.7910e-02, -1.2415e+00, -3.2025e-01,\n",
       "                       -8.4438e-01, -5.5135e-01,  1.9890e+00],\n",
       "                      [ 1.9003e+00,  1.6951e+00,  2.8090e-02, -1.7537e-01, -1.7735e+00,\n",
       "                       -7.0464e-01, -3.9465e-01,  1.8868e+00],\n",
       "                      [-2.1844e-01,  1.6630e-01,  2.1442e+00,  1.7046e+00,  3.4590e-01,\n",
       "                        6.4248e-01, -2.0395e-01,  6.8537e-01],\n",
       "                      [-1.3969e-01, -1.1808e+00, -1.2829e+00,  4.4849e-01, -5.9074e-01,\n",
       "                        8.5406e-01, -4.9007e-01, -3.5946e-01],\n",
       "                      [ 6.6637e-01, -7.4265e-02, -2.0960e-01,  1.6632e-01,  1.4703e+00,\n",
       "                       -9.3909e-01, -6.0132e-01, -9.9640e-02],\n",
       "                      [-9.8515e-01, -2.4885e+00, -3.3132e-01,  8.4358e-01,  9.8745e-01,\n",
       "                       -3.3197e-01, -8.0762e-01,  8.2436e-01],\n",
       "                      [ 2.4700e-02, -1.0641e+00, -7.6019e-01, -4.0751e-01,  9.6236e-01,\n",
       "                       -1.4264e-01,  1.5271e-01, -3.8802e-02],\n",
       "                      [ 9.4461e-01, -1.5824e+00,  9.8713e-01,  1.1457e+00, -1.4181e-01,\n",
       "                       -2.7634e-01, -1.9321e-01,  7.7678e-01],\n",
       "                      [ 6.8388e-01, -1.3246e+00, -5.1608e-01,  6.0018e-01, -4.7022e-01,\n",
       "                       -6.0864e-01, -4.6192e-02, -1.6457e+00],\n",
       "                      [-4.8333e-01, -7.4029e-01,  3.1428e-01,  1.4156e-01,  1.0348e+00,\n",
       "                       -6.2644e-01, -5.1509e-01,  6.9029e-01],\n",
       "                      [-4.9400e-01,  1.1366e+00, -4.6184e-01,  1.4200e+00,  8.4852e-01,\n",
       "                       -4.7891e-02,  6.6856e-01,  1.0430e+00],\n",
       "                      [ 6.8990e-01, -1.3129e+00,  3.7804e-02, -1.1702e+00, -1.0319e-01,\n",
       "                        1.1895e+00,  7.6069e-01, -7.4630e-01],\n",
       "                      [-1.3839e+00,  4.8687e-01, -1.0020e+00,  3.2949e-02, -4.2920e-01,\n",
       "                       -9.8180e-01, -6.4206e-01,  8.2659e-01],\n",
       "                      [ 1.5914e+00, -1.2081e-01, -4.8302e-01,  1.1330e-01,  7.7151e-02,\n",
       "                       -9.2281e-01, -1.2620e+00,  1.0861e+00]], device='cuda:0')),\n",
       "             ('input_embeddings.embeddings.sku.weight',\n",
       "              tensor([[ 1.0966e+00, -6.8369e-01,  6.6043e-02, -7.7380e-04,  1.6206e-01,\n",
       "                        1.1960e+00, -1.3062e+00, -1.4040e+00],\n",
       "                      [-1.0597e+00,  3.0573e-01,  4.1506e-01, -7.1741e-01,  2.8340e+00,\n",
       "                        1.9535e+00,  2.0487e+00, -1.0880e+00],\n",
       "                      [ 1.6217e+00,  8.5127e-01, -4.0047e-01, -6.0883e-01, -5.0810e-01,\n",
       "                       -6.1849e-01, -1.6470e+00, -1.0362e+00],\n",
       "                      [-4.5031e-01, -7.2966e-02, -5.4795e-01, -1.1426e+00, -4.4875e-01,\n",
       "                       -3.0454e-02,  3.8303e-01, -4.4770e-02],\n",
       "                      [ 1.1799e+00, -3.3143e-01,  6.4950e-01,  9.4959e-02, -7.5259e-01,\n",
       "                       -6.4723e-01, -1.2823e+00,  1.9653e+00],\n",
       "                      [-9.6385e-01, -2.5668e+00,  7.0961e-01,  8.1984e-01,  6.2145e-01,\n",
       "                        4.2319e-01, -3.3890e-01,  5.1797e-01],\n",
       "                      [-1.3638e+00,  1.9296e-01, -6.1033e-01,  1.6323e-01,  1.5102e+00,\n",
       "                        2.1230e-01, -7.2520e-01, -9.5277e-01],\n",
       "                      [ 5.2169e-01, -4.6387e-01,  1.8238e-01, -3.8666e-01, -1.7907e+00,\n",
       "                        9.3293e-02, -1.9153e+00, -6.4218e-01],\n",
       "                      [ 1.3439e+00, -1.2922e+00,  7.6624e-01,  6.4540e-01,  3.5332e-01,\n",
       "                       -2.6475e+00, -1.4575e+00, -9.7124e-01],\n",
       "                      [ 2.5403e-01, -1.7906e-01,  1.1993e+00, -4.2922e-01,  1.0103e+00,\n",
       "                        6.1104e-01,  1.2208e+00, -6.0764e-01],\n",
       "                      [-1.7376e+00, -1.2535e-01, -1.3658e+00,  1.1117e+00, -6.2280e-01,\n",
       "                       -7.8918e-01, -1.6782e-01,  1.6433e+00],\n",
       "                      [ 2.0071e+00, -1.2531e+00,  1.1189e+00,  1.7733e+00, -2.0717e+00,\n",
       "                       -4.1253e-01, -9.7696e-01, -3.3634e-02],\n",
       "                      [ 1.8595e+00,  2.6221e+00,  3.6905e-01,  3.8030e-01,  1.9898e-01,\n",
       "                       -2.3609e-01,  3.0341e-01, -4.5008e-01],\n",
       "                      [ 4.7390e-01,  6.5034e-01,  1.1662e+00,  1.6936e-02,  5.3259e-01,\n",
       "                       -6.0354e-01, -1.7426e-01,  6.0921e-01],\n",
       "                      [-8.0322e-01, -1.1209e+00,  1.9564e-01, -7.8152e-01, -1.7899e+00,\n",
       "                       -2.6157e-01, -4.4025e-01,  2.1848e+00],\n",
       "                      [-4.8010e-01, -1.2872e+00,  7.3888e-01,  3.3895e-02, -3.1229e-01,\n",
       "                       -2.5418e-01, -1.2055e+00, -9.5421e-01],\n",
       "                      [ 6.1277e-02,  8.5261e-02,  7.4813e-01, -1.6356e-01, -9.0856e-01,\n",
       "                        3.1300e-01,  8.0505e-01, -1.1134e+00],\n",
       "                      [ 4.9816e-01, -1.2000e+00,  1.2711e-01,  4.4037e-01,  6.3777e-01,\n",
       "                        1.5979e-01,  1.7698e+00,  6.2682e-01],\n",
       "                      [-1.8737e+00,  2.3259e+00, -9.2039e-01,  6.6611e-01, -4.4026e-01,\n",
       "                       -2.3180e+00,  1.2946e+00,  2.2267e-01],\n",
       "                      [-8.4834e-01,  1.6489e+00,  1.6006e+00, -7.8589e-02,  4.3105e-01,\n",
       "                        3.6835e-01,  7.6380e-01,  1.1792e+00],\n",
       "                      [-4.1379e-01,  5.1841e-01, -7.0154e-01, -4.3234e-01,  1.4148e-01,\n",
       "                        7.1104e-02,  5.6335e-01, -5.7864e-01],\n",
       "                      [-1.0838e+00, -3.8893e-01,  8.1261e-01,  1.4981e+00,  4.3896e-02,\n",
       "                        1.4443e+00,  2.3203e-01,  5.0650e-01],\n",
       "                      [-1.2787e+00, -3.8427e-02,  1.9138e+00,  3.3784e-01,  1.2506e-01,\n",
       "                       -7.6215e-01, -1.1906e+00,  7.7561e-01],\n",
       "                      [ 1.5193e+00,  3.5802e-02,  1.0366e+00,  8.8169e-01, -1.3237e+00,\n",
       "                       -3.6746e-01,  1.0117e+00, -1.4080e+00],\n",
       "                      [-1.9967e-02, -1.2131e+00,  1.1971e+00, -7.8177e-01,  1.1162e+00,\n",
       "                        2.9159e-01,  2.9770e-01,  7.5923e-01]], device='cuda:0')),\n",
       "             ('input_embeddings.embeddings.special_days.weight',\n",
       "              tensor([[ 1.9491e+00, -4.2519e-01, -3.7528e-01,  1.4467e+00, -7.8717e-01,\n",
       "                        2.4992e+00],\n",
       "                      [-3.0195e-01,  2.2069e-01,  2.1163e-01,  1.2271e+00, -5.7228e-01,\n",
       "                       -1.7070e-01],\n",
       "                      [-4.5870e-01, -1.5441e-01, -2.1314e-01, -8.8802e-01, -1.5147e+00,\n",
       "                        1.8518e+00],\n",
       "                      [-1.7016e-01, -1.3861e+00,  1.6513e+00, -5.1567e-01, -7.5318e-01,\n",
       "                       -5.5455e-02],\n",
       "                      [-1.5256e+00,  1.2538e+00, -6.8434e-01, -2.1216e+00,  7.2196e-01,\n",
       "                       -5.9426e-01],\n",
       "                      [ 1.9674e-01, -4.0626e-01, -1.2157e+00,  1.5274e-02, -1.0486e+00,\n",
       "                        1.7823e+00],\n",
       "                      [-5.9511e-01, -1.4568e-01, -3.8542e-01,  8.1006e-01,  1.2704e+00,\n",
       "                       -7.5035e-02],\n",
       "                      [-2.2950e+00, -1.3631e+00,  1.4306e+00, -2.5830e-01, -7.9175e-01,\n",
       "                        4.7021e-01],\n",
       "                      [ 1.2479e-01,  4.9390e-01,  1.8783e+00,  1.8154e-01, -7.1250e-01,\n",
       "                       -1.5326e-01],\n",
       "                      [ 8.2447e-01,  1.4659e+00, -1.0087e-03, -8.4943e-01, -5.1238e-01,\n",
       "                        5.5741e-01],\n",
       "                      [-1.7602e-02, -1.9953e+00,  1.2103e+00, -1.3310e-01,  8.2437e-01,\n",
       "                        7.9835e-01]], device='cuda:0')),\n",
       "             ('input_embeddings.embeddings.month.weight',\n",
       "              tensor([[-0.3444, -0.1889,  0.0417, -0.3357, -1.2594, -0.2131],\n",
       "                      [ 0.3444, -3.1016, -0.8881, -0.5891,  0.1307,  1.7127],\n",
       "                      [ 0.6464,  0.1379,  0.5234, -0.8212,  0.0929, -0.7844],\n",
       "                      [ 0.0350,  0.8422, -0.2108,  0.8012,  0.0169,  0.0803],\n",
       "                      [-1.2598, -0.7298,  1.2975, -0.0965,  1.3945, -1.3005],\n",
       "                      [-0.7347,  0.0447,  1.7551,  0.0675, -0.3978,  0.7583],\n",
       "                      [-0.5347, -0.1458,  0.9213,  0.5282,  0.6138, -0.2786],\n",
       "                      [ 0.5885,  0.7091, -0.2645, -2.9836, -0.4146,  1.4559],\n",
       "                      [-0.5218,  0.8302, -0.0510,  1.4310,  0.3673, -0.0192],\n",
       "                      [-1.0667, -1.9893,  0.3416,  1.5886, -0.3489, -0.4579],\n",
       "                      [-1.2322, -0.5981, -0.1349,  0.1488,  0.4250,  0.4826],\n",
       "                      [ 0.4881,  1.0082, -0.5950,  0.3926, -1.4314, -0.0398]],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.avg_population_2017.weight',\n",
       "              tensor([[ 0.3588],\n",
       "                      [-0.3940],\n",
       "                      [-0.9364],\n",
       "                      [ 0.3622],\n",
       "                      [-0.4955],\n",
       "                      [ 0.5089],\n",
       "                      [ 0.6685],\n",
       "                      [ 0.3857]], device='cuda:0')),\n",
       "             ('prescalers.avg_population_2017.bias',\n",
       "              tensor([ 0.9383,  0.9498,  0.2117, -0.7286,  0.8934, -0.4745, -0.4724,  0.8368],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.avg_yearly_household_income_2017.weight',\n",
       "              tensor([[ 0.7748],\n",
       "                      [ 0.3022],\n",
       "                      [ 0.0627],\n",
       "                      [-0.8412],\n",
       "                      [-0.1038],\n",
       "                      [ 0.9591],\n",
       "                      [ 0.2547],\n",
       "                      [ 0.0856]], device='cuda:0')),\n",
       "             ('prescalers.avg_yearly_household_income_2017.bias',\n",
       "              tensor([-0.2077, -0.3488,  0.5960,  0.0617,  0.6506, -0.1770,  0.4369,  0.4128],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.encoder_length.weight',\n",
       "              tensor([[ 0.1595],\n",
       "                      [ 0.6284],\n",
       "                      [ 0.6266],\n",
       "                      [ 0.9269],\n",
       "                      [ 0.7688],\n",
       "                      [-0.2557],\n",
       "                      [-0.8466],\n",
       "                      [ 0.1828]], device='cuda:0')),\n",
       "             ('prescalers.encoder_length.bias',\n",
       "              tensor([-0.0087, -0.2608, -0.1675,  0.0470,  0.7296,  0.3117, -0.3551, -0.4112],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.volume_center.weight',\n",
       "              tensor([[-0.2476],\n",
       "                      [-0.3865],\n",
       "                      [ 0.8992],\n",
       "                      [ 0.5296],\n",
       "                      [ 0.9030],\n",
       "                      [ 0.0032],\n",
       "                      [ 0.2017],\n",
       "                      [ 0.3468]], device='cuda:0')),\n",
       "             ('prescalers.volume_center.bias',\n",
       "              tensor([-0.9466,  0.0893, -0.0669, -0.5607, -0.7759,  0.8853,  0.8131,  0.4635],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.volume_scale.weight',\n",
       "              tensor([[ 0.9542],\n",
       "                      [-0.4058],\n",
       "                      [-0.1727],\n",
       "                      [ 0.3786],\n",
       "                      [-0.1652],\n",
       "                      [-0.1962],\n",
       "                      [-0.8266],\n",
       "                      [ 0.2687]], device='cuda:0')),\n",
       "             ('prescalers.volume_scale.bias',\n",
       "              tensor([-0.6043,  0.0364,  0.9750, -0.3078, -0.3152,  0.6033, -0.3677, -0.0859],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.time_idx.weight',\n",
       "              tensor([[ 0.9337],\n",
       "                      [-0.4100],\n",
       "                      [-0.7154],\n",
       "                      [-0.5596],\n",
       "                      [-0.2772],\n",
       "                      [-0.4745],\n",
       "                      [-0.5189],\n",
       "                      [ 0.4039]], device='cuda:0')),\n",
       "             ('prescalers.time_idx.bias',\n",
       "              tensor([ 0.1699, -0.3201, -0.7769, -0.3149, -0.4220, -0.3254, -0.9021,  0.2154],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.price_regular.weight',\n",
       "              tensor([[-0.7347],\n",
       "                      [-0.7788],\n",
       "                      [-0.8170],\n",
       "                      [ 0.4174],\n",
       "                      [-0.6020],\n",
       "                      [-0.4128],\n",
       "                      [ 0.7838],\n",
       "                      [ 0.5310]], device='cuda:0')),\n",
       "             ('prescalers.price_regular.bias',\n",
       "              tensor([ 0.5734, -0.9495, -0.7171, -0.3775,  0.8261,  0.1023, -0.7479,  0.0063],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.discount_in_percent.weight',\n",
       "              tensor([[-0.7767],\n",
       "                      [-0.2191],\n",
       "                      [-0.2750],\n",
       "                      [ 0.8657],\n",
       "                      [ 0.3097],\n",
       "                      [-0.1744],\n",
       "                      [ 0.1689],\n",
       "                      [-0.2887]], device='cuda:0')),\n",
       "             ('prescalers.discount_in_percent.bias',\n",
       "              tensor([ 0.3929,  0.3956,  0.2685, -0.3898,  0.8532, -0.1444, -0.3893,  0.6263],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.relative_time_idx.weight',\n",
       "              tensor([[ 0.8151],\n",
       "                      [ 0.9952],\n",
       "                      [ 0.2963],\n",
       "                      [-0.3409],\n",
       "                      [ 0.5079],\n",
       "                      [ 0.8580],\n",
       "                      [-0.9808],\n",
       "                      [-0.1239]], device='cuda:0')),\n",
       "             ('prescalers.relative_time_idx.bias',\n",
       "              tensor([-0.6820,  0.1864,  0.4136, -0.2066, -0.0837,  0.4501, -0.1681, -0.8398],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.volume.weight',\n",
       "              tensor([[ 0.8001],\n",
       "                      [-0.5033],\n",
       "                      [-0.1099],\n",
       "                      [ 0.0943],\n",
       "                      [-0.0601],\n",
       "                      [-0.9407],\n",
       "                      [ 0.4588],\n",
       "                      [-0.4542]], device='cuda:0')),\n",
       "             ('prescalers.volume.bias',\n",
       "              tensor([-0.5187,  0.2389, -0.5219, -0.4622, -0.3369, -0.3757, -0.4176, -0.2697],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.log_volume.weight',\n",
       "              tensor([[ 0.2599],\n",
       "                      [-0.8092],\n",
       "                      [-0.6053],\n",
       "                      [ 0.0146],\n",
       "                      [ 0.1391],\n",
       "                      [ 0.5523],\n",
       "                      [-0.7024],\n",
       "                      [ 0.3192]], device='cuda:0')),\n",
       "             ('prescalers.log_volume.bias',\n",
       "              tensor([ 0.5684,  0.5553, -0.9314, -0.3816, -0.8596, -0.6328,  0.5570, -0.1493],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.industry_volume.weight',\n",
       "              tensor([[ 0.4247],\n",
       "                      [-0.5870],\n",
       "                      [ 0.1520],\n",
       "                      [-0.6049],\n",
       "                      [ 0.4999],\n",
       "                      [-0.4374],\n",
       "                      [-0.2508],\n",
       "                      [-0.8676]], device='cuda:0')),\n",
       "             ('prescalers.industry_volume.bias',\n",
       "              tensor([ 0.0033,  0.9495,  0.4854, -0.5335,  0.0134, -0.1096, -0.8051,  0.7841],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.soda_volume.weight',\n",
       "              tensor([[ 0.0161],\n",
       "                      [ 0.2106],\n",
       "                      [-0.4038],\n",
       "                      [-0.4679],\n",
       "                      [ 0.1649],\n",
       "                      [ 0.3697],\n",
       "                      [ 0.2243],\n",
       "                      [-0.4819]], device='cuda:0')),\n",
       "             ('prescalers.soda_volume.bias',\n",
       "              tensor([ 9.7090e-01, -1.4720e-01, -6.1242e-01, -4.6771e-01,  9.8442e-01,\n",
       "                       4.8161e-05, -1.3574e-01, -4.1616e-01], device='cuda:0')),\n",
       "             ('prescalers.avg_max_temp.weight',\n",
       "              tensor([[-0.2621],\n",
       "                      [-0.8422],\n",
       "                      [-0.7947],\n",
       "                      [ 0.5853],\n",
       "                      [ 0.8554],\n",
       "                      [ 0.9543],\n",
       "                      [-0.7219],\n",
       "                      [ 0.5409]], device='cuda:0')),\n",
       "             ('prescalers.avg_max_temp.bias',\n",
       "              tensor([-0.6190,  0.5966,  0.7216,  0.7739,  0.7201,  0.6256,  0.0195,  0.4595],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.avg_volume_by_agency.weight',\n",
       "              tensor([[-0.3578],\n",
       "                      [ 0.4354],\n",
       "                      [-0.3214],\n",
       "                      [-0.0168],\n",
       "                      [-0.8704],\n",
       "                      [-0.2615],\n",
       "                      [-0.5259],\n",
       "                      [-0.3373]], device='cuda:0')),\n",
       "             ('prescalers.avg_volume_by_agency.bias',\n",
       "              tensor([-0.6386, -0.8994,  0.0651,  0.6490,  0.9107,  0.5836, -0.5183, -0.9890],\n",
       "                     device='cuda:0')),\n",
       "             ('prescalers.avg_volume_by_sku.weight',\n",
       "              tensor([[ 0.3793],\n",
       "                      [ 0.5603],\n",
       "                      [-0.8585],\n",
       "                      [ 0.3586],\n",
       "                      [ 0.8455],\n",
       "                      [ 0.0606],\n",
       "                      [-0.6025],\n",
       "                      [ 0.8199]], device='cuda:0')),\n",
       "             ('prescalers.avg_volume_by_sku.bias',\n",
       "              tensor([ 0.4270,  0.6622, -0.6763,  0.5819, -0.6831,  0.9895, -0.4237,  0.6026],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.resample_norm.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.resample_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.resample_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.fc1.weight',\n",
       "              tensor([[-3.2065e-01, -4.1018e-01, -6.7443e-02, -1.2159e-01,  5.2404e-02,\n",
       "                       -1.6371e-01, -2.5878e-01, -3.2199e-02, -4.6966e-02, -1.7246e-01,\n",
       "                       -1.5916e-01,  1.7118e-01,  1.6790e-01, -1.4983e-01,  1.0096e-01,\n",
       "                        2.1661e-01,  9.7937e-02, -2.1937e-01, -1.9326e-01, -9.5707e-02,\n",
       "                        1.4744e-01, -6.4183e-03,  7.8214e-02, -1.6174e-01, -2.8075e-01,\n",
       "                       -4.5122e-02, -4.9591e-02, -1.1023e-01, -1.3764e-01,  7.4263e-02,\n",
       "                       -2.4866e-01, -1.5630e-01,  5.3845e-06,  2.6914e-01, -1.1718e-01,\n",
       "                       -1.7007e-01,  9.0554e-02, -4.6889e-02, -2.4744e-01, -5.5175e-02,\n",
       "                       -1.1403e-01,  8.7438e-02,  4.7121e-02, -3.2244e-02, -1.1605e-01,\n",
       "                        1.0120e-01, -3.1454e-01, -2.9193e-02, -3.1209e-01,  2.3158e-01,\n",
       "                       -2.2423e-01,  9.1855e-02, -7.6035e-02,  2.2652e-02, -3.2664e-02,\n",
       "                        1.6756e-01],\n",
       "                      [ 1.2456e-01, -1.6119e-02,  1.8094e-01,  8.5552e-02,  7.7726e-02,\n",
       "                       -4.5537e-01, -9.6680e-02, -1.0103e-01, -1.3792e-01,  1.8938e-01,\n",
       "                        3.7013e-02,  2.8856e-01, -3.0101e-01,  1.3038e-01, -9.0543e-02,\n",
       "                       -1.7728e-01, -1.3110e-01,  2.4318e-01,  2.7703e-02,  3.4573e-02,\n",
       "                       -5.3337e-02, -3.2635e-01, -9.4532e-02, -3.4374e-02,  2.6273e-01,\n",
       "                       -1.2048e-01, -4.1689e-02, -9.3817e-02,  2.7696e-02,  1.8621e-01,\n",
       "                        7.6846e-02,  7.6683e-02,  1.0526e-01,  1.2890e-02,  2.3607e-01,\n",
       "                       -1.5767e-01,  1.4147e-01, -3.9559e-01,  5.1708e-02, -2.3441e-01,\n",
       "                       -9.3380e-02,  1.8141e-01,  1.0963e-01, -1.9320e-01, -1.3387e-01,\n",
       "                        1.1262e-02, -1.2970e-01,  2.0219e-02, -2.7748e-02,  2.6718e-01,\n",
       "                       -1.1132e-01, -1.0963e-01,  1.4005e-01,  3.5238e-01, -2.4708e-01,\n",
       "                        6.2969e-02],\n",
       "                      [-2.9150e-01,  2.1604e-01,  2.5632e-01, -2.3594e-01, -4.8619e-03,\n",
       "                        3.6600e-01, -1.7381e-01,  1.6467e-01,  1.0230e-01, -2.4329e-01,\n",
       "                       -2.2752e-01, -1.2437e-01, -6.7618e-02,  7.9404e-02, -1.2899e-03,\n",
       "                        6.2410e-02, -9.2758e-02, -9.1810e-02, -9.2617e-02,  1.7399e-01,\n",
       "                       -1.1879e-01,  1.2593e-01, -6.7032e-03, -2.1586e-02, -2.6575e-01,\n",
       "                        5.1557e-02,  1.3841e-01,  3.2405e-01, -5.0796e-01, -8.0172e-03,\n",
       "                        1.3391e-01, -2.4184e-01, -1.0044e-01,  2.3758e-01,  1.0892e-01,\n",
       "                       -1.8469e-01, -2.8981e-01,  1.5086e-01, -9.5976e-02, -1.7322e-01,\n",
       "                       -2.9545e-01, -3.3075e-01,  1.7305e-01, -1.3300e-01,  2.4556e-01,\n",
       "                       -3.1334e-01,  5.9539e-01, -3.8799e-02,  3.1740e-02, -6.2170e-03,\n",
       "                        6.9074e-02, -7.5398e-03, -2.2882e-01, -3.2121e-01, -9.1088e-02,\n",
       "                       -1.8843e-01],\n",
       "                      [ 3.3712e-01,  5.4971e-02, -3.1865e-02, -1.4112e-01,  2.6534e-01,\n",
       "                       -1.6012e-01, -6.3488e-02, -1.7064e-01,  5.6258e-02, -8.4210e-02,\n",
       "                        3.5592e-01, -2.4457e-01, -2.3305e-01,  1.6101e-01,  3.0995e-01,\n",
       "                       -9.1309e-02, -1.5912e-01, -9.6672e-02, -1.8037e-02,  1.6804e-03,\n",
       "                       -1.8420e-01, -2.5434e-02, -2.7436e-02,  3.6621e-01,  1.2936e-01,\n",
       "                        2.8695e-01, -1.7291e-01,  4.2551e-01, -6.9563e-02, -2.0412e-01,\n",
       "                        3.7573e-01,  1.9558e-02,  4.4477e-01,  8.1929e-03,  1.0970e-01,\n",
       "                        1.2623e-01,  1.2189e-01, -2.8772e-01, -4.9433e-01, -1.0798e-01,\n",
       "                        1.7447e-01, -3.8738e-03,  9.2215e-02,  7.1396e-02, -1.9983e-01,\n",
       "                        4.7872e-01, -2.1860e-01, -2.0344e-01,  2.7734e-01,  2.9627e-01,\n",
       "                        8.0855e-02, -5.1644e-02,  1.1226e-01,  1.8363e-01, -7.6591e-02,\n",
       "                       -4.7201e-02],\n",
       "                      [ 1.8938e-01, -2.7679e-01, -5.7003e-03, -2.2006e-02,  7.2762e-02,\n",
       "                        1.6570e-01, -3.9995e-02,  1.1245e-02, -7.2983e-02,  6.7427e-02,\n",
       "                        3.2342e-01,  4.0943e-02,  5.9916e-02, -1.3676e-01,  3.2423e-02,\n",
       "                        5.6778e-02,  2.3725e-02, -3.3124e-01,  1.4649e-01, -2.0082e-02,\n",
       "                        1.6834e-01, -1.4613e-01,  2.5032e-01, -3.3479e-01,  9.2911e-02,\n",
       "                       -5.0239e-02,  1.3712e-01,  2.0487e-01, -6.8020e-02, -4.8151e-03,\n",
       "                       -2.8975e-02,  2.0545e-01, -9.2440e-02,  4.6181e-02,  3.6338e-01,\n",
       "                       -4.2025e-02,  2.1342e-01, -1.5759e-01, -2.4939e-01, -2.4504e-01,\n",
       "                        9.9450e-02, -1.1798e-01,  2.6977e-01,  8.3672e-02, -2.3897e-01,\n",
       "                       -2.1235e-01,  1.1088e-01,  2.2091e-01,  6.5855e-02,  6.8953e-02,\n",
       "                       -5.5074e-03,  2.1698e-01, -2.1897e-01,  3.0961e-02, -1.0361e-01,\n",
       "                        1.0295e-01],\n",
       "                      [-1.0550e-01, -3.3416e-01,  2.1736e-01,  7.3238e-03, -1.4434e-01,\n",
       "                       -3.7975e-01, -9.6596e-02, -1.3331e-01,  8.3420e-02,  3.1335e-01,\n",
       "                        4.7838e-02, -1.4933e-01,  2.5538e-01, -1.3672e-02,  3.9421e-01,\n",
       "                        1.1541e-01,  2.8744e-02,  3.8080e-02, -1.1265e-01, -2.9378e-01,\n",
       "                        2.8555e-01, -2.7663e-01, -1.1130e-01,  5.0490e-03, -3.2833e-01,\n",
       "                        2.3011e-01, -1.9791e-01,  2.8508e-01, -2.6508e-01, -2.5307e-01,\n",
       "                       -4.0029e-01,  1.6181e-01, -1.8447e-01,  9.1935e-02, -1.3159e-01,\n",
       "                        3.6409e-01, -3.8448e-01, -1.5666e-01, -2.8299e-02,  2.4849e-01,\n",
       "                       -2.6653e-02,  1.5134e-01,  1.7482e-01,  3.0948e-01, -1.7570e-01,\n",
       "                       -1.6141e-01,  3.0105e-02, -7.7527e-02,  1.2228e-01, -3.5013e-01,\n",
       "                       -2.5812e-01,  8.5127e-02, -3.3711e-03,  1.1003e-01,  1.7974e-01,\n",
       "                       -3.5585e-01],\n",
       "                      [ 1.7043e-02,  3.7683e-01, -1.1433e-01,  8.5128e-02, -7.2956e-02,\n",
       "                        1.2391e-01, -1.4120e-01,  2.2122e-01, -2.0256e-01,  2.3734e-01,\n",
       "                       -4.1473e-02,  2.9477e-01, -9.9929e-03,  7.1674e-02,  1.8607e-01,\n",
       "                       -3.3478e-01,  3.8470e-02, -3.4210e-02, -1.7576e-01,  8.9306e-02,\n",
       "                       -1.9068e-01, -2.3860e-01, -3.3004e-02,  1.0364e-01,  3.9085e-02,\n",
       "                        2.2645e-02,  1.8161e-01, -2.2818e-01,  3.3988e-02, -3.7429e-01,\n",
       "                        1.2148e-01, -6.9869e-02,  4.2208e-01,  4.2056e-02, -1.7576e-01,\n",
       "                        6.0635e-02,  7.0192e-03,  3.2289e-02, -1.3734e-01, -7.2428e-01,\n",
       "                       -1.8004e-01, -6.8727e-02, -2.3584e-01, -1.7502e-02,  1.2347e-01,\n",
       "                        3.0936e-02,  2.5430e-01, -2.1132e-01, -8.9089e-02,  9.0319e-02,\n",
       "                        1.6081e-01,  6.9705e-02,  2.0074e-01,  3.3335e-01, -9.1429e-03,\n",
       "                        1.2262e-01]], device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.fc2.weight',\n",
       "              tensor([[-0.7433, -0.3793,  0.4975, -0.2268, -0.2577,  0.2552, -0.0957],\n",
       "                      [-0.1054,  0.3000, -0.9614, -0.3249, -0.3141, -0.1845, -0.3895],\n",
       "                      [-0.7995, -0.1894, -0.1440,  0.2410,  0.0219, -0.0371,  0.1382],\n",
       "                      [ 0.2553, -0.7959, -0.7943,  0.4701,  0.0391,  0.5328,  0.5472],\n",
       "                      [-0.6485,  0.5209,  0.2423,  0.6239, -0.1367,  0.3707, -0.2330],\n",
       "                      [-0.5251, -0.4844,  0.6733,  0.1851,  0.1146, -0.1428,  0.2461],\n",
       "                      [ 0.6303, -0.5402, -0.3315, -0.7777, -0.3152,  0.7978,  0.6119]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.0810, -0.4845,  0.3816,  0.0489,  0.0106, -0.5092, -0.1201],\n",
       "                      [-0.2594,  0.5235,  0.3806,  0.3987,  0.3661, -0.3313, -0.2296],\n",
       "                      [-0.2092, -0.2143,  0.4161,  0.1816,  0.4283, -0.0250, -0.4765],\n",
       "                      [-0.1551,  0.3757,  0.3254,  0.1655, -0.1568, -0.4989, -0.2872],\n",
       "                      [ 0.2787, -0.2156,  0.2557,  0.1459, -0.2053,  0.3256, -0.1718],\n",
       "                      [-0.0178, -0.2036, -0.5070,  0.0862,  0.1545, -0.2691,  0.3279],\n",
       "                      [-0.4795, -0.5153, -0.3301, -0.1847, -0.0594, -0.1033,  0.2439],\n",
       "                      [-0.4691,  0.0787,  0.0093,  0.1412,  0.5314,  0.3290, -0.2960],\n",
       "                      [-0.4380, -0.1294, -0.2681,  0.1867,  0.0049,  0.4299,  0.2100],\n",
       "                      [-0.0983,  0.0184,  0.1280, -0.0663,  0.4313, -0.4179,  0.2605],\n",
       "                      [-0.3407, -0.4683, -0.1097,  0.2605,  0.3777,  0.1341, -0.0462],\n",
       "                      [-0.0300, -0.2167, -0.0480, -0.0369,  0.4549,  0.3128, -0.4277],\n",
       "                      [ 0.0022, -0.3288, -0.0849, -0.4248,  0.1390, -0.3854,  0.5277],\n",
       "                      [ 0.4037, -0.3679, -0.5032,  0.0209, -0.1492,  0.1569, -0.3618]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.agency.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.agency.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.agency.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.sku.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.sku.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.sku.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_population_2017.fc1.weight',\n",
       "              tensor([[ 0.6665,  0.0632, -0.0789,  0.2892,  0.2592,  0.0532, -0.0354,  0.0934],\n",
       "                      [-0.4179, -0.3450,  0.2323,  0.4913,  0.2296,  0.1820,  0.1240, -0.2857],\n",
       "                      [ 0.6547, -0.0364,  0.5614, -0.1227,  0.2104,  0.6464, -0.0310, -0.0372],\n",
       "                      [-0.3408,  0.4269,  0.7839, -0.2999,  0.0661, -0.2277,  0.3550, -0.7159],\n",
       "                      [-0.2018, -0.2212, -0.6327,  0.7420,  0.8844,  0.6150,  0.1478,  0.4200],\n",
       "                      [-0.1154,  0.1979, -0.0679,  0.1246,  0.5577, -0.9345,  0.5448, -0.3312],\n",
       "                      [-0.2791,  0.1939, -1.1384,  0.1865, -0.4974, -0.6631, -0.7249,  0.0713],\n",
       "                      [-0.5717,  0.6697, -0.4984, -0.3011,  0.1609,  0.0661,  0.1734, -0.0408]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_population_2017.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_population_2017.fc2.weight',\n",
       "              tensor([[ 0.6725, -0.6327,  0.2256,  0.3299, -1.0062, -0.2581,  0.8674,  0.0160],\n",
       "                      [-0.5607,  0.1959, -0.2452, -0.1445, -0.3609,  0.9568, -0.1636,  0.2410],\n",
       "                      [ 0.5854,  0.0108, -0.4578,  0.1092, -0.2703, -0.4150,  0.0998, -0.0967],\n",
       "                      [-0.7305, -0.1013,  0.0157,  0.1455,  0.2970,  0.6714, -0.2578,  0.1601],\n",
       "                      [-0.3817, -0.0983, -0.1817, -0.7765, -0.0755, -0.2669,  0.2810, -1.3868],\n",
       "                      [-0.2726,  0.2627,  0.3473,  0.3653, -0.9261, -0.5949, -0.3291,  0.1976],\n",
       "                      [-1.1059, -0.2877,  0.2160,  0.4169, -0.0633, -0.0226,  0.0903,  0.2675],\n",
       "                      [-0.0328,  0.3055,  0.3324, -0.1250,  0.1081, -0.3061, -0.1273,  0.4963]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_population_2017.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_population_2017.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.3269, -0.1595, -0.3843, -0.2647, -0.0156, -0.4275, -0.4385,  0.3745],\n",
       "                      [ 0.0470, -0.2211, -0.0166,  0.3708, -0.4171, -0.2651, -0.3616, -0.0364],\n",
       "                      [-0.0172, -0.3897,  0.3470, -0.3840,  0.4668, -0.3442, -0.0685,  0.0935],\n",
       "                      [-0.2222,  0.4598, -0.3447, -0.0277, -0.3671,  0.1388,  0.4263,  0.4638],\n",
       "                      [ 0.0594, -0.2503,  0.4859,  0.0373,  0.3383, -0.2597, -0.2320, -0.4151],\n",
       "                      [ 0.4601,  0.0829, -0.3591,  0.0429, -0.2145,  0.0250,  0.1660, -0.2481],\n",
       "                      [ 0.0872, -0.3157,  0.0963, -0.4828,  0.0797,  0.4968,  0.4606,  0.1824],\n",
       "                      [ 0.3679,  0.4861,  0.1417,  0.1668,  0.0650,  0.4427,  0.4295, -0.2351],\n",
       "                      [-0.0206, -0.2519,  0.1794, -0.4845,  0.1769, -0.1372,  0.1813,  0.1561],\n",
       "                      [-0.2488,  0.2594,  0.2123, -0.4250,  0.4989,  0.4304,  0.3111, -0.0507],\n",
       "                      [ 0.1771, -0.2705, -0.1699,  0.2360,  0.2226,  0.1980, -0.4769,  0.4143],\n",
       "                      [-0.2088,  0.4327,  0.4120,  0.1853,  0.4981,  0.2871,  0.2932, -0.1698],\n",
       "                      [ 0.4637,  0.1310,  0.2954, -0.1131,  0.3621,  0.4436, -0.3831,  0.4099],\n",
       "                      [-0.3304, -0.3442, -0.4178,  0.1445, -0.3754, -0.1882, -0.2513,  0.1336],\n",
       "                      [-0.4909, -0.2292,  0.0037,  0.0449, -0.2258,  0.1791, -0.3299, -0.4234],\n",
       "                      [-0.0711, -0.2703,  0.3152, -0.3418, -0.0420,  0.2077, -0.4379,  0.3871]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_population_2017.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_population_2017.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_population_2017.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_yearly_household_income_2017.fc1.weight',\n",
       "              tensor([[ 0.1623,  0.7468,  0.2927,  0.3800,  0.8936, -0.6838, -0.4013,  0.2287],\n",
       "                      [ 0.2425, -0.5178,  0.0810, -0.1728, -0.6494, -0.1348,  0.1033, -0.1920],\n",
       "                      [ 0.0487,  0.3978, -1.0804, -0.2847, -0.6036,  0.3927,  0.0412,  0.8208],\n",
       "                      [ 0.7969,  1.2819, -0.0634,  0.1157,  0.6799,  0.7371, -0.2768, -0.0076],\n",
       "                      [-0.4354,  0.0181,  0.5495, -0.1400, -0.2184, -0.3890,  0.6091, -0.0766],\n",
       "                      [ 0.2386,  0.2978,  0.1396,  0.1197,  0.0404,  0.2270, -0.6859, -0.2373],\n",
       "                      [-0.9078,  0.5565,  0.5858, -0.8590, -0.2673, -0.6531, -0.4623,  0.3107],\n",
       "                      [ 0.0983,  0.5343,  0.2425,  0.0030, -0.1685,  0.5256, -0.6755,  0.2705]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_yearly_household_income_2017.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_yearly_household_income_2017.fc2.weight',\n",
       "              tensor([[-0.3283, -0.4339, -0.0522,  0.4878, -0.5014,  0.6403,  0.6065,  0.0606],\n",
       "                      [-0.1405,  0.8627,  0.0635, -0.4405,  0.9109,  0.7932,  0.4328, -0.1383],\n",
       "                      [ 0.4326,  0.4912,  0.3620,  0.0665, -0.5271, -1.1563, -0.4514, -0.7093],\n",
       "                      [ 0.4291,  1.5176, -0.5744,  0.1135, -0.4592,  0.4923, -0.7918, -0.1479],\n",
       "                      [-0.1234, -0.3399, -0.5049, -0.1941, -0.7537, -0.3712,  0.2279, -0.2382],\n",
       "                      [ 0.2196, -0.2516,  1.0584,  0.6095,  0.3636,  0.0673,  1.0387, -0.4392],\n",
       "                      [ 0.0791, -0.8715, -0.6469,  0.6537, -0.4385, -0.0079,  0.8044, -0.2149],\n",
       "                      [-0.0388, -0.2507, -1.1135, -0.0863, -0.2221,  0.1463,  0.1289, -1.0752]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_yearly_household_income_2017.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_yearly_household_income_2017.gate_norm.glu.fc.weight',\n",
       "              tensor([[-4.7596e-01,  4.5148e-01,  3.7905e-01,  4.9188e-01,  2.7250e-01,\n",
       "                       -2.4306e-01,  3.7931e-01,  4.5696e-01],\n",
       "                      [-1.9118e-01, -8.1730e-02,  3.9127e-01,  4.0249e-01,  3.3029e-01,\n",
       "                        3.8307e-01, -2.5695e-01, -8.6258e-02],\n",
       "                      [-1.9975e-01,  2.5987e-01,  1.2461e-01, -3.8623e-01, -6.2806e-02,\n",
       "                       -4.0773e-01, -4.7056e-01,  4.5581e-01],\n",
       "                      [-2.5151e-01,  2.2316e-01, -1.1134e-01, -1.0125e-01, -3.2294e-04,\n",
       "                        3.8996e-01, -6.9168e-02,  4.1373e-01],\n",
       "                      [ 2.9255e-01,  3.4300e-01, -4.5347e-01, -2.3380e-01, -4.0736e-01,\n",
       "                       -1.0619e-01, -1.0356e-01,  1.0160e-01],\n",
       "                      [ 4.4799e-01,  2.2445e-01, -3.4793e-01, -3.1357e-01,  3.7755e-01,\n",
       "                        4.9772e-02,  1.4125e-01, -2.6152e-01],\n",
       "                      [-6.0975e-02,  1.4235e-01, -3.2811e-01,  3.2633e-01,  2.4917e-01,\n",
       "                       -2.9159e-01, -2.0504e-01, -1.1755e-01],\n",
       "                      [ 7.7813e-02, -1.8341e-01,  4.7831e-01, -4.8160e-01, -2.8260e-01,\n",
       "                       -3.0349e-01,  1.3519e-01,  7.0953e-02],\n",
       "                      [-1.4248e-01,  4.2673e-01, -4.3163e-01,  1.7623e-01, -2.7513e-01,\n",
       "                       -1.1385e-01, -4.8150e-01, -3.7325e-01],\n",
       "                      [-4.2422e-01,  2.1814e-01, -1.8775e-01,  2.6155e-01, -2.7097e-01,\n",
       "                       -1.2388e-01,  6.0524e-02,  4.1896e-01],\n",
       "                      [-1.3476e-01,  2.8986e-01,  1.3794e-01,  3.0410e-01,  3.1585e-01,\n",
       "                        2.0291e-01, -1.5077e-01, -1.4033e-01],\n",
       "                      [ 1.9465e-01,  2.7252e-01, -2.6687e-02,  2.5064e-01, -3.0081e-01,\n",
       "                        2.8183e-01, -6.1357e-02, -3.4409e-01],\n",
       "                      [-2.4294e-01, -3.8185e-01,  1.0086e-01, -2.9653e-01, -1.4318e-01,\n",
       "                       -3.1327e-02, -3.0508e-01,  1.2839e-02],\n",
       "                      [-6.3456e-02,  1.5837e-01,  3.6120e-01, -3.0183e-01,  2.7337e-01,\n",
       "                       -1.0593e-02, -2.8578e-01, -2.2676e-01],\n",
       "                      [ 1.2727e-01,  1.0411e-01, -1.6150e-02, -2.4892e-01,  2.5215e-01,\n",
       "                        7.4185e-02, -4.8607e-01, -8.8363e-02],\n",
       "                      [-1.3566e-01, -2.1335e-01, -2.7735e-01, -4.0563e-01,  4.9245e-01,\n",
       "                       -4.5671e-01,  4.6479e-01, -3.9305e-01]], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_yearly_household_income_2017.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_yearly_household_income_2017.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.avg_yearly_household_income_2017.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.encoder_length.fc1.weight',\n",
       "              tensor([[ 0.2629, -0.0443,  0.0418, -0.2754, -0.9494, -0.0096,  0.1465,  0.1217],\n",
       "                      [-0.1002, -0.6121, -0.0833, -0.3185, -0.2149,  0.4078,  0.8925,  0.1831],\n",
       "                      [ 1.0718, -0.4234,  0.5024,  0.0497,  0.5659, -0.3895, -0.0035,  0.5185],\n",
       "                      [ 0.2708,  0.1354,  0.3263, -0.1128,  0.4272, -0.2195, -0.2296,  0.3792],\n",
       "                      [ 0.7787,  1.0189, -0.0566, -0.5033, -0.3116,  0.5304,  0.5890,  0.1651],\n",
       "                      [ 0.5113,  0.3879,  0.3230,  0.3702,  0.6558, -0.9726,  0.8716,  0.1215],\n",
       "                      [ 0.0202,  0.1777,  0.9691, -0.6275,  0.0730,  0.1307,  0.2485,  0.4270],\n",
       "                      [-0.2395, -0.2882, -1.1620, -0.1427,  0.5105,  0.4480, -0.0220,  0.1349]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.encoder_length.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.encoder_length.fc2.weight',\n",
       "              tensor([[-0.6563, -0.3878, -0.0473, -0.5858,  0.2528,  0.1884,  0.6369, -0.2635],\n",
       "                      [ 0.2258, -0.3887, -1.2896,  0.6664,  0.4124,  0.0948,  0.1066, -0.1096],\n",
       "                      [ 0.2131,  0.0612,  0.2787,  0.1523,  0.2635,  0.7238,  0.5728,  0.1587],\n",
       "                      [ 0.2519,  0.6011,  0.2738, -0.2549, -0.9154, -0.4898,  0.7899,  1.3862],\n",
       "                      [-1.3864,  0.2180,  0.0623,  0.7590,  0.1244, -0.4667,  0.5096,  0.0366],\n",
       "                      [ 0.5163,  0.0824, -0.2958, -0.0073,  0.1305,  0.0652,  0.6029,  1.0957],\n",
       "                      [ 0.0386,  0.8025,  0.6343,  0.0954,  0.3212,  0.2616,  0.1769,  0.0738],\n",
       "                      [ 0.7418, -0.1318,  0.4594,  0.0751, -0.3673,  0.7456, -0.5205,  0.4544]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.encoder_length.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.0972,  0.3346,  0.3127, -0.4046, -0.3710, -0.1835, -0.3597,  0.1568],\n",
       "                      [-0.3276, -0.3817,  0.1456,  0.3018, -0.1454, -0.4982,  0.0707,  0.2562],\n",
       "                      [ 0.3906,  0.0474,  0.3471, -0.4471,  0.4783, -0.3229, -0.3413,  0.3588],\n",
       "                      [-0.1111,  0.3086, -0.3502,  0.3783,  0.4742,  0.1514,  0.4033, -0.3571],\n",
       "                      [-0.1104,  0.1522,  0.2825, -0.2670,  0.3182, -0.1646, -0.2669,  0.0978],\n",
       "                      [-0.3983, -0.4589,  0.1663,  0.1703,  0.1923, -0.0656, -0.3657, -0.4017],\n",
       "                      [ 0.4784, -0.4335,  0.1507,  0.4061,  0.3820, -0.3153, -0.1612, -0.3998],\n",
       "                      [ 0.3136, -0.4692, -0.4603, -0.3338,  0.4078,  0.3241,  0.3350,  0.3836],\n",
       "                      [-0.2332, -0.2788, -0.3072,  0.1650,  0.1945,  0.1038, -0.3847,  0.0444],\n",
       "                      [-0.2653, -0.0983, -0.0774,  0.0249, -0.4384,  0.4268, -0.2128,  0.1562],\n",
       "                      [ 0.3443,  0.2015,  0.3502,  0.2823,  0.3661,  0.1055,  0.3193, -0.2173],\n",
       "                      [-0.2694,  0.2388,  0.1312, -0.0187, -0.4218,  0.1634,  0.3239, -0.0577],\n",
       "                      [ 0.1149,  0.2226, -0.4938, -0.0823, -0.1855, -0.2556,  0.3056,  0.4957],\n",
       "                      [ 0.0798,  0.3112, -0.3709,  0.0881, -0.0647, -0.3084,  0.1025,  0.1592],\n",
       "                      [-0.0241,  0.2123,  0.2401,  0.4535,  0.0290,  0.0178, -0.0072,  0.0690],\n",
       "                      [-0.3242, -0.0615, -0.4228, -0.3507, -0.4259,  0.3708, -0.2873, -0.0404]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.encoder_length.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.encoder_length.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_center.fc1.weight',\n",
       "              tensor([[-0.2094, -0.4080,  0.0085, -0.5921,  0.1374,  0.7158, -0.4505, -0.4729],\n",
       "                      [ 0.6486, -1.0030,  0.1412, -0.4056, -0.0756,  0.7131,  0.5634, -0.4265],\n",
       "                      [ 0.3075, -0.1017, -0.8310,  0.4403,  0.1704, -0.4803, -0.4102,  0.5640],\n",
       "                      [-0.5893, -0.5858,  0.8001, -0.1928,  0.6832, -0.7024, -0.2996, -0.7472],\n",
       "                      [-0.0501,  0.6255, -0.0550, -0.7027,  0.0782,  0.2392,  0.2813, -0.6664],\n",
       "                      [-0.2115, -0.2260, -0.3408, -0.4799, -0.7422,  0.0408, -0.4869,  0.2580],\n",
       "                      [-0.3665,  0.7174,  0.0090, -0.0423,  0.0166,  0.6920, -0.3705, -0.4218],\n",
       "                      [-0.7935,  0.0245,  0.5664, -0.9764, -0.3415,  0.1826, -0.7055, -0.1283]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_center.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_center.fc2.weight',\n",
       "              tensor([[-0.6597, -0.0356,  0.1343, -0.3495,  0.2010,  0.4257,  0.1267,  0.8275],\n",
       "                      [ 1.3339, -0.0702,  0.4708, -0.0059,  0.2618, -0.2995, -0.0679, -0.6533],\n",
       "                      [-0.3687, -0.3843, -0.0256,  0.7993, -0.3092, -0.1035, -0.1940,  0.0406],\n",
       "                      [-0.2461,  0.8281,  0.2056, -0.1214,  0.4390, -0.1846,  0.1198, -0.1211],\n",
       "                      [-0.6718,  0.6339, -0.6469, -0.3707, -0.3749, -0.0399, -0.0776, -0.2147],\n",
       "                      [ 0.2693,  0.6681, -0.2819,  0.3317,  1.1324,  0.5573,  0.3255,  0.6977],\n",
       "                      [-0.0854,  1.3534,  0.3312, -0.3270, -0.2852, -0.2470, -0.0987,  0.1933],\n",
       "                      [-0.6253,  0.4545, -0.0789, -0.2195,  0.0934,  0.5167, -0.6109, -0.2189]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_center.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_center.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.0719, -0.1004,  0.0964, -0.3936,  0.0184,  0.2293, -0.4682, -0.2656],\n",
       "                      [ 0.3133,  0.0113, -0.0170,  0.0510, -0.2244,  0.4135, -0.0496, -0.1821],\n",
       "                      [ 0.2632, -0.4162, -0.0922,  0.0504, -0.1552,  0.2721, -0.4270, -0.1441],\n",
       "                      [-0.2101,  0.4627,  0.1995, -0.3730,  0.1938, -0.0106,  0.4577,  0.2759],\n",
       "                      [-0.2920,  0.4457, -0.0894, -0.1139,  0.1495,  0.4968,  0.1509, -0.4824],\n",
       "                      [-0.1596,  0.4656, -0.1762, -0.2405, -0.3985, -0.2760, -0.2734,  0.1194],\n",
       "                      [ 0.1998,  0.4772,  0.3281,  0.0074,  0.2696,  0.2858, -0.4313,  0.2523],\n",
       "                      [-0.3420,  0.3861, -0.2175,  0.1037, -0.0053,  0.2320,  0.0778, -0.3627],\n",
       "                      [ 0.2025,  0.2949, -0.2604, -0.3244, -0.3405, -0.2433, -0.0630,  0.0374],\n",
       "                      [-0.0035, -0.1322,  0.3103,  0.0264, -0.2903, -0.1323, -0.2940, -0.1764],\n",
       "                      [-0.4717,  0.0874, -0.3874,  0.1934,  0.3425, -0.3720, -0.2639, -0.3951],\n",
       "                      [ 0.1334,  0.0967, -0.2581,  0.3020,  0.2075, -0.4518, -0.0272, -0.2152],\n",
       "                      [-0.0867,  0.2784, -0.0538, -0.3473,  0.3517, -0.4570, -0.1717,  0.1927],\n",
       "                      [ 0.4419,  0.4853, -0.1175,  0.1668, -0.4391, -0.0973, -0.1555,  0.1419],\n",
       "                      [-0.3276,  0.1080,  0.2583,  0.3897, -0.0845,  0.4568, -0.4724, -0.1417],\n",
       "                      [ 0.1896,  0.1282,  0.2355, -0.3318,  0.3079, -0.4693, -0.3428, -0.0340]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_center.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_center.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_center.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_scale.fc1.weight',\n",
       "              tensor([[-0.2953, -0.3017,  0.3448,  0.3613, -0.7916, -0.1867,  0.3028, -0.0100],\n",
       "                      [-1.2253,  0.6504, -0.6785,  0.2006,  0.5562,  0.2117,  0.9527,  0.3598],\n",
       "                      [-0.3978, -0.3434,  0.9546, -0.2471,  1.3237, -0.1860, -0.3025,  0.5445],\n",
       "                      [ 0.2543, -0.5323, -0.2324, -0.4576,  0.7453,  0.3426,  0.2178,  0.1571],\n",
       "                      [ 0.0323, -1.0287,  0.5565, -0.3790, -0.5475,  0.2824, -0.3563,  1.0665],\n",
       "                      [ 0.7283, -0.5655,  0.6165,  0.4395, -0.1007,  0.2735, -0.4086,  0.5071],\n",
       "                      [ 0.3348,  0.6017,  0.4149, -0.4596, -0.1601,  0.1810,  0.0859, -0.3725],\n",
       "                      [-0.2515,  0.7614, -1.2511, -0.3126,  0.2265, -0.1188, -0.4789,  0.0411]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_scale.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_scale.fc2.weight',\n",
       "              tensor([[ 0.2955,  0.2603,  0.1315,  0.7313, -0.2600,  0.0298,  0.0200,  0.7589],\n",
       "                      [-0.0223, -0.3870,  0.7238, -0.9047,  0.3655, -0.4146, -0.0733,  0.4975],\n",
       "                      [ 0.1017, -0.3445, -0.2706,  1.0233,  0.9172, -1.0853,  0.4925, -0.1157],\n",
       "                      [ 0.6917, -0.6947,  0.1949, -0.7692, -0.5137, -0.2684,  0.3154, -0.3448],\n",
       "                      [-0.4385, -0.1917, -0.0295,  0.3803,  0.1877, -0.1648, -0.8450, -0.5595],\n",
       "                      [ 1.1317,  0.4447,  0.3678, -0.3112, -0.6234, -0.2047,  0.1199, -0.5589],\n",
       "                      [-1.4022,  0.2406,  0.1648,  0.7468,  0.3689, -0.3520,  0.1766, -0.4676],\n",
       "                      [-0.2319,  0.6921, -0.3422, -0.1828,  0.2082, -0.4530,  0.2585,  0.3369]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_scale.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_scale.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.4247,  0.4632, -0.1754, -0.4775,  0.4664, -0.2688,  0.4781, -0.3192],\n",
       "                      [ 0.0907,  0.1478, -0.1181,  0.3899, -0.4533, -0.2078, -0.0787,  0.3829],\n",
       "                      [ 0.2316,  0.3216,  0.2152,  0.4497, -0.1245, -0.1544, -0.0687,  0.1967],\n",
       "                      [-0.1466,  0.1836,  0.1371,  0.1176,  0.4074,  0.0796,  0.3318, -0.1394],\n",
       "                      [-0.4493,  0.3056,  0.2074,  0.4200,  0.1910,  0.0100, -0.3609, -0.4740],\n",
       "                      [ 0.1003,  0.4079, -0.0389, -0.1631,  0.2501, -0.2421,  0.1764, -0.4057],\n",
       "                      [-0.4531, -0.2917, -0.0856,  0.1686,  0.2530, -0.3165, -0.1027,  0.1646],\n",
       "                      [-0.1103,  0.0075,  0.3237, -0.1442,  0.2578,  0.4063,  0.1667, -0.0888],\n",
       "                      [-0.3166, -0.3305, -0.0972,  0.1563,  0.2735, -0.0241,  0.4029, -0.1980],\n",
       "                      [ 0.0997, -0.2560,  0.1344,  0.4267,  0.1752,  0.0335, -0.1840, -0.4102],\n",
       "                      [-0.3422, -0.4289,  0.3554, -0.2086, -0.0748, -0.4481, -0.1394,  0.4253],\n",
       "                      [ 0.0919, -0.0893,  0.2606,  0.3855,  0.3891, -0.3699,  0.0359, -0.4106],\n",
       "                      [-0.3447,  0.3839, -0.3984, -0.2452,  0.2398,  0.4865, -0.4857, -0.3226],\n",
       "                      [-0.1961,  0.3873,  0.2914,  0.3117,  0.3204, -0.1251,  0.3687, -0.0141],\n",
       "                      [ 0.0470, -0.1326,  0.2121,  0.2233, -0.0530,  0.4402, -0.1295,  0.1266],\n",
       "                      [ 0.4541,  0.2817, -0.1821, -0.2265,  0.0965, -0.0038,  0.0352,  0.3221]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_scale.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_scale.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_variable_selection.single_variable_grns.volume_scale.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.avg_population_2017.weight',\n",
       "              tensor([[ 0.3588],\n",
       "                      [-0.3940],\n",
       "                      [-0.9364],\n",
       "                      [ 0.3622],\n",
       "                      [-0.4955],\n",
       "                      [ 0.5089],\n",
       "                      [ 0.6685],\n",
       "                      [ 0.3857]], device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.avg_population_2017.bias',\n",
       "              tensor([ 0.9383,  0.9498,  0.2117, -0.7286,  0.8934, -0.4745, -0.4724,  0.8368],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.avg_yearly_household_income_2017.weight',\n",
       "              tensor([[ 0.7748],\n",
       "                      [ 0.3022],\n",
       "                      [ 0.0627],\n",
       "                      [-0.8412],\n",
       "                      [-0.1038],\n",
       "                      [ 0.9591],\n",
       "                      [ 0.2547],\n",
       "                      [ 0.0856]], device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.avg_yearly_household_income_2017.bias',\n",
       "              tensor([-0.2077, -0.3488,  0.5960,  0.0617,  0.6506, -0.1770,  0.4369,  0.4128],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.encoder_length.weight',\n",
       "              tensor([[ 0.1595],\n",
       "                      [ 0.6284],\n",
       "                      [ 0.6266],\n",
       "                      [ 0.9269],\n",
       "                      [ 0.7688],\n",
       "                      [-0.2557],\n",
       "                      [-0.8466],\n",
       "                      [ 0.1828]], device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.encoder_length.bias',\n",
       "              tensor([-0.0087, -0.2608, -0.1675,  0.0470,  0.7296,  0.3117, -0.3551, -0.4112],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.volume_center.weight',\n",
       "              tensor([[-0.2476],\n",
       "                      [-0.3865],\n",
       "                      [ 0.8992],\n",
       "                      [ 0.5296],\n",
       "                      [ 0.9030],\n",
       "                      [ 0.0032],\n",
       "                      [ 0.2017],\n",
       "                      [ 0.3468]], device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.volume_center.bias',\n",
       "              tensor([-0.9466,  0.0893, -0.0669, -0.5607, -0.7759,  0.8853,  0.8131,  0.4635],\n",
       "                     device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.volume_scale.weight',\n",
       "              tensor([[ 0.9542],\n",
       "                      [-0.4058],\n",
       "                      [-0.1727],\n",
       "                      [ 0.3786],\n",
       "                      [-0.1652],\n",
       "                      [-0.1962],\n",
       "                      [-0.8266],\n",
       "                      [ 0.2687]], device='cuda:0')),\n",
       "             ('static_variable_selection.prescalers.volume_scale.bias',\n",
       "              tensor([-0.6043,  0.0364,  0.9750, -0.3078, -0.3152,  0.6033, -0.3677, -0.0859],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.resample_norm.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.resample_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.resample_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.fc1.weight',\n",
       "              tensor([[ 1.2778e-01,  8.4578e-02, -2.0048e-01, -7.9199e-03,  1.9519e-01,\n",
       "                       -1.7903e-01, -1.5849e-01, -6.8596e-02,  2.0801e-01, -6.1757e-02,\n",
       "                       -1.6618e-01,  3.5227e-02, -2.2673e-02,  1.3773e-01,  1.0405e-01,\n",
       "                       -7.1859e-02,  2.2057e-01,  2.8458e-02,  1.2919e-01, -1.0634e-01,\n",
       "                       -1.0861e-01, -1.0746e-01,  1.6056e-01,  1.6318e-01,  2.2485e-01,\n",
       "                       -1.1040e-01, -1.0601e-01,  3.9802e-02,  3.1398e-02, -1.0519e-01,\n",
       "                        4.3643e-02, -1.7841e-01, -1.1520e-01,  1.3077e-01, -2.1962e-01,\n",
       "                        1.9719e-02,  2.3247e-02,  4.1242e-02,  2.3624e-02,  2.7581e-02,\n",
       "                        8.9482e-02,  1.1075e-01,  7.2101e-02,  2.2108e-01, -1.0943e-01,\n",
       "                       -6.3213e-02, -1.2413e-02,  5.1795e-02, -7.5404e-02, -3.7683e-02,\n",
       "                        5.5614e-02,  6.4237e-02,  3.1008e-02,  6.4589e-02, -7.5632e-02,\n",
       "                       -5.8101e-02,  2.6093e-02,  2.0820e-01,  1.2808e-01, -2.8358e-01,\n",
       "                       -2.6938e-02, -3.5837e-01, -3.0513e-02,  2.8215e-02,  7.8003e-02,\n",
       "                        2.3281e-01,  3.1955e-02,  3.8690e-02, -3.2093e-01,  7.6959e-02,\n",
       "                       -2.6723e-01,  1.2306e-01, -6.4997e-02,  3.0973e-01, -9.6503e-02,\n",
       "                       -3.2354e-02,  1.4105e-02, -1.3675e-01, -2.9915e-02,  3.3425e-02,\n",
       "                       -2.3460e-03,  6.6881e-02,  1.4820e-01,  4.5405e-02,  2.6090e-02,\n",
       "                       -1.0024e-01,  1.1499e-01,  1.0335e-02,  2.2534e-01,  1.5707e-02,\n",
       "                        8.3906e-02,  3.3120e-04,  1.0709e-01,  8.5119e-02, -3.7014e-02,\n",
       "                        1.3899e-02,  6.8999e-02,  6.3900e-03,  2.8241e-01, -9.8362e-02],\n",
       "                      [-1.2885e-01, -1.0296e-01, -1.1972e-02,  7.9679e-02, -1.8509e-02,\n",
       "                       -6.2147e-02,  2.4008e-01,  1.1505e-01, -4.1063e-02, -2.2116e-01,\n",
       "                        9.4931e-02, -1.0953e-01,  1.5987e-01, -3.3384e-02, -1.9939e-01,\n",
       "                        4.8038e-03, -1.5786e-01,  1.3061e-03, -1.2396e-01,  1.3893e-01,\n",
       "                        5.2907e-02,  4.1098e-02, -2.1114e-02,  2.3792e-02, -7.5446e-02,\n",
       "                       -1.4776e-02, -4.8189e-02,  8.0578e-03, -1.6386e-01, -1.0580e-01,\n",
       "                        1.5729e-01, -6.2530e-02, -8.1508e-02, -1.4106e-01, -4.0859e-02,\n",
       "                       -8.0166e-02,  2.7396e-02,  3.4024e-02,  1.2809e-01,  1.5870e-02,\n",
       "                        7.2257e-03, -8.0764e-02, -2.4584e-01, -1.0876e-01,  2.2953e-01,\n",
       "                        1.3217e-01,  9.6231e-02,  3.1632e-01,  1.7884e-02,  1.7981e-01,\n",
       "                        2.6958e-01, -2.2886e-01, -8.7579e-02, -5.7246e-02,  6.4054e-02,\n",
       "                        5.7906e-02,  3.0208e-01, -1.6405e-01, -8.4862e-02, -4.7571e-02,\n",
       "                       -1.4304e-02,  1.4025e-02,  5.3946e-02,  2.3650e-01,  1.6550e-01,\n",
       "                       -6.9807e-02, -3.8254e-01,  3.5909e-02,  7.3350e-02,  1.1009e-01,\n",
       "                       -2.2499e-01,  2.8112e-01, -9.4592e-02,  5.1345e-02,  1.6367e-02,\n",
       "                        3.3259e-01,  2.9692e-03, -1.0109e-01, -3.0855e-02,  9.2570e-02,\n",
       "                        7.2971e-02,  1.8196e-01, -7.6073e-02,  3.9832e-02,  1.4821e-02,\n",
       "                        1.6663e-01, -1.2076e-01,  2.6448e-02, -2.9361e-01, -5.3103e-02,\n",
       "                       -1.1152e-01,  8.9188e-04,  1.2533e-01, -1.0305e-01,  1.9521e-01,\n",
       "                        9.4529e-02, -2.2922e-01, -1.3350e-01, -5.0710e-02,  2.0366e-01],\n",
       "                      [ 1.3271e-01, -5.9542e-02, -6.9507e-02, -1.3161e-01, -4.5404e-02,\n",
       "                        8.2303e-02, -1.8196e-01,  8.1101e-02, -8.0639e-02, -7.6293e-03,\n",
       "                       -1.0333e-01, -1.4632e-01,  6.6703e-02, -4.4772e-02, -1.7621e-01,\n",
       "                       -3.5536e-03,  1.0340e-01,  3.2936e-01, -1.5019e-01, -7.6165e-02,\n",
       "                        7.2511e-03, -7.5735e-02,  5.1289e-02,  7.2732e-02,  2.2746e-01,\n",
       "                        8.2919e-02,  2.2287e-02, -1.3899e-01,  8.0791e-02, -9.8773e-02,\n",
       "                       -4.1303e-02,  9.9031e-02, -1.7135e-01,  2.4853e-02,  3.6062e-02,\n",
       "                        1.1413e-01,  6.2095e-02, -6.5857e-02,  2.9755e-02, -9.5080e-02,\n",
       "                       -7.2892e-03, -1.2755e-02,  1.3556e-01, -1.7360e-01, -1.2711e-01,\n",
       "                       -2.9952e-01,  6.5983e-02, -8.9941e-02, -8.3867e-03, -1.7007e-01,\n",
       "                       -1.8059e-01, -5.6121e-02, -4.3983e-02,  2.2162e-01,  1.9810e-02,\n",
       "                       -3.5610e-01, -2.8684e-01, -1.4532e-01,  1.3805e-01, -9.5370e-03,\n",
       "                        2.1576e-02, -7.9908e-02,  1.8511e-02, -1.0950e-03,  2.3784e-02,\n",
       "                       -1.6813e-01, -5.3564e-02, -4.5418e-02,  1.6311e-01, -1.8272e-01,\n",
       "                       -6.5252e-02, -3.2203e-01, -1.1413e-02, -4.2867e-02,  4.5828e-02,\n",
       "                        1.4710e-01,  6.1554e-02,  1.7774e-02,  3.6686e-01, -2.5198e-02,\n",
       "                        1.1041e-01,  1.7370e-01,  6.2985e-02, -4.2765e-02,  5.3434e-02,\n",
       "                        2.4764e-01,  2.1582e-01,  2.6264e-04,  5.2934e-02, -5.3620e-02,\n",
       "                        3.7479e-01, -2.2672e-01,  2.7722e-02,  5.7871e-02,  4.9871e-02,\n",
       "                       -9.3239e-03,  5.2575e-02, -6.5203e-02,  3.0756e-01,  3.0992e-03],\n",
       "                      [ 2.2145e-01,  2.7163e-01,  1.8118e-01,  1.8634e-01,  1.0815e-03,\n",
       "                       -3.5573e-02,  1.1934e-01, -3.7072e-02,  8.9276e-02,  2.5910e-02,\n",
       "                       -8.2215e-03, -2.7759e-03,  9.5167e-02, -9.4924e-02, -3.2527e-02,\n",
       "                        1.9744e-02, -2.9021e-01,  2.0841e-01,  6.2769e-03,  1.4701e-03,\n",
       "                       -1.9898e-02,  1.1549e-01,  1.5258e-01,  2.4399e-01, -3.2010e-02,\n",
       "                       -6.8941e-04, -1.2119e-01, -1.0235e-02, -1.1654e-02,  1.2082e-01,\n",
       "                       -1.2939e-01,  7.6203e-02,  6.1461e-02, -1.3114e-01,  1.2073e-01,\n",
       "                        1.7918e-01, -5.3143e-04, -3.3549e-02,  2.4804e-02, -4.8319e-02,\n",
       "                       -1.6226e-01, -3.2226e-03, -7.0962e-02, -2.6457e-01,  1.6428e-02,\n",
       "                        2.7071e-01, -1.6193e-01,  2.2756e-01, -9.1371e-02,  7.3998e-02,\n",
       "                       -1.0289e-01, -8.7551e-02, -9.1721e-03, -1.4754e-03,  1.7090e-01,\n",
       "                       -1.2743e-01,  1.0706e-01,  1.0968e-01,  1.0531e-01,  7.8879e-02,\n",
       "                        6.5339e-02, -7.1735e-02, -1.2983e-01,  1.2509e-02,  2.1911e-01,\n",
       "                       -1.3354e-01, -6.9790e-02, -1.2283e-01, -1.2056e-01, -2.7211e-02,\n",
       "                        6.6556e-02, -1.0006e-01,  6.4889e-03, -1.5170e-01, -9.9289e-02,\n",
       "                       -8.6088e-02, -1.1168e-01, -1.9563e-01, -1.5932e-01,  6.9539e-02,\n",
       "                       -1.2444e-02,  1.0025e-02,  2.0132e-01,  2.3523e-01, -5.3510e-02,\n",
       "                       -3.2475e-02, -1.6733e-01, -1.4634e-01, -1.5023e-01, -1.5622e-01,\n",
       "                       -1.1962e-01,  7.3355e-02,  8.0589e-02, -6.1868e-02, -1.0067e-01,\n",
       "                        3.3078e-01, -1.0625e-01,  9.5542e-02,  2.5995e-02, -9.5144e-02],\n",
       "                      [ 7.8071e-02,  3.6557e-01,  5.9618e-02,  3.6188e-01, -1.3399e-01,\n",
       "                       -7.3667e-02, -1.0766e-01, -1.3355e-01,  8.7737e-02,  4.7376e-02,\n",
       "                       -8.1974e-02, -3.4172e-02, -1.6916e-01,  2.0696e-01, -8.8853e-02,\n",
       "                        1.5786e-02, -2.8484e-02,  7.1133e-03,  2.1007e-01,  1.2460e-01,\n",
       "                       -4.5427e-02, -9.3504e-02,  1.6046e-01,  9.9706e-02,  4.4685e-02,\n",
       "                       -6.4376e-02, -2.5647e-02, -4.4199e-02, -1.3087e-01, -1.0478e-02,\n",
       "                       -1.5888e-01, -3.7983e-02,  2.1768e-01, -1.1968e-01, -1.9435e-01,\n",
       "                       -4.2335e-02,  2.5781e-01,  9.2161e-02, -1.3240e-02, -9.3367e-02,\n",
       "                        6.4634e-02,  1.6531e-01, -3.1478e-02,  1.7386e-01,  6.6474e-02,\n",
       "                        1.8037e-01, -5.5603e-02,  2.1006e-02, -5.4489e-02, -7.1238e-02,\n",
       "                        1.4130e-01, -1.0125e-01,  6.1053e-02, -6.0129e-02,  2.8935e-02,\n",
       "                        3.5919e-05,  1.3622e-01, -1.7238e-01, -9.7999e-03,  8.6299e-03,\n",
       "                       -9.4295e-02, -1.0215e-01,  2.1520e-02,  3.9831e-02,  3.8053e-02,\n",
       "                       -2.2823e-02,  1.6618e-01,  7.5678e-02,  6.0029e-02, -5.0162e-02,\n",
       "                       -2.9953e-02,  2.8552e-01, -1.2876e-01,  5.6206e-02, -7.8399e-02,\n",
       "                        1.8124e-01, -3.2685e-02,  1.3255e-01, -3.9166e-02, -4.0653e-01,\n",
       "                       -1.0676e-02, -7.3643e-02, -1.4826e-01,  1.1914e-01, -1.6812e-01,\n",
       "                        4.6380e-02,  4.1142e-02, -7.3260e-02,  2.2951e-01,  1.8276e-01,\n",
       "                       -3.7145e-02, -1.1759e-01, -2.7638e-01,  1.1943e-01, -1.2163e-01,\n",
       "                        1.6682e-01,  1.1054e-01,  1.9672e-02, -2.4522e-01,  1.0453e-01],\n",
       "                      [-1.0977e-01, -1.1150e-01, -5.1762e-02,  7.9112e-03, -1.6564e-01,\n",
       "                        1.7253e-01, -1.3301e-01,  9.3463e-02,  4.5134e-02,  8.9597e-02,\n",
       "                        1.5941e-01, -1.1046e-01,  7.9588e-03, -3.4014e-02,  1.2954e-01,\n",
       "                        1.0392e-01, -1.1400e-01, -2.0952e-01, -2.0482e-01,  1.4844e-01,\n",
       "                       -4.6238e-02,  1.7607e-01,  8.5834e-02, -1.3261e-02,  2.7363e-01,\n",
       "                       -1.5282e-01, -1.2868e-02, -8.0476e-02, -3.7508e-01, -6.1211e-02,\n",
       "                        1.3183e-01,  6.1506e-02, -2.3918e-01, -3.8930e-01,  1.1330e-01,\n",
       "                       -5.2052e-02,  3.1066e-01,  5.8304e-02, -9.9610e-02,  1.3926e-02,\n",
       "                        1.0975e-01,  5.0157e-03,  4.4050e-02, -1.8170e-01,  2.3584e-01,\n",
       "                        2.0908e-03, -1.8741e-01, -1.1803e-01,  1.3729e-01, -3.3565e-03,\n",
       "                        5.9113e-02, -9.6943e-02, -1.2679e-01,  6.5845e-02, -1.1034e-01,\n",
       "                       -1.0624e-01, -3.4553e-01, -3.4034e-02, -3.1599e-01,  7.5443e-02,\n",
       "                        9.5329e-03, -1.6647e-01, -3.2800e-01,  1.5389e-01, -8.8909e-02,\n",
       "                        2.7199e-01,  8.3307e-02,  1.1959e-01, -6.5729e-02,  2.1936e-02,\n",
       "                       -1.3197e-01,  2.9008e-01,  3.6223e-02, -1.8042e-02, -2.1138e-01,\n",
       "                        8.2284e-02,  1.5714e-01,  1.5799e-01, -1.1267e-01,  1.4467e-01,\n",
       "                        1.4409e-01, -1.0736e-01, -2.1787e-01, -3.8000e-02,  2.8815e-02,\n",
       "                       -2.0808e-01,  2.7970e-02, -4.5577e-02, -1.8599e-01,  2.9936e-01,\n",
       "                       -2.7456e-01, -6.7325e-02, -5.6418e-02, -2.8973e-01, -1.6084e-01,\n",
       "                        1.2793e-01,  2.0073e-02,  1.8623e-01,  4.0514e-03, -1.3106e-02],\n",
       "                      [ 1.1093e-01,  1.8782e-01, -7.2674e-02, -6.8342e-03,  3.6982e-02,\n",
       "                        2.3977e-01, -1.2326e-02,  2.9126e-01, -6.1769e-02,  4.8691e-02,\n",
       "                       -7.5168e-02, -2.5285e-01,  1.1378e-01, -2.8906e-01, -2.2513e-01,\n",
       "                       -1.0889e-01,  1.0666e-01, -2.4469e-01, -9.0577e-02, -3.4483e-03,\n",
       "                       -4.0096e-02,  5.3111e-02, -4.4705e-01,  1.4773e-01,  7.5999e-02,\n",
       "                       -6.8483e-02, -1.6451e-01,  4.6326e-02,  8.6762e-02, -2.5629e-01,\n",
       "                        8.1091e-02, -1.5543e-01, -1.2362e-01, -1.4612e-01, -5.8722e-02,\n",
       "                        2.2041e-01,  2.7632e-01, -4.0370e-03,  8.4302e-02, -3.0697e-01,\n",
       "                       -3.6532e-02,  3.9802e-02, -7.2963e-02,  2.1524e-01, -2.9232e-01,\n",
       "                       -1.6494e-02,  8.7582e-02,  1.7408e-01,  2.3549e-02,  2.5346e-02,\n",
       "                       -8.6965e-02,  1.2514e-01, -5.8227e-02, -5.5243e-02, -2.1784e-02,\n",
       "                        8.6343e-02, -6.0032e-02,  8.8669e-02, -9.1055e-02,  4.3273e-01,\n",
       "                        8.3502e-02,  1.2291e-01,  1.1703e-01,  2.4730e-02,  2.8116e-01,\n",
       "                       -1.6080e-01, -3.1819e-01, -8.2176e-02, -1.0884e-01, -8.2644e-02,\n",
       "                        7.3268e-02,  2.9812e-01,  3.5902e-02,  2.1283e-01,  1.8569e-01,\n",
       "                       -1.0459e-01,  2.1177e-01, -7.0214e-02,  2.1309e-01, -4.4865e-02,\n",
       "                       -7.0631e-02,  9.9397e-02,  4.8389e-02, -1.8970e-01, -4.1213e-02,\n",
       "                        1.5661e-01, -3.9280e-02,  9.1560e-02,  5.2389e-02,  1.4485e-01,\n",
       "                        4.9629e-02, -1.6409e-02, -2.1614e-01,  9.9994e-02, -1.2004e-02,\n",
       "                       -4.7265e-02,  4.8690e-02, -3.1030e-02,  2.3974e-01,  1.0342e-01],\n",
       "                      [ 3.0347e-01, -5.4239e-02, -1.1368e-01, -1.0754e-01,  1.3444e-01,\n",
       "                       -1.8972e-01,  1.3554e-01, -2.5943e-01, -1.8243e-01,  2.2752e-01,\n",
       "                        1.7262e-01,  1.6375e-01,  1.7727e-02, -1.4103e-01,  1.3176e-01,\n",
       "                       -1.5542e-01,  6.6969e-02, -1.7008e-01,  2.1164e-01,  9.2712e-02,\n",
       "                        2.1574e-01, -2.2931e-01,  7.4931e-02, -1.9401e-01, -2.4083e-01,\n",
       "                       -1.7198e-01,  1.3311e-01, -1.5882e-02, -6.9157e-02,  1.3537e-01,\n",
       "                       -1.1931e-01, -5.2052e-02,  1.8606e-01,  4.8372e-02,  1.2255e-02,\n",
       "                       -2.4900e-01, -9.2418e-02, -5.0701e-02, -1.1562e-01,  5.2836e-02,\n",
       "                        7.9315e-02, -4.6000e-03,  6.2320e-02,  1.9374e-01, -4.2450e-02,\n",
       "                        2.2626e-02, -9.5730e-02,  1.0613e-01, -4.1627e-02, -1.4164e-01,\n",
       "                       -1.4081e-01,  6.8420e-02,  2.5521e-01,  1.8432e-01,  2.6029e-02,\n",
       "                       -2.7669e-01, -1.6387e-01,  1.4884e-01,  3.7039e-02,  2.6184e-01,\n",
       "                       -9.2175e-02,  3.9159e-02, -9.2971e-04, -2.6575e-01, -6.6896e-03,\n",
       "                        1.1870e-01,  3.1081e-01, -2.4070e-02,  2.2333e-01,  2.2100e-01,\n",
       "                        1.4623e-01, -9.1193e-02, -8.7637e-02,  1.2000e-02, -7.0097e-02,\n",
       "                       -2.0473e-01, -1.7966e-01,  1.9839e-01,  5.5821e-02, -4.1213e-02,\n",
       "                        1.7516e-01,  1.0952e-01,  5.2520e-02,  3.7609e-02,  1.3310e-01,\n",
       "                       -2.7318e-01,  1.8174e-02, -1.4332e-01, -1.0731e-01, -1.4197e-01,\n",
       "                        9.2846e-02,  1.5079e-01,  1.4809e-02, -8.4056e-02, -2.4435e-01,\n",
       "                        1.4930e-01,  7.1305e-02,  6.4459e-02, -2.4679e-01, -9.1928e-02]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.context.weight',\n",
       "              tensor([[-0.4806,  0.4035,  0.2508,  0.2144, -0.3479, -0.3496,  0.6081,  0.1567],\n",
       "                      [-0.1363, -0.1240,  0.4100, -0.1525,  0.4137, -0.1736,  0.1447,  0.1613],\n",
       "                      [-0.3137,  0.0151,  0.1223, -0.5989, -0.1206,  0.0583,  0.5044,  0.1356],\n",
       "                      [-0.5205, -0.1795,  0.6063, -0.0797,  0.4620,  0.0703,  0.4018, -0.2632],\n",
       "                      [ 0.6016,  0.1292, -0.1254,  0.4709,  0.3020, -0.4116, -0.0440,  0.4389],\n",
       "                      [ 0.1526, -0.1937, -0.3987, -0.4288,  0.3404,  0.2771, -0.5426, -0.1257],\n",
       "                      [ 0.1550, -0.5418,  0.5277, -0.0653, -0.2488,  0.0682,  0.2212,  0.1361],\n",
       "                      [ 0.5807,  0.3447, -0.0593,  0.1042,  0.1484, -0.2429, -0.5247, -0.0651]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.fc2.weight',\n",
       "              tensor([[-0.1458,  0.0505,  0.5062, -0.4079, -0.8726, -0.4967, -0.1206, -0.7112],\n",
       "                      [-0.4049, -0.1072, -0.5576,  0.0707,  1.0786, -0.5667,  0.7807,  0.1145],\n",
       "                      [-0.0170,  0.7548, -0.0597,  0.7321,  0.0867, -0.2068, -0.1246, -0.4151],\n",
       "                      [-0.7204,  0.2701, -0.0684, -0.2354,  0.4188, -0.1929,  0.3920, -0.4044],\n",
       "                      [-0.4505, -0.3181, -0.5435, -0.0141,  0.2743,  0.0567, -0.2856,  0.3373],\n",
       "                      [-0.6537,  0.0733,  0.4335,  1.6045, -0.5547,  0.2742,  0.5209, -0.5978],\n",
       "                      [-0.2558,  0.4954,  0.3953, -0.1709,  0.7411, -0.3928, -0.3950,  0.4389],\n",
       "                      [-0.2976, -0.1997, -0.1501, -0.0073,  0.3554, -0.0927, -0.0287, -0.2332]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.2539,  0.0960,  0.1298,  0.0777,  0.3880,  0.0389,  0.0357, -0.0549],\n",
       "                      [-0.4061,  0.1643,  0.3275,  0.0416, -0.3276,  0.3772,  0.0941,  0.3038],\n",
       "                      [ 0.1825,  0.0663, -0.1238,  0.0862,  0.1352, -0.0255, -0.2683, -0.2208],\n",
       "                      [-0.3850, -0.1643, -0.0677,  0.3436, -0.2247, -0.4134,  0.2303,  0.3622],\n",
       "                      [-0.3277, -0.0042,  0.1336,  0.2708, -0.0754,  0.1913,  0.3228,  0.2458],\n",
       "                      [ 0.2047,  0.2555, -0.3764,  0.0893,  0.3240, -0.3328, -0.3682, -0.3469],\n",
       "                      [ 0.1290,  0.3899, -0.0381, -0.1670,  0.0249, -0.3464,  0.0727, -0.2762],\n",
       "                      [-0.2827, -0.3064, -0.1189,  0.2738,  0.0853,  0.2924, -0.4053, -0.3421],\n",
       "                      [ 0.2574,  0.3309,  0.3567, -0.3901,  0.1882, -0.4142, -0.1242,  0.0085],\n",
       "                      [ 0.1964, -0.1283, -0.3632, -0.4082, -0.1685,  0.3201,  0.1823,  0.2078],\n",
       "                      [-0.3397, -0.3775,  0.3887,  0.2744, -0.1811,  0.0353,  0.3026,  0.3781],\n",
       "                      [-0.3380, -0.2082,  0.1632,  0.3210,  0.0731, -0.0259,  0.0163,  0.3823],\n",
       "                      [-0.3298,  0.1914, -0.3008,  0.0399, -0.3968,  0.2721, -0.2341,  0.0279],\n",
       "                      [-0.2635,  0.0385, -0.2046, -0.2148, -0.1820,  0.2606,  0.0587, -0.1082],\n",
       "                      [ 0.3578,  0.0823, -0.1359, -0.0190, -0.1642, -0.1666, -0.1312,  0.1001],\n",
       "                      [-0.3741, -0.3271,  0.2820, -0.1006, -0.0155,  0.1467, -0.1879,  0.2943],\n",
       "                      [-0.0951,  0.0256, -0.2913,  0.1708, -0.2986,  0.2555, -0.0595, -0.1534],\n",
       "                      [-0.1406,  0.1603,  0.4114,  0.1141,  0.2575, -0.3541, -0.0991, -0.2379],\n",
       "                      [-0.3015,  0.0721, -0.1313,  0.0951, -0.1670, -0.3830, -0.2162, -0.4038],\n",
       "                      [ 0.0910, -0.3154,  0.3229,  0.1818, -0.2357, -0.1201, -0.3764,  0.3026],\n",
       "                      [-0.1879, -0.0882,  0.0310,  0.2039, -0.1252,  0.2060,  0.2161, -0.0519],\n",
       "                      [ 0.2785, -0.3684, -0.2287, -0.0330, -0.0428,  0.1490,  0.3034, -0.3033],\n",
       "                      [ 0.2204,  0.1008,  0.3489,  0.2242, -0.0913, -0.0596, -0.2796,  0.0927],\n",
       "                      [ 0.3287,  0.1446,  0.3397,  0.1678,  0.0808, -0.0909, -0.3629, -0.0787],\n",
       "                      [ 0.3566,  0.3653, -0.1421,  0.3448,  0.3463, -0.3584, -0.4144, -0.2092],\n",
       "                      [-0.0425,  0.1627,  0.1759,  0.2661, -0.2057,  0.2810,  0.0958, -0.2982]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.special_days.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.special_days.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.special_days.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.month.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.month.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.month.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.time_idx.fc1.weight',\n",
       "              tensor([[ 0.2328,  0.0249,  0.8767, -0.7822,  0.1321,  0.2947, -0.3479, -0.4911],\n",
       "                      [-0.3612,  0.0785,  0.1833,  0.4472,  0.4951,  0.5343,  0.4409,  0.0597],\n",
       "                      [-0.8970, -0.6470, -0.7066,  0.8931, -0.0935,  0.2284,  0.2546,  0.0622],\n",
       "                      [-0.2770,  0.5844,  0.8296, -0.4887, -0.7188, -0.5396, -0.5158,  0.2456],\n",
       "                      [ 0.3366,  0.4074, -0.4736,  0.2078, -0.3705, -1.0154,  0.3730, -0.1167],\n",
       "                      [-0.6352, -0.3485,  0.5804, -0.8641,  0.3120,  0.0978,  0.4784,  0.4958],\n",
       "                      [ 0.6007, -0.3171, -0.5438, -0.3439, -0.0170, -0.6481,  0.5092,  1.0472],\n",
       "                      [-0.2373,  0.3771, -0.0552,  0.6048,  0.4231,  0.5499, -1.4335,  0.2164]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.time_idx.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.time_idx.fc2.weight',\n",
       "              tensor([[-0.0380, -0.7294,  0.8414,  0.2326, -0.4740, -0.2637, -0.0880,  0.8421],\n",
       "                      [ 0.3640, -0.4182,  0.0849,  0.4226,  0.1401,  0.4603,  0.9913, -0.5278],\n",
       "                      [ 0.2375,  0.2152, -0.0465, -0.1962, -0.9637, -0.4594,  0.5637,  0.7094],\n",
       "                      [-0.7965, -0.5834,  0.4641, -0.5618, -0.5262, -0.2234,  0.2616, -0.1694],\n",
       "                      [-0.1796, -0.4342,  0.4038,  0.2222,  0.0604,  0.3972, -0.1346,  0.8160],\n",
       "                      [-0.7808, -0.4695,  0.6526,  0.4316, -0.2690,  0.2696, -0.0939, -0.8255],\n",
       "                      [ 0.1808, -0.8465,  0.2025,  0.1096, -0.5774,  0.7599, -0.9190,  0.6093],\n",
       "                      [ 0.0202, -0.4920,  0.0703, -0.4958, -0.7744, -0.6676, -0.8342, -0.9240]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.time_idx.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.4203,  0.0941,  0.4768, -0.2152,  0.0233, -0.1605,  0.4228, -0.2795],\n",
       "                      [ 0.2878, -0.3511,  0.3757, -0.4655, -0.2486, -0.2257, -0.0849, -0.0062],\n",
       "                      [ 0.1616,  0.4484,  0.2945, -0.2411,  0.4698, -0.0736, -0.2788,  0.1869],\n",
       "                      [-0.0871,  0.4772,  0.0558,  0.3309,  0.1287, -0.3268,  0.1052, -0.2893],\n",
       "                      [-0.1339, -0.1611, -0.3962,  0.1935,  0.3538, -0.4927,  0.2722, -0.3948],\n",
       "                      [-0.4893,  0.1724, -0.0111, -0.3065,  0.4477,  0.0408, -0.3136,  0.2294],\n",
       "                      [ 0.0354, -0.0800, -0.3559, -0.0363,  0.2894, -0.2443,  0.2303, -0.4914],\n",
       "                      [-0.1892, -0.1573, -0.4399,  0.1787, -0.3915,  0.2894,  0.1024,  0.0066],\n",
       "                      [-0.2666, -0.1702,  0.1214,  0.4807, -0.2395, -0.3402, -0.2218, -0.3592],\n",
       "                      [-0.0658, -0.3564,  0.3625,  0.3549, -0.3181,  0.4410,  0.1037, -0.3181],\n",
       "                      [ 0.1661, -0.4538, -0.2659, -0.3609, -0.2781, -0.1082,  0.1139,  0.0954],\n",
       "                      [-0.4887, -0.4786, -0.0759,  0.4267,  0.1852,  0.4463, -0.2369,  0.1394],\n",
       "                      [-0.4353,  0.2602, -0.0123, -0.0379, -0.2700, -0.4369, -0.1841, -0.0472],\n",
       "                      [-0.2655,  0.2090, -0.0868,  0.0492, -0.4656,  0.1408, -0.2445, -0.3778],\n",
       "                      [-0.2007, -0.4547, -0.3816,  0.3728,  0.4093, -0.3473,  0.1084, -0.2575],\n",
       "                      [ 0.4679,  0.3052,  0.1988, -0.4077, -0.2459, -0.1051, -0.4470, -0.2922]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.price_regular.fc1.weight',\n",
       "              tensor([[ 0.2229,  0.4761, -0.2762, -0.3663,  0.2519, -0.0909, -0.3811, -0.4239],\n",
       "                      [ 0.9975, -0.1777,  0.2335,  0.3756, -0.1923, -0.0332,  0.3473, -0.3735],\n",
       "                      [ 0.0675,  0.0244, -0.5539,  0.7503,  0.2646, -0.7791, -0.1102, -0.4439],\n",
       "                      [ 0.1420,  1.5450, -0.4392,  0.0195,  0.0175, -0.6802, -0.1857, -0.0200],\n",
       "                      [-0.3459,  0.3053,  0.1389,  0.3671, -0.1868, -0.1976, -0.6224, -0.2130],\n",
       "                      [ 0.2567,  0.3606,  0.5124, -0.3457, -0.2663, -1.0031,  0.2687,  0.2123],\n",
       "                      [-0.3075, -0.2345, -0.0348, -0.9593, -0.5929,  0.6980,  0.1590,  0.5243],\n",
       "                      [ 0.5668,  0.1523,  0.0058, -0.1824, -0.0728,  0.5708,  1.0096, -0.5994]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.price_regular.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.price_regular.fc2.weight',\n",
       "              tensor([[ 0.4349, -0.3808, -0.2594,  0.4005, -0.3724,  0.9555,  0.1614, -0.2717],\n",
       "                      [-0.4167,  0.1208,  0.9181, -0.2372, -0.1930,  0.1836,  0.1724,  0.2777],\n",
       "                      [ 0.5623,  0.2507,  0.3725,  0.7435, -0.0257,  0.1264,  0.3975,  0.6321],\n",
       "                      [ 0.0608,  0.0557, -0.2189, -0.0047,  0.1284, -0.0015, -0.5823, -0.2301],\n",
       "                      [ 0.3991,  0.4816,  0.3603, -0.1416,  0.0469,  0.8287,  0.5650,  0.3166],\n",
       "                      [ 0.0913,  0.0723,  0.8137,  0.7472,  0.2258,  0.3407, -1.3694, -0.0219],\n",
       "                      [-1.0311,  0.3018, -0.0741, -0.1034, -0.2076, -0.2807, -0.7610, -0.3434],\n",
       "                      [-0.4372,  0.8646,  0.7966,  0.4120,  0.0875,  0.1891, -0.2625,  0.5934]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.price_regular.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.price_regular.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.4680,  0.3121, -0.4015, -0.4293,  0.0204,  0.4010,  0.1452,  0.0703],\n",
       "                      [-0.0324, -0.4968,  0.3009,  0.3189, -0.3516, -0.0921,  0.4861, -0.1916],\n",
       "                      [-0.3433,  0.2860,  0.2310,  0.4307, -0.2153,  0.1216,  0.1204,  0.4068],\n",
       "                      [ 0.2802,  0.1175, -0.0703, -0.0892, -0.2698,  0.2103,  0.4261, -0.2542],\n",
       "                      [-0.3417,  0.3723,  0.0672, -0.2357,  0.3238, -0.4074, -0.2457, -0.1607],\n",
       "                      [-0.0159,  0.1066,  0.2391, -0.1746, -0.0485, -0.2608, -0.3288,  0.1091],\n",
       "                      [ 0.3687,  0.4315, -0.3902,  0.2366, -0.1543, -0.0249, -0.0209,  0.4319],\n",
       "                      [ 0.4190, -0.4049,  0.1084,  0.2924,  0.1341, -0.0116, -0.2360, -0.3528],\n",
       "                      [-0.4921, -0.0097, -0.1929,  0.1180, -0.2114,  0.4153, -0.3528,  0.4437],\n",
       "                      [-0.1982,  0.0773, -0.1834,  0.2107,  0.3946,  0.4675, -0.3463,  0.3432],\n",
       "                      [ 0.3307, -0.4103,  0.2021,  0.0967,  0.2744,  0.4381,  0.0114, -0.1851],\n",
       "                      [-0.2254,  0.0646, -0.0734, -0.3581,  0.0139,  0.2863,  0.0166,  0.3143],\n",
       "                      [-0.1889,  0.3921,  0.1191, -0.1680,  0.2411,  0.2459, -0.2144, -0.0909],\n",
       "                      [ 0.2581, -0.4406,  0.1905,  0.1096, -0.3408, -0.0616,  0.1463,  0.3478],\n",
       "                      [ 0.3656, -0.3225, -0.3251,  0.2364,  0.4933,  0.4270,  0.1969,  0.4741],\n",
       "                      [-0.2295, -0.0142, -0.4078, -0.3068, -0.3381, -0.4536,  0.1411,  0.1292]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.price_regular.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.price_regular.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.price_regular.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.discount_in_percent.fc1.weight',\n",
       "              tensor([[-0.4963, -0.7500, -0.5198, -0.0352,  0.5308, -0.2349,  0.3069,  1.0443],\n",
       "                      [-0.2739,  0.5471,  0.0742, -0.3528,  0.4863,  0.2626,  0.8588,  0.3231],\n",
       "                      [-0.0343, -0.2768, -0.3986,  0.1141,  0.0353,  0.2358,  1.0498, -0.4046],\n",
       "                      [-0.2749, -0.1478,  0.9509,  0.8977, -0.2937,  0.0090,  0.6115, -0.5642],\n",
       "                      [ 0.4269, -0.6605,  0.1293, -0.0029, -0.3342,  0.2318, -0.1758, -0.4323],\n",
       "                      [-0.2189,  0.1284, -0.8432,  0.3457, -0.1077,  0.2305,  0.0370, -0.3563],\n",
       "                      [ 0.4100,  1.2554, -0.5939, -0.0376, -1.2577,  0.6574,  0.1391,  0.0508],\n",
       "                      [-0.0188,  0.1476,  0.3996, -0.8318,  1.1988,  0.4360,  0.5380,  0.8177]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.discount_in_percent.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.discount_in_percent.fc2.weight',\n",
       "              tensor([[-2.2222e-01, -4.5339e-01,  3.3890e-01, -8.7629e-04, -6.2208e-01,\n",
       "                        7.0902e-01, -4.1553e-01,  7.0436e-01],\n",
       "                      [ 7.5160e-01, -8.0450e-01, -4.2170e-01, -2.1826e-01,  1.9031e-01,\n",
       "                       -8.8452e-02,  1.1780e-01,  2.4872e-01],\n",
       "                      [-9.8973e-01, -2.9346e-01, -5.2396e-01,  1.1027e+00, -8.4255e-01,\n",
       "                       -2.6148e-01, -3.4652e-01, -7.4221e-02],\n",
       "                      [ 3.7118e-02,  1.2606e+00, -6.1382e-01,  4.1933e-01, -1.5831e-01,\n",
       "                       -7.3517e-01,  8.1183e-01,  2.3683e-01],\n",
       "                      [-1.0316e-01, -6.6533e-01,  1.3515e-01,  3.9315e-01, -5.5713e-01,\n",
       "                       -6.1763e-01,  1.7318e-01,  6.6606e-01],\n",
       "                      [ 2.9323e-01,  2.5481e-01,  1.5358e-01,  3.1411e-01, -2.5454e-01,\n",
       "                       -3.6477e-01, -8.1851e-02, -1.2500e-01],\n",
       "                      [-5.9511e-01,  6.1894e-01,  5.5036e-01, -7.5717e-01, -5.0936e-02,\n",
       "                        1.1781e-01,  1.5263e-01,  1.5919e-01],\n",
       "                      [ 8.0516e-01, -4.5670e-01, -7.6850e-01,  2.2746e-01,  1.2169e-01,\n",
       "                        9.9158e-01, -6.2289e-01,  4.5816e-01]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.discount_in_percent.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.discount_in_percent.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.0651, -0.1256, -0.2335,  0.0055,  0.1698,  0.0802, -0.3315,  0.3389],\n",
       "                      [ 0.0943, -0.2047,  0.4328,  0.1008,  0.2600,  0.3535, -0.0089,  0.4121],\n",
       "                      [-0.0022,  0.4000,  0.0606,  0.2301,  0.2518, -0.2771,  0.4369,  0.0152],\n",
       "                      [ 0.1838, -0.3689, -0.1866,  0.3259, -0.3156,  0.0693,  0.4391, -0.4749],\n",
       "                      [-0.0055,  0.0812,  0.3277, -0.1680, -0.4887, -0.3095,  0.1501, -0.3682],\n",
       "                      [-0.4280, -0.0126,  0.1312, -0.3135, -0.1942,  0.2735, -0.3381, -0.4113],\n",
       "                      [-0.1511,  0.4017, -0.1466, -0.3389, -0.3547, -0.1175,  0.3551,  0.1879],\n",
       "                      [-0.1669, -0.4338, -0.3034,  0.1056,  0.4204,  0.2575, -0.0639,  0.2652],\n",
       "                      [ 0.0360,  0.0687,  0.2331, -0.1231,  0.1457,  0.0446,  0.1525, -0.1070],\n",
       "                      [ 0.3232, -0.4504,  0.3321, -0.4125, -0.3364, -0.3074, -0.0483, -0.0496],\n",
       "                      [-0.4862,  0.2653,  0.1230,  0.4885, -0.3568, -0.4021,  0.1201,  0.3852],\n",
       "                      [ 0.3338,  0.2028,  0.0841,  0.2492, -0.1990, -0.4987, -0.4163, -0.3198],\n",
       "                      [ 0.1117,  0.4477,  0.3227, -0.3264,  0.1394,  0.4423,  0.0123, -0.0932],\n",
       "                      [-0.2709, -0.0363,  0.3763, -0.1412, -0.0755,  0.2426, -0.1917, -0.2310],\n",
       "                      [ 0.0844,  0.3620,  0.0533, -0.0201, -0.3972,  0.2986,  0.0228, -0.2201],\n",
       "                      [-0.4399, -0.2372, -0.3514,  0.1024,  0.3664, -0.0988,  0.3043, -0.1063]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.discount_in_percent.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.discount_in_percent.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.discount_in_percent.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight',\n",
       "              tensor([[ 0.4939, -0.4887,  0.1877, -0.9243, -0.3798, -0.2085,  0.6888,  0.4333],\n",
       "                      [-0.6534,  0.2811,  0.5255,  0.0492,  0.1439, -0.1833,  0.6015,  0.2265],\n",
       "                      [-0.6026,  0.9649,  0.3179,  0.1253, -0.4374,  1.0145,  0.2110,  0.0993],\n",
       "                      [ 0.1001,  0.7616, -0.0233, -0.3566, -0.4533,  0.0913, -1.0144,  0.4918],\n",
       "                      [ 0.0344,  0.7790,  0.0631,  0.3632, -0.9171,  0.5860,  0.1366,  0.2661],\n",
       "                      [ 0.6055,  0.2577,  0.5684,  0.1266,  0.2610,  0.7546, -0.6158,  0.1818],\n",
       "                      [-0.2834,  0.0526, -0.0452,  0.2104,  0.5366,  1.4339, -0.4832,  0.4075],\n",
       "                      [-0.0637, -0.3221, -0.4774, -0.7420, -0.8334, -0.8331, -0.0782, -0.5607]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight',\n",
       "              tensor([[-0.2837,  0.3054,  0.2615, -0.3345, -0.0740,  0.0129, -0.3007,  0.0416],\n",
       "                      [-0.2077, -0.3975,  0.3937, -0.3221, -0.6088,  0.1218, -0.1779,  0.5478],\n",
       "                      [ 0.0819, -0.0719,  0.1432, -0.3460,  1.0841, -0.2723, -0.0803,  0.4494],\n",
       "                      [-0.5716,  0.3499,  0.4502,  0.2454,  0.4163,  0.6407, -0.0326,  0.4607],\n",
       "                      [-0.0171, -0.3077,  0.0114,  0.1876, -0.3776, -0.1125,  1.0202,  0.6514],\n",
       "                      [ 0.1114,  0.1364,  0.2688, -0.5712, -0.6544, -0.9117,  1.7024, -0.5404],\n",
       "                      [-0.1710, -0.2111,  0.1752,  0.8613, -0.0976, -0.1817,  0.1791,  0.3481],\n",
       "                      [ 0.0398, -0.8066, -0.0480,  0.5748, -0.3229, -0.1604,  0.8133, -1.1463]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.3505, -0.3022, -0.1319,  0.2172,  0.1035, -0.4303,  0.4828,  0.4693],\n",
       "                      [ 0.2466, -0.4898,  0.2793,  0.1427, -0.0618, -0.4189,  0.4236, -0.1495],\n",
       "                      [-0.4044,  0.3859,  0.1951,  0.1472,  0.3232,  0.1742, -0.1088, -0.0869],\n",
       "                      [ 0.4134, -0.0164, -0.4176, -0.3455, -0.3773,  0.0478,  0.3656,  0.2991],\n",
       "                      [ 0.1323,  0.1666, -0.2368,  0.4680,  0.1907, -0.3151, -0.3331, -0.4479],\n",
       "                      [-0.1423,  0.3657,  0.0294, -0.2370,  0.1392, -0.3471,  0.1490,  0.3414],\n",
       "                      [ 0.2431, -0.1522, -0.1701,  0.2084,  0.2994, -0.1225, -0.0011, -0.0564],\n",
       "                      [-0.0588, -0.4437, -0.4125,  0.4287, -0.2408,  0.3697,  0.3102, -0.0761],\n",
       "                      [-0.2419,  0.0166, -0.0867, -0.2966,  0.4860, -0.0395, -0.0769, -0.3387],\n",
       "                      [ 0.0813,  0.0693,  0.4931, -0.1544,  0.2812,  0.0243,  0.2654,  0.0088],\n",
       "                      [-0.0862,  0.1960, -0.2227,  0.3030, -0.4188, -0.3584,  0.4764, -0.1884],\n",
       "                      [-0.3976, -0.3655,  0.4848, -0.0699, -0.4207, -0.0721, -0.2437, -0.3354],\n",
       "                      [-0.2447,  0.3787,  0.2017,  0.2921,  0.0413, -0.2090, -0.2041, -0.3356],\n",
       "                      [-0.3612, -0.4311,  0.0888,  0.2624,  0.4080, -0.0127, -0.0729, -0.0416],\n",
       "                      [ 0.1970, -0.0792, -0.1757, -0.1378, -0.4884, -0.3851, -0.2140,  0.0484],\n",
       "                      [-0.3140,  0.1915, -0.2735,  0.4838, -0.4419,  0.2788, -0.2596, -0.1773]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.volume.fc1.weight',\n",
       "              tensor([[-2.8838e-01,  6.3454e-01,  4.8837e-02, -3.6337e-01, -1.5305e-01,\n",
       "                       -3.1104e-01,  8.3281e-01,  8.7908e-01],\n",
       "                      [-5.4853e-01, -2.4508e-01,  7.7929e-01,  4.9356e-01,  7.7372e-02,\n",
       "                        3.0287e-01, -3.8381e-01,  2.1281e-03],\n",
       "                      [-5.1947e-01, -1.1799e+00, -2.6810e-01, -6.0041e-01,  1.8844e-01,\n",
       "                       -5.7475e-01,  3.4470e-01,  5.2209e-01],\n",
       "                      [-4.2634e-01, -9.7515e-01,  2.3168e-01,  8.8199e-01,  1.8766e-02,\n",
       "                       -3.2996e-01, -4.9502e-02,  5.1398e-01],\n",
       "                      [ 4.2876e-01,  5.2352e-01,  6.2196e-03,  7.1846e-01,  9.2133e-01,\n",
       "                        4.5351e-01, -4.8003e-01,  1.1639e-01],\n",
       "                      [ 6.4406e-04,  4.7401e-01, -8.3949e-01, -2.3670e-01, -1.4034e-01,\n",
       "                       -4.5660e-01, -7.8521e-02, -1.7290e-01],\n",
       "                      [ 6.1068e-01, -2.9715e-02, -4.7340e-01, -1.3457e-01,  7.1296e-01,\n",
       "                       -6.2729e-01,  9.6809e-01, -4.1519e-01],\n",
       "                      [-4.6131e-01, -2.9522e-01,  1.9098e-01,  1.4032e-02, -9.0320e-01,\n",
       "                        2.7500e-01, -8.1343e-01, -3.4211e-01]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.volume.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.volume.fc2.weight',\n",
       "              tensor([[-0.3217,  0.3822, -0.3044, -0.8822,  0.6548, -0.3082,  0.0535, -0.7372],\n",
       "                      [ 0.2790,  0.1004, -0.2361,  0.2851, -0.7892, -0.2427,  0.1394,  0.4706],\n",
       "                      [ 0.2695,  0.6678,  0.4175, -0.5195, -0.2207, -0.2068, -0.2235, -0.0333],\n",
       "                      [ 0.0578,  0.4645, -0.5876,  0.7231,  0.1445, -0.2873, -0.2428, -0.2086],\n",
       "                      [-0.0975, -0.3855, -0.5377, -0.3278, -0.2689, -0.1695, -0.1368,  0.7453],\n",
       "                      [-0.2645,  1.1380,  0.1379,  0.2118, -0.8904, -0.1237, -0.3067, -0.4535],\n",
       "                      [ 0.1038, -0.2307,  0.3757, -0.1691,  0.2418, -1.1907, -0.5170,  1.0816],\n",
       "                      [ 0.2722,  0.0899,  0.3146,  0.3610, -0.1396, -0.4948, -0.9907,  0.0202]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.volume.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.volume.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.4776,  0.3085,  0.3444,  0.2110,  0.1526,  0.1034, -0.3833, -0.2003],\n",
       "                      [ 0.3225,  0.4211,  0.0134,  0.1285, -0.4743,  0.3530, -0.2912, -0.2680],\n",
       "                      [ 0.4934, -0.1433, -0.2526,  0.0688,  0.3940,  0.4543,  0.0419,  0.3404],\n",
       "                      [ 0.3566, -0.0836, -0.3951,  0.0135, -0.1698,  0.1752, -0.3663, -0.3354],\n",
       "                      [-0.3766, -0.3741,  0.3803, -0.4982, -0.0184, -0.3086, -0.2103, -0.1441],\n",
       "                      [ 0.2346,  0.3362, -0.1125,  0.0163, -0.0055,  0.4553,  0.2235, -0.1038],\n",
       "                      [ 0.3386, -0.4037,  0.1982,  0.3879, -0.2595,  0.1871,  0.2293, -0.4195],\n",
       "                      [ 0.1438,  0.3781,  0.0459, -0.0966, -0.1959, -0.3319,  0.1214, -0.4727],\n",
       "                      [-0.4280, -0.1809, -0.4735,  0.4669, -0.1611, -0.2658,  0.1257,  0.2152],\n",
       "                      [ 0.3765, -0.2019, -0.0874, -0.3776, -0.4366, -0.2176,  0.0563, -0.2479],\n",
       "                      [-0.1380,  0.1833,  0.1032,  0.3085,  0.2309,  0.2637, -0.2585,  0.2682],\n",
       "                      [-0.4481,  0.1540, -0.3153,  0.1381, -0.4575, -0.0828,  0.3075, -0.2500],\n",
       "                      [ 0.3095, -0.0777,  0.4691,  0.4711, -0.2950, -0.1171, -0.1022, -0.1891],\n",
       "                      [ 0.1644, -0.4553, -0.2998, -0.0784, -0.4449, -0.4789,  0.2051, -0.4175],\n",
       "                      [ 0.3322, -0.2903, -0.0399,  0.3015, -0.4931, -0.4868,  0.0208, -0.2030],\n",
       "                      [ 0.2337,  0.1745,  0.0615,  0.1877,  0.4278,  0.0794,  0.3308, -0.2819]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.volume.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.volume.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.volume.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.log_volume.fc1.weight',\n",
       "              tensor([[-0.5268,  0.2875,  0.0344,  0.2265, -0.8967,  0.2291,  0.1954, -0.1443],\n",
       "                      [-0.4395, -0.0408,  0.2979,  0.0370, -0.4365,  0.2744, -1.2087, -0.4327],\n",
       "                      [-0.7825,  0.0181,  0.2598, -0.0971, -0.0144,  1.1714,  0.1522,  0.0600],\n",
       "                      [ 0.6156,  0.5448, -0.1664,  0.1028,  0.3118, -0.2853, -0.4758, -0.5778],\n",
       "                      [-0.9883,  0.0753, -0.7067,  0.4700,  0.1832,  0.7062, -0.4205,  0.7811],\n",
       "                      [-0.0152, -0.3083, -0.2102,  0.0536,  0.5755,  0.4079, -0.1627,  1.3129],\n",
       "                      [ 0.0433,  0.4937,  0.1748, -0.2370,  0.2118, -0.5785,  0.7270, -0.5111],\n",
       "                      [ 0.2283, -0.4727, -0.0401,  0.2705, -0.2286, -0.5888,  1.0304,  0.5483]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.log_volume.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.log_volume.fc2.weight',\n",
       "              tensor([[-0.2271, -0.7225,  0.0078, -0.0104, -0.2792, -0.3533, -0.5700, -0.3432],\n",
       "                      [ 0.0424,  0.0644,  0.8655,  0.0634,  0.3119,  0.4824,  0.9101, -0.1063],\n",
       "                      [-0.5479, -0.3181, -0.5464, -0.0079, -0.4163, -0.4548,  0.0798,  0.2106],\n",
       "                      [ 0.0789,  0.2171, -0.7163,  0.9873,  0.3169, -0.2309, -0.0046, -0.1668],\n",
       "                      [-0.1346,  0.5527, -0.2304,  0.4312, -0.0144,  0.2738,  0.3649, -0.0293],\n",
       "                      [ 0.2752,  0.0334, -0.4666,  0.3807,  0.7847,  0.3202, -0.3418,  0.0387],\n",
       "                      [ 0.1754, -0.3644, -1.0255,  0.5066,  0.2054, -0.4725, -0.0852, -0.2793],\n",
       "                      [-1.1542,  0.1100,  0.0490, -0.0134,  0.1557,  1.0139, -0.2825,  0.1931]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.log_volume.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.log_volume.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.2601,  0.4375,  0.1006,  0.2291, -0.2517,  0.1625,  0.1077,  0.3988],\n",
       "                      [-0.4944, -0.1818,  0.0125, -0.3589,  0.0852,  0.3224,  0.3013, -0.2578],\n",
       "                      [ 0.2021, -0.3638,  0.3108, -0.4087, -0.4533,  0.1735, -0.0472,  0.1232],\n",
       "                      [ 0.4652,  0.4790,  0.2819, -0.4536, -0.0770,  0.0547, -0.4869,  0.4181],\n",
       "                      [ 0.3281, -0.2310, -0.1043, -0.2900,  0.1923,  0.0862, -0.1733,  0.2673],\n",
       "                      [-0.1081,  0.0537,  0.3462, -0.2349, -0.4611,  0.2699, -0.3268,  0.1890],\n",
       "                      [-0.1503,  0.3356, -0.0190, -0.2277, -0.3527,  0.3360, -0.3129,  0.1417],\n",
       "                      [ 0.3824, -0.4016, -0.4196,  0.0510, -0.1963, -0.3670,  0.3306, -0.4651],\n",
       "                      [-0.2280, -0.4153,  0.1322,  0.0431,  0.2086,  0.2093, -0.0020, -0.1502],\n",
       "                      [ 0.4421,  0.0208,  0.1190, -0.4117, -0.4900, -0.2442, -0.2620,  0.1449],\n",
       "                      [-0.2222,  0.0522,  0.4633, -0.1475,  0.1277,  0.0061,  0.3290,  0.2187],\n",
       "                      [-0.0232,  0.2735, -0.0254, -0.0850, -0.1949, -0.4079,  0.4177, -0.3168],\n",
       "                      [-0.4767, -0.2243,  0.1010, -0.0454,  0.2276,  0.2865,  0.2941, -0.4195],\n",
       "                      [ 0.2038,  0.2475, -0.2774,  0.0024,  0.0749,  0.0627,  0.2683,  0.4245],\n",
       "                      [ 0.4802,  0.1119,  0.2924,  0.2138, -0.2705,  0.3344, -0.0355,  0.2040],\n",
       "                      [-0.3318,  0.4000,  0.1116,  0.1133, -0.4448, -0.0435, -0.1748,  0.4721]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.log_volume.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.log_volume.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.log_volume.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.industry_volume.fc1.weight',\n",
       "              tensor([[ 0.4292, -0.0221,  0.4837,  0.0830, -0.5140, -0.4340, -0.2650, -0.2664],\n",
       "                      [-0.1282, -0.3428,  1.1290,  0.3674,  0.4550, -0.7533, -0.6579, -0.1140],\n",
       "                      [ 0.5281,  0.7983, -0.2320, -0.0530,  0.1159,  0.5898, -0.5841,  0.2419],\n",
       "                      [-0.7752, -1.5295,  0.6387,  0.7696,  0.8681,  0.3305,  0.1930, -1.1979],\n",
       "                      [ 0.5561, -0.3063,  0.3932,  0.1015, -0.3128,  0.6274, -0.3428,  0.4347],\n",
       "                      [-0.3415, -0.3183, -0.3566,  0.2276, -0.0256,  0.0349, -0.0075,  0.4727],\n",
       "                      [ 0.5730, -0.1637, -0.7189, -0.1957,  0.4695, -0.1516,  0.5072,  0.4224],\n",
       "                      [-1.1887,  0.1042, -0.1972,  0.2718,  0.5368,  0.5666, -0.1708, -0.0644]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.industry_volume.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.industry_volume.fc2.weight',\n",
       "              tensor([[ 0.3947,  0.6317, -0.6164,  0.6799,  0.3726, -0.5241,  0.0802, -0.0109],\n",
       "                      [ 0.0053,  0.0045,  0.2349,  0.9765,  0.5319,  0.3094, -0.4610, -0.6818],\n",
       "                      [-0.4275, -0.4048,  0.1859,  0.6795,  0.9294, -0.4150, -0.0515, -0.2615],\n",
       "                      [-0.1211,  0.3854,  1.2767, -0.0823,  0.2292, -0.0332, -0.1560,  0.2962],\n",
       "                      [ 0.0342, -0.5831, -0.1676, -0.2266,  0.0690,  0.0256,  0.9104,  0.3224],\n",
       "                      [ 0.7936, -0.0913, -0.2920, -0.2795,  0.3951,  0.0727, -0.0761, -1.2186],\n",
       "                      [-1.0272, -0.8759,  0.4482, -0.4627, -0.0443, -0.4447, -0.3922, -0.4150],\n",
       "                      [ 0.8103, -0.4297,  0.3313, -0.8609,  0.5734,  0.3818,  0.1132, -0.9649]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.industry_volume.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.industry_volume.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.3482, -0.4145,  0.2765,  0.2261, -0.2573,  0.4196, -0.2405,  0.3800],\n",
       "                      [-0.3833,  0.3944, -0.1124, -0.4417,  0.2663, -0.0410,  0.1412,  0.2303],\n",
       "                      [ 0.0534,  0.1597, -0.4214, -0.4413, -0.2348, -0.2614, -0.4713,  0.0781],\n",
       "                      [-0.0397, -0.1101, -0.0232,  0.2403, -0.1855,  0.0316, -0.0447,  0.2414],\n",
       "                      [-0.0532,  0.1796, -0.1958,  0.3873,  0.0842,  0.0841,  0.2421, -0.4984],\n",
       "                      [ 0.2209,  0.4017,  0.2994,  0.3247, -0.4016,  0.4328,  0.1118, -0.4874],\n",
       "                      [ 0.4524,  0.3899, -0.0798,  0.4903,  0.0315,  0.4010, -0.4420, -0.4662],\n",
       "                      [ 0.1393, -0.0037, -0.4244, -0.2804,  0.2803,  0.3187, -0.3792, -0.2235],\n",
       "                      [ 0.0029, -0.0006, -0.3683,  0.3698, -0.3491,  0.3557, -0.3093, -0.4968],\n",
       "                      [ 0.1246, -0.2392,  0.3371, -0.1658,  0.0477,  0.3722, -0.3247, -0.2059],\n",
       "                      [ 0.3404,  0.4218,  0.0871,  0.3844,  0.3025,  0.2827, -0.0197,  0.4827],\n",
       "                      [-0.1589,  0.0340, -0.1509, -0.0375,  0.3005,  0.3791,  0.0745,  0.3287],\n",
       "                      [ 0.3505,  0.2430, -0.1363,  0.2917,  0.4197,  0.4136,  0.1296,  0.3690],\n",
       "                      [-0.3454,  0.0947, -0.4393,  0.2567,  0.0230, -0.0962,  0.3187, -0.0765],\n",
       "                      [ 0.2042,  0.2690, -0.2480, -0.4331,  0.0447, -0.3058, -0.2835,  0.2355],\n",
       "                      [ 0.1188, -0.1111, -0.1818, -0.3698, -0.2137,  0.0320, -0.2921, -0.4539]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.industry_volume.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.industry_volume.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.industry_volume.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.soda_volume.fc1.weight',\n",
       "              tensor([[-0.1455, -0.1440,  0.5464,  0.1873,  0.0076, -0.3311,  1.1494, -0.9559],\n",
       "                      [ 0.8111,  0.0191,  0.3047,  0.1195,  0.3828, -0.1045,  0.3728,  0.7326],\n",
       "                      [-0.3708,  0.5285,  0.4610,  0.4612, -1.2209,  0.1852, -0.0821,  0.2536],\n",
       "                      [-0.5322, -0.2700, -0.3441,  0.4828,  1.0571,  0.0599, -0.2612, -0.8075],\n",
       "                      [-0.1951, -0.2364, -0.8442, -0.6871,  0.2218,  0.5738, -0.3004, -0.7664],\n",
       "                      [-0.1284, -0.2709,  0.1261, -0.1185,  0.2336, -0.1217,  0.0388, -0.0674],\n",
       "                      [-0.6276, -0.0238, -0.3596, -0.6039,  0.2813, -0.6023,  0.2723,  0.3182],\n",
       "                      [-0.0051, -0.1204, -0.6055, -0.9839,  0.8387,  0.2425, -0.6663, -0.5858]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.soda_volume.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.soda_volume.fc2.weight',\n",
       "              tensor([[ 0.2223, -0.4804, -0.0827, -0.7042,  0.0697, -0.1919, -0.2158, -0.6797],\n",
       "                      [-0.2718, -0.5598, -0.2901,  0.0408,  0.7449, -0.2722,  0.9889, -0.7145],\n",
       "                      [ 0.2323, -0.0921,  0.1622,  0.3576,  0.8612,  0.5503,  0.4686,  0.4050],\n",
       "                      [-0.2924,  0.4019,  0.1726, -0.3151,  0.2590,  0.4795,  0.2968,  0.8283],\n",
       "                      [-0.2148,  0.3417, -0.3141,  0.0332, -0.1107, -0.0646,  0.0587, -0.0313],\n",
       "                      [-0.2050,  0.4952,  0.2574,  1.0390,  0.1251,  0.2474, -0.1282,  0.1722],\n",
       "                      [-0.3561,  0.2294, -1.1144, -0.0751, -0.3725,  0.6512, -0.1754, -0.1377],\n",
       "                      [-0.1319,  0.8451,  0.5506, -1.0871, -0.3720, -0.1442,  0.3269,  0.5300]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.soda_volume.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.soda_volume.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.0697, -0.0937, -0.1005, -0.2552,  0.3590, -0.0832, -0.4898, -0.3206],\n",
       "                      [-0.4947,  0.2767, -0.0574, -0.2549, -0.3835,  0.2437, -0.4321, -0.4548],\n",
       "                      [-0.0451,  0.2985, -0.3948, -0.3237,  0.1612, -0.4857,  0.3322,  0.2673],\n",
       "                      [ 0.2440,  0.4256,  0.4344, -0.2309,  0.2824,  0.2730,  0.2264, -0.1365],\n",
       "                      [-0.2751, -0.3246,  0.1073, -0.0137,  0.0253,  0.4478, -0.4063,  0.1157],\n",
       "                      [ 0.0900, -0.0222,  0.3310,  0.3246, -0.3366,  0.0889, -0.3009, -0.2765],\n",
       "                      [-0.4177,  0.1864, -0.0511, -0.3176, -0.0993, -0.0369,  0.1889,  0.4255],\n",
       "                      [-0.3320, -0.0312,  0.4840,  0.3297,  0.2305, -0.1505,  0.0872,  0.0340],\n",
       "                      [ 0.0073,  0.3263, -0.1703, -0.1232,  0.3485,  0.1269, -0.4747, -0.0981],\n",
       "                      [ 0.3373,  0.3030,  0.3337, -0.2930, -0.3736,  0.1597,  0.3837,  0.4087],\n",
       "                      [ 0.1921,  0.2952, -0.3451,  0.1202, -0.0515, -0.0056,  0.2361, -0.3746],\n",
       "                      [ 0.0482, -0.1752,  0.2509, -0.4464, -0.2758, -0.3571,  0.3744,  0.3112],\n",
       "                      [ 0.4146,  0.4936,  0.1523,  0.0638,  0.1397,  0.0802,  0.0597, -0.3774],\n",
       "                      [ 0.3847, -0.3386,  0.3488,  0.2294,  0.1296,  0.1873,  0.1097, -0.2453],\n",
       "                      [-0.2659, -0.2541, -0.3010,  0.2278,  0.0372, -0.0051,  0.1339,  0.4618],\n",
       "                      [-0.0387, -0.2401, -0.3627,  0.4131, -0.4418,  0.2440,  0.4376,  0.2671]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.soda_volume.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.soda_volume.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.soda_volume.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_max_temp.fc1.weight',\n",
       "              tensor([[ 0.6786,  0.3478,  0.0660, -0.5023,  0.0624,  0.2752,  0.1634, -0.0178],\n",
       "                      [ 0.3527,  0.4256,  0.0196,  0.3687,  0.5763, -0.1746, -1.4646, -0.2275],\n",
       "                      [-1.1193, -0.1059, -0.1508,  0.9370,  0.9980,  0.6132,  0.6285,  0.4692],\n",
       "                      [ 0.2713,  0.1853, -0.2976,  0.6281, -0.0455,  0.2380,  0.6010, -0.5237],\n",
       "                      [ 0.1764, -0.3286, -0.4561,  0.1810,  0.3921,  0.3966,  0.5008, -0.4764],\n",
       "                      [ 0.2948,  0.1991,  0.1791,  0.0062,  0.4119, -0.3499,  0.0666,  0.3424],\n",
       "                      [-0.3168,  0.2473,  0.9541,  0.7313, -0.3025,  0.0947,  0.4822, -0.8286],\n",
       "                      [-0.1221,  1.6674,  0.3195, -0.3882, -0.2206, -0.1462,  0.2031, -0.3645]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_max_temp.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_max_temp.fc2.weight',\n",
       "              tensor([[ 1.0355,  0.0706,  0.0609,  0.1182, -0.1281,  0.1159,  0.5515,  0.4244],\n",
       "                      [-0.7953, -0.0454, -0.1011,  0.0811, -0.3609, -0.5337, -0.6156,  0.1323],\n",
       "                      [-0.1119, -0.1504, -0.4003,  0.3627,  0.5137, -0.7946, -0.1060, -0.4529],\n",
       "                      [-0.4890,  0.3446, -0.1632,  0.6222, -0.2356,  0.0052, -0.2398, -0.0774],\n",
       "                      [ 0.6299, -0.8672,  0.0037,  1.0945,  0.4149,  0.2336,  0.3124, -0.1102],\n",
       "                      [ 0.0351, -1.0392,  0.4135, -0.4317, -0.0334, -0.5259,  0.0612, -0.6943],\n",
       "                      [ 0.1032, -0.6115,  0.2038, -0.3728, -0.2070, -0.6697, -0.7177,  0.8854],\n",
       "                      [-0.2364,  0.0686,  0.2600, -0.8407,  0.4988,  0.3045, -0.1450, -0.3071]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_max_temp.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_max_temp.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.0952,  0.3915, -0.2755,  0.2295, -0.2500, -0.2565,  0.4401,  0.0607],\n",
       "                      [ 0.4991, -0.4157, -0.1808, -0.4244,  0.3984,  0.2428,  0.0233,  0.4723],\n",
       "                      [-0.3468, -0.3658,  0.4620, -0.1308,  0.3248,  0.2400,  0.1357, -0.3140],\n",
       "                      [-0.1653,  0.4345,  0.1970, -0.1336,  0.1616, -0.1242, -0.0387,  0.0872],\n",
       "                      [ 0.3485,  0.4783,  0.4553, -0.1057,  0.0403, -0.4810, -0.0493,  0.0290],\n",
       "                      [-0.3198,  0.4477, -0.2109, -0.4635, -0.2298, -0.0870, -0.4161,  0.3182],\n",
       "                      [ 0.0718, -0.2940,  0.0440, -0.4321,  0.1577, -0.0166, -0.0394,  0.0407],\n",
       "                      [-0.2285,  0.3341, -0.3636, -0.0075,  0.4128,  0.1054, -0.3600,  0.4966],\n",
       "                      [-0.2964, -0.2126,  0.3070, -0.3006,  0.0200,  0.1845,  0.2770, -0.3092],\n",
       "                      [ 0.4770,  0.3720, -0.1989,  0.0030, -0.1752, -0.2577,  0.4336,  0.3717],\n",
       "                      [ 0.1298,  0.4498, -0.4857,  0.0369, -0.2475,  0.2710,  0.0396, -0.3929],\n",
       "                      [ 0.0157,  0.2049, -0.1538, -0.0473, -0.3556,  0.4309, -0.4840, -0.2959],\n",
       "                      [-0.3945, -0.2223, -0.2720,  0.1577,  0.4322,  0.0217,  0.1145,  0.3777],\n",
       "                      [-0.4992,  0.0333,  0.2252,  0.0913, -0.2082, -0.1674, -0.2616,  0.4948],\n",
       "                      [-0.2209, -0.0858,  0.0095, -0.3754, -0.3274, -0.3374,  0.1012, -0.3033],\n",
       "                      [-0.3939, -0.2846, -0.1724, -0.1358, -0.3123,  0.1429, -0.0628, -0.3613]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_max_temp.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_max_temp.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_max_temp.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_agency.fc1.weight',\n",
       "              tensor([[-0.0505, -0.4450,  0.2417,  0.1082,  0.1093,  0.0362, -0.2353, -0.8317],\n",
       "                      [ 0.1260, -0.0537,  0.6575, -0.4364,  0.2031,  0.1691,  0.7839,  0.5412],\n",
       "                      [ 0.1387, -0.1203,  0.4189, -0.3752,  0.3484,  0.3092,  0.5711, -0.2431],\n",
       "                      [ 0.6271, -0.0083, -0.1235, -0.1599,  0.3644, -0.4725,  0.2108, -0.8030],\n",
       "                      [-0.8203,  0.5139,  0.7848,  1.0605,  0.2015,  0.0634,  0.1322,  0.3579],\n",
       "                      [-0.7440,  0.3865, -0.3391, -0.1033, -0.7816, -0.4596, -0.6721,  1.0226],\n",
       "                      [ 0.3967,  0.7930, -0.1298, -0.0075, -0.1122, -0.0384, -0.7882,  0.1734],\n",
       "                      [ 0.2408, -0.0276, -0.6904, -0.7894,  0.5698, -0.0877, -0.2156, -0.2693]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_agency.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_agency.fc2.weight',\n",
       "              tensor([[ 0.5125,  0.6595, -0.2128, -0.5373, -1.3117,  0.6286, -0.2325, -0.5887],\n",
       "                      [-0.3823,  1.0163,  0.4428, -1.1570, -0.9732, -0.1198, -0.1324,  0.0141],\n",
       "                      [-0.6305,  0.0207,  0.0856, -0.3928, -0.0899,  0.1482,  0.2239,  0.2896],\n",
       "                      [ 0.1397,  0.5026,  0.1137,  0.2049, -0.1259,  0.9912,  0.5724, -0.5697],\n",
       "                      [-0.4027, -0.1827, -0.8265, -0.7320,  0.0486, -0.6203,  0.1369,  0.3183],\n",
       "                      [-0.1881,  0.8530, -1.1139,  1.1030, -0.2405, -0.0186, -0.1959, -0.5161],\n",
       "                      [ 0.0478,  0.3106, -0.3294, -0.2748,  0.9051,  0.9068, -0.0506,  0.3562],\n",
       "                      [-0.6860, -0.5945,  0.2266, -0.1324,  0.2969,  0.2520, -0.6552,  1.0644]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_agency.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_agency.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.1002, -0.2886,  0.1478, -0.4545, -0.1860,  0.2521, -0.0132, -0.3379],\n",
       "                      [ 0.2471,  0.0347, -0.0716, -0.4809, -0.1804,  0.0552, -0.2717,  0.0841],\n",
       "                      [-0.3552,  0.3858,  0.3850,  0.2945, -0.0594, -0.4983, -0.1952, -0.0405],\n",
       "                      [-0.4608,  0.3936,  0.1423,  0.3793, -0.4473, -0.2567,  0.1127, -0.0076],\n",
       "                      [-0.2908,  0.3656,  0.2062, -0.0238,  0.4765, -0.4876, -0.4542,  0.0997],\n",
       "                      [ 0.4538,  0.2827, -0.2751,  0.3587,  0.2598,  0.0284,  0.3163,  0.0989],\n",
       "                      [ 0.0007, -0.1384, -0.2656, -0.3152, -0.0657, -0.3419,  0.2119,  0.1412],\n",
       "                      [-0.4875, -0.3678,  0.3573, -0.2621, -0.0052, -0.3203, -0.1094,  0.2466],\n",
       "                      [ 0.1271,  0.2454, -0.0291, -0.3989, -0.0063,  0.2964,  0.1170,  0.1034],\n",
       "                      [ 0.0985,  0.4102,  0.2522, -0.0818, -0.2713,  0.4069, -0.2601, -0.3342],\n",
       "                      [ 0.1562, -0.3193, -0.4314, -0.4049,  0.1233, -0.3142,  0.4423, -0.0201],\n",
       "                      [-0.2124, -0.3066, -0.1495,  0.4362, -0.3192, -0.4629,  0.1488,  0.1695],\n",
       "                      [-0.4236, -0.2244,  0.4334, -0.2363,  0.2098, -0.2400, -0.4414, -0.4823],\n",
       "                      [ 0.3814,  0.1533,  0.1422,  0.1721,  0.1927,  0.3301,  0.3836,  0.3856],\n",
       "                      [ 0.1607,  0.0893,  0.1073, -0.4050,  0.2229,  0.1233,  0.2173, -0.1234],\n",
       "                      [ 0.4153,  0.0601, -0.1185, -0.0141, -0.1996, -0.0735,  0.4244,  0.1659]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_agency.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_agency.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_agency.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_sku.fc1.weight',\n",
       "              tensor([[ 1.1005, -0.6106, -0.7735,  0.6723, -0.7367, -0.2237, -0.1106,  0.0717],\n",
       "                      [-0.7076,  0.1585,  0.0380, -0.2633,  0.7466,  0.3938,  0.4172, -0.3006],\n",
       "                      [-0.2605, -0.0210, -0.7268,  0.5089,  0.4824,  0.4528,  0.1540, -0.1320],\n",
       "                      [ 0.5860, -0.3635,  0.5946, -0.5785,  0.1034, -0.5216,  0.0161,  0.2465],\n",
       "                      [ 0.4392,  0.0329,  0.2008, -0.7277,  0.3633,  0.1587,  0.3503,  0.0257],\n",
       "                      [ 1.1828,  0.4487,  0.3540,  0.4534, -0.0080, -0.6615,  0.2656, -0.7711],\n",
       "                      [ 1.0450, -1.0778,  0.5075,  0.6273, -0.6386,  1.1532,  0.4657, -0.0361],\n",
       "                      [-0.7021,  1.2123, -0.3761, -0.3291, -0.7653,  0.8096, -0.3835, -0.5137]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_sku.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_sku.fc2.weight',\n",
       "              tensor([[ 0.6455,  0.5951,  0.6201, -0.4252,  0.1204,  0.2144, -0.7745,  0.0297],\n",
       "                      [ 0.2594, -0.3384,  0.5292,  0.7823,  0.2827, -0.0949,  0.3341,  0.4144],\n",
       "                      [-0.2600,  1.2648, -0.6410,  0.1035,  0.1566, -0.0102,  0.1958,  0.4030],\n",
       "                      [-1.0861, -0.2856,  0.5597,  1.0490, -0.0314,  0.1567,  0.8388, -0.2879],\n",
       "                      [-0.5138, -0.3503,  0.5463,  0.0491,  0.1154, -0.0189, -0.2323,  0.9845],\n",
       "                      [-0.2498,  0.1588, -0.5184, -0.3737, -0.5931, -0.2360,  0.4295,  0.3534],\n",
       "                      [-0.3335, -0.0375,  0.3479,  1.0681, -0.1512, -1.0739, -0.2068, -0.8221],\n",
       "                      [-0.0530, -0.3345,  0.6235, -0.1239, -1.2708, -0.0050,  0.6167, -0.5043]],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_sku.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_sku.gate_norm.glu.fc.weight',\n",
       "              tensor([[-1.1031e-01,  4.3635e-01,  4.3442e-01, -1.6577e-01,  8.3898e-02,\n",
       "                       -1.3668e-01,  4.0039e-01,  2.3973e-01],\n",
       "                      [ 1.3706e-03,  3.0238e-01, -4.0147e-01, -1.2787e-01,  1.0206e-01,\n",
       "                       -4.7370e-01,  4.3702e-01,  4.1079e-02],\n",
       "                      [ 4.4172e-01, -1.4552e-01,  2.9771e-02, -1.3790e-01, -2.0500e-01,\n",
       "                       -1.8528e-01,  3.4581e-01,  4.4925e-01],\n",
       "                      [ 1.4388e-01,  2.7920e-01,  2.1750e-01,  6.2668e-04, -3.7217e-01,\n",
       "                        1.2543e-01, -1.7181e-01,  1.9144e-01],\n",
       "                      [-3.2534e-01, -3.3985e-02, -1.9654e-01, -4.6255e-01, -4.6225e-01,\n",
       "                        4.6131e-01, -5.4395e-04, -4.3102e-01],\n",
       "                      [ 8.1987e-02, -3.1379e-02,  4.1191e-01,  4.7123e-01, -1.2852e-01,\n",
       "                       -3.0003e-01, -2.8654e-01, -1.3295e-01],\n",
       "                      [-2.7447e-01,  4.5067e-01, -1.9112e-01,  2.5761e-01,  2.2628e-01,\n",
       "                        1.1690e-01,  2.4375e-01,  4.2340e-01],\n",
       "                      [ 2.1274e-01,  2.2001e-01, -4.1953e-01, -4.4311e-02,  1.1545e-02,\n",
       "                        3.9158e-01,  2.1365e-01,  3.8885e-01],\n",
       "                      [ 3.8674e-01, -2.3323e-01,  7.0933e-02,  4.7677e-01,  1.7676e-01,\n",
       "                        2.8270e-01,  2.0324e-01, -1.5696e-01],\n",
       "                      [ 1.1940e-01, -3.4548e-01,  4.6128e-01,  2.8608e-02,  3.8746e-01,\n",
       "                       -3.5148e-01, -4.5933e-01,  5.9868e-02],\n",
       "                      [-6.4060e-02, -2.0225e-01,  2.6198e-01, -3.2526e-01,  4.3814e-01,\n",
       "                       -4.8811e-01,  1.0254e-01, -2.9235e-01],\n",
       "                      [ 1.0847e-01,  4.9379e-01, -6.0014e-02,  1.1626e-01, -1.9677e-01,\n",
       "                       -2.5657e-01, -4.2710e-01,  2.8860e-01],\n",
       "                      [-5.5529e-03,  1.7315e-01, -3.8455e-01, -4.1628e-01, -4.5464e-01,\n",
       "                       -2.8814e-01, -6.5012e-02, -7.5443e-02],\n",
       "                      [ 2.1985e-01, -2.4025e-01,  4.8719e-01, -2.2785e-01, -4.7020e-01,\n",
       "                        3.7823e-01, -3.2134e-01,  4.7651e-02],\n",
       "                      [-4.8273e-02, -1.0430e-01,  3.2395e-04, -4.9168e-01,  4.4962e-01,\n",
       "                       -3.2459e-01,  3.0485e-01, -2.9566e-01],\n",
       "                      [-1.2312e-01, -1.1825e-02, -1.9707e-01, -2.1661e-01, -4.2087e-01,\n",
       "                       -3.4342e-01, -2.3460e-02, -1.4616e-01]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_sku.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_sku.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.single_variable_grns.avg_volume_by_sku.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.time_idx.weight',\n",
       "              tensor([[ 0.9337],\n",
       "                      [-0.4100],\n",
       "                      [-0.7154],\n",
       "                      [-0.5596],\n",
       "                      [-0.2772],\n",
       "                      [-0.4745],\n",
       "                      [-0.5189],\n",
       "                      [ 0.4039]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.time_idx.bias',\n",
       "              tensor([ 0.1699, -0.3201, -0.7769, -0.3149, -0.4220, -0.3254, -0.9021,  0.2154],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.price_regular.weight',\n",
       "              tensor([[-0.7347],\n",
       "                      [-0.7788],\n",
       "                      [-0.8170],\n",
       "                      [ 0.4174],\n",
       "                      [-0.6020],\n",
       "                      [-0.4128],\n",
       "                      [ 0.7838],\n",
       "                      [ 0.5310]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.price_regular.bias',\n",
       "              tensor([ 0.5734, -0.9495, -0.7171, -0.3775,  0.8261,  0.1023, -0.7479,  0.0063],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.discount_in_percent.weight',\n",
       "              tensor([[-0.7767],\n",
       "                      [-0.2191],\n",
       "                      [-0.2750],\n",
       "                      [ 0.8657],\n",
       "                      [ 0.3097],\n",
       "                      [-0.1744],\n",
       "                      [ 0.1689],\n",
       "                      [-0.2887]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.discount_in_percent.bias',\n",
       "              tensor([ 0.3929,  0.3956,  0.2685, -0.3898,  0.8532, -0.1444, -0.3893,  0.6263],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.relative_time_idx.weight',\n",
       "              tensor([[ 0.8151],\n",
       "                      [ 0.9952],\n",
       "                      [ 0.2963],\n",
       "                      [-0.3409],\n",
       "                      [ 0.5079],\n",
       "                      [ 0.8580],\n",
       "                      [-0.9808],\n",
       "                      [-0.1239]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.relative_time_idx.bias',\n",
       "              tensor([-0.6820,  0.1864,  0.4136, -0.2066, -0.0837,  0.4501, -0.1681, -0.8398],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.volume.weight',\n",
       "              tensor([[ 0.8001],\n",
       "                      [-0.5033],\n",
       "                      [-0.1099],\n",
       "                      [ 0.0943],\n",
       "                      [-0.0601],\n",
       "                      [-0.9407],\n",
       "                      [ 0.4588],\n",
       "                      [-0.4542]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.volume.bias',\n",
       "              tensor([-0.5187,  0.2389, -0.5219, -0.4622, -0.3369, -0.3757, -0.4176, -0.2697],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.log_volume.weight',\n",
       "              tensor([[ 0.2599],\n",
       "                      [-0.8092],\n",
       "                      [-0.6053],\n",
       "                      [ 0.0146],\n",
       "                      [ 0.1391],\n",
       "                      [ 0.5523],\n",
       "                      [-0.7024],\n",
       "                      [ 0.3192]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.log_volume.bias',\n",
       "              tensor([ 0.5684,  0.5553, -0.9314, -0.3816, -0.8596, -0.6328,  0.5570, -0.1493],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.industry_volume.weight',\n",
       "              tensor([[ 0.4247],\n",
       "                      [-0.5870],\n",
       "                      [ 0.1520],\n",
       "                      [-0.6049],\n",
       "                      [ 0.4999],\n",
       "                      [-0.4374],\n",
       "                      [-0.2508],\n",
       "                      [-0.8676]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.industry_volume.bias',\n",
       "              tensor([ 0.0033,  0.9495,  0.4854, -0.5335,  0.0134, -0.1096, -0.8051,  0.7841],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.soda_volume.weight',\n",
       "              tensor([[ 0.0161],\n",
       "                      [ 0.2106],\n",
       "                      [-0.4038],\n",
       "                      [-0.4679],\n",
       "                      [ 0.1649],\n",
       "                      [ 0.3697],\n",
       "                      [ 0.2243],\n",
       "                      [-0.4819]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.soda_volume.bias',\n",
       "              tensor([ 9.7090e-01, -1.4720e-01, -6.1242e-01, -4.6771e-01,  9.8442e-01,\n",
       "                       4.8161e-05, -1.3574e-01, -4.1616e-01], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.avg_max_temp.weight',\n",
       "              tensor([[-0.2621],\n",
       "                      [-0.8422],\n",
       "                      [-0.7947],\n",
       "                      [ 0.5853],\n",
       "                      [ 0.8554],\n",
       "                      [ 0.9543],\n",
       "                      [-0.7219],\n",
       "                      [ 0.5409]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.avg_max_temp.bias',\n",
       "              tensor([-0.6190,  0.5966,  0.7216,  0.7739,  0.7201,  0.6256,  0.0195,  0.4595],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.avg_volume_by_agency.weight',\n",
       "              tensor([[-0.3578],\n",
       "                      [ 0.4354],\n",
       "                      [-0.3214],\n",
       "                      [-0.0168],\n",
       "                      [-0.8704],\n",
       "                      [-0.2615],\n",
       "                      [-0.5259],\n",
       "                      [-0.3373]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.avg_volume_by_agency.bias',\n",
       "              tensor([-0.6386, -0.8994,  0.0651,  0.6490,  0.9107,  0.5836, -0.5183, -0.9890],\n",
       "                     device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.avg_volume_by_sku.weight',\n",
       "              tensor([[ 0.3793],\n",
       "                      [ 0.5603],\n",
       "                      [-0.8585],\n",
       "                      [ 0.3586],\n",
       "                      [ 0.8455],\n",
       "                      [ 0.0606],\n",
       "                      [-0.6025],\n",
       "                      [ 0.8199]], device='cuda:0')),\n",
       "             ('encoder_variable_selection.prescalers.avg_volume_by_sku.bias',\n",
       "              tensor([ 0.4270,  0.6622, -0.6763,  0.5819, -0.6831,  0.9895, -0.4237,  0.6026],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.resample_norm.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.resample_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.resample_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.fc1.weight',\n",
       "              tensor([[-0.1909,  0.5306, -0.0587,  0.2633, -0.0567, -0.3266,  0.1188,  0.1511,\n",
       "                       -0.0067,  0.0228,  0.1634,  0.1457, -0.3077, -0.1102,  0.0248, -0.0105,\n",
       "                        0.0267, -0.1254,  0.1806,  0.3690, -0.0896, -0.1613, -0.3141, -0.1336,\n",
       "                        0.3321,  0.0781,  0.1473, -0.1729, -0.1122,  0.2513,  0.0116, -0.0046,\n",
       "                        0.0717,  0.0475,  0.0828, -0.0145,  0.2029, -0.1221, -0.2317,  0.1988,\n",
       "                       -0.3073,  0.4164, -0.0266, -0.1874],\n",
       "                      [ 0.2500,  0.0881,  0.0703,  0.0132,  0.0320,  0.4057,  0.1897, -0.0948,\n",
       "                       -0.0168,  0.2267,  0.3837,  0.1013, -0.0756, -0.2411,  0.3772,  0.0825,\n",
       "                       -0.2487,  0.2002,  0.0382, -0.5000,  0.3540,  0.2921, -0.2248, -0.0636,\n",
       "                       -0.1816,  0.1708,  0.2629, -0.1706, -0.2375, -0.1551,  0.3227, -0.3411,\n",
       "                        0.2080, -0.1240,  0.0858, -0.0818, -0.0536,  0.3438,  0.0126, -0.0581,\n",
       "                       -0.0292,  0.1497,  0.3387,  0.2176],\n",
       "                      [-0.2311,  0.2219, -0.2703,  0.2807,  0.0098, -0.0274, -0.4412,  0.0887,\n",
       "                        0.1349,  0.2835, -0.0466, -0.2924, -0.1764,  0.2060, -0.1257, -0.1817,\n",
       "                       -0.1055, -0.2524,  0.2133,  0.3453, -0.2828,  0.1050, -0.0561, -0.1881,\n",
       "                        0.0974, -0.1794, -0.1159,  0.5168,  0.1303,  0.2008,  0.2782,  0.2129,\n",
       "                        0.6449, -0.1421, -0.6145,  0.3506,  0.0911,  0.1951,  0.2511, -0.0877,\n",
       "                        0.1716, -0.1611, -0.1733, -0.1590],\n",
       "                      [-0.1284,  0.0218, -0.2294,  0.1163, -0.0103, -0.1639,  0.1073, -0.0035,\n",
       "                       -0.4654,  0.1865,  0.3088,  0.1223, -0.0364, -0.3345,  0.0056, -0.1242,\n",
       "                       -0.2435,  0.1054,  0.4538, -0.0138, -0.1226, -0.1036,  0.2360, -0.1038,\n",
       "                       -0.0897, -0.3588, -0.2914, -0.1447, -0.2640, -0.0967, -0.0873, -0.3344,\n",
       "                        0.1286,  0.0872,  0.4072, -0.3515,  0.1113, -0.0522, -0.0095, -0.0930,\n",
       "                       -0.0547,  0.2381, -0.1754, -0.0534],\n",
       "                      [-0.1690, -0.0426,  0.1135,  0.1282, -0.0754,  0.1240,  0.2171,  0.3342,\n",
       "                       -0.5513,  0.1700,  0.3699, -0.0822,  0.0541,  0.4070,  0.2333,  0.5675,\n",
       "                       -0.0855,  0.0796, -0.3365, -0.1051,  0.2130,  0.1632, -0.0512,  0.1800,\n",
       "                        0.1543, -0.0551,  0.4982,  0.2512,  0.2325,  0.0046, -0.2510,  0.3670,\n",
       "                       -0.1474,  0.1553,  0.0271, -0.0314, -0.1097,  0.5619,  0.1271, -0.0220,\n",
       "                        0.0395, -0.0879,  0.1032, -0.1009],\n",
       "                      [ 0.0727,  0.2871, -0.2287, -0.1829,  0.1741,  0.2218, -0.0767,  0.1456,\n",
       "                       -0.0728, -0.3847,  0.1228, -0.3916,  0.3917,  0.2636, -0.2707, -0.2742,\n",
       "                        0.0838, -0.4652,  0.0524,  0.1442, -0.3142, -0.3725,  0.0385, -0.0007,\n",
       "                        0.2502,  0.3213, -0.2818,  0.0518, -0.0445,  0.2620,  0.5160,  0.0799,\n",
       "                        0.1261, -0.3132, -0.1642,  0.1044, -0.0113, -0.0182, -0.2890,  0.1750,\n",
       "                        0.1763,  0.2751, -0.4861,  0.2845]], device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.context.weight',\n",
       "              tensor([[-0.2802,  0.0543, -0.1654,  0.4392,  0.4147,  0.4508,  0.3482, -0.3787],\n",
       "                      [-0.5039, -0.4399, -0.0838,  0.5146, -0.1454,  0.6024,  0.4886, -0.6213],\n",
       "                      [ 0.3023, -0.2761, -0.6245,  0.2295, -0.2249, -0.5816, -0.4607,  0.4817],\n",
       "                      [-0.1568,  0.5131, -0.2272,  0.6395, -0.1639,  0.6196,  0.2539, -0.4919],\n",
       "                      [ 0.2861,  0.2749, -0.5496, -0.5660,  0.0380,  0.3546,  0.5578, -0.1815],\n",
       "                      [-0.6131,  0.2990,  0.0456,  0.0167,  0.4133,  0.0782,  0.5675,  0.5026]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.fc2.weight',\n",
       "              tensor([[ 0.7474,  0.9287, -0.2774,  0.0204, -0.9733, -0.5424],\n",
       "                      [-0.2442, -0.3083, -0.3172,  0.7144, -0.8015,  0.1296],\n",
       "                      [ 1.0168, -0.4341,  0.5699,  1.2352, -0.9599,  0.5490],\n",
       "                      [-0.2039, -1.5605, -0.3479, -0.5299, -0.8855,  0.4160],\n",
       "                      [ 0.4687, -0.7291,  0.8913, -0.2827,  0.4013, -1.0291],\n",
       "                      [ 0.1189,  0.4724,  0.3677, -0.0171, -0.4013,  0.7755]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.0651,  0.3342,  0.2978, -0.5176, -0.5045, -0.3648],\n",
       "                      [ 0.2973,  0.5332, -0.3380,  0.1082,  0.0322,  0.2155],\n",
       "                      [ 0.2230,  0.0900,  0.3841, -0.1919,  0.5512, -0.0163],\n",
       "                      [-0.5233,  0.2814,  0.4065,  0.3871,  0.0635,  0.1953],\n",
       "                      [ 0.1792, -0.2465, -0.0231,  0.0136, -0.3197, -0.2154],\n",
       "                      [-0.2300, -0.0948, -0.3799,  0.3349, -0.0146,  0.4441],\n",
       "                      [-0.3707,  0.1603, -0.1894,  0.3059, -0.2309, -0.2863],\n",
       "                      [ 0.0459, -0.3311,  0.3984, -0.0218,  0.3236, -0.1694],\n",
       "                      [-0.1421, -0.5461,  0.1613,  0.1969,  0.3791,  0.0765],\n",
       "                      [-0.0552, -0.0776,  0.2355,  0.5522,  0.0371, -0.4871],\n",
       "                      [-0.5154,  0.2210,  0.5139, -0.3052,  0.2910,  0.4832],\n",
       "                      [ 0.5053,  0.3668, -0.3746,  0.4050,  0.0203, -0.3466]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.flattened_grn.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.special_days.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.special_days.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.special_days.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.month.mask',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.month.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.month.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.time_idx.fc1.weight',\n",
       "              tensor([[-4.8257e-01,  1.5503e-01, -1.7300e-01, -9.0854e-01,  1.8336e-01,\n",
       "                        1.0571e-01, -3.4245e-01, -3.6999e-01],\n",
       "                      [-4.9251e-01,  3.4639e-01, -4.4446e-01, -1.3633e-01,  1.0490e+00,\n",
       "                        9.6285e-02,  1.0478e-02, -5.5124e-01],\n",
       "                      [ 7.9754e-01, -3.8606e-02,  9.3410e-01, -1.0658e+00, -1.0946e-01,\n",
       "                        1.1824e-01,  1.6868e-01,  3.3027e-01],\n",
       "                      [ 1.2174e-01,  7.6243e-01,  2.8534e-01,  5.6863e-01,  3.1441e-01,\n",
       "                       -4.2515e-01,  1.1532e-01, -9.9504e-01],\n",
       "                      [ 4.2602e-01, -4.1546e-01,  1.9525e-01,  1.3903e-01,  9.5335e-01,\n",
       "                        6.5574e-02,  1.6105e-01,  2.6405e-01],\n",
       "                      [ 7.8148e-02, -5.2945e-01, -2.4535e-01, -6.9874e-01, -4.5013e-01,\n",
       "                        7.4189e-01, -7.0801e-01, -4.0139e-01],\n",
       "                      [-6.8750e-01,  2.6477e-01,  3.6074e-01, -6.7841e-04,  2.0912e-01,\n",
       "                       -8.4618e-01, -3.1863e-01, -7.9440e-01],\n",
       "                      [ 7.4124e-01,  2.6334e-01, -9.4677e-01,  1.8493e-01, -2.9716e-01,\n",
       "                        2.5001e-02, -1.0133e+00, -5.0481e-01]], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.time_idx.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.time_idx.fc2.weight',\n",
       "              tensor([[-0.0355,  0.3288, -0.5000,  0.0883,  0.1734,  0.5468, -0.3809,  0.0169],\n",
       "                      [ 0.5319,  0.2476,  0.0141,  0.4707, -0.1289,  0.5051,  0.6728, -0.0065],\n",
       "                      [-0.2206, -0.5603, -0.3661, -1.1569,  0.1945,  0.2052, -0.0482,  0.8774],\n",
       "                      [-0.5639,  0.9174, -0.1356,  0.0931,  0.2241,  0.3703, -0.1686, -1.0231],\n",
       "                      [ 0.2812, -0.1018,  0.4532,  0.7354,  0.7675, -1.2533, -0.2050, -0.0680],\n",
       "                      [-0.5274,  1.4274,  0.3327,  0.5151, -0.0174, -1.1441, -0.7599,  0.3086],\n",
       "                      [-0.0474, -0.1040, -0.1803,  0.0337, -0.2657, -0.2322, -0.0104,  0.1286],\n",
       "                      [-0.2233,  0.7069,  0.1213,  0.6810,  0.4623, -0.5873, -0.9216,  0.0918]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.time_idx.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.0778, -0.3437,  0.2968, -0.4646,  0.1708, -0.1988,  0.4276, -0.2626],\n",
       "                      [ 0.4664, -0.3640, -0.3307, -0.0513, -0.3480,  0.0508, -0.3574, -0.0527],\n",
       "                      [-0.0640, -0.1770,  0.0812, -0.2841,  0.2918, -0.1426, -0.2850, -0.1462],\n",
       "                      [ 0.1829, -0.2854, -0.4667, -0.1131, -0.3390,  0.4889, -0.1755,  0.1263],\n",
       "                      [-0.2356,  0.0123, -0.1101, -0.0729,  0.4142,  0.2102, -0.2535,  0.2586],\n",
       "                      [-0.3219,  0.3847, -0.4416, -0.4872,  0.4907,  0.2731,  0.0176, -0.3866],\n",
       "                      [ 0.3083, -0.2029,  0.1399,  0.0873,  0.3213, -0.1180,  0.4998, -0.3627],\n",
       "                      [-0.2265,  0.4924, -0.4413, -0.1524,  0.1562,  0.2000, -0.1596, -0.3923],\n",
       "                      [ 0.4226, -0.3837,  0.4759,  0.0374, -0.2858,  0.0702, -0.0168, -0.4162],\n",
       "                      [ 0.4338, -0.2920, -0.0894, -0.2678,  0.1100, -0.3352,  0.4286, -0.1327],\n",
       "                      [ 0.4666,  0.0022, -0.0805, -0.4486,  0.3139, -0.0032, -0.3976,  0.2415],\n",
       "                      [ 0.0760, -0.2734, -0.3005, -0.1008,  0.2342,  0.1614, -0.3089, -0.3506],\n",
       "                      [ 0.4188,  0.0975,  0.2439, -0.4712,  0.2360,  0.4340, -0.0156,  0.4055],\n",
       "                      [ 0.1059,  0.0195,  0.1746, -0.1751, -0.0530, -0.0979,  0.1290,  0.0497],\n",
       "                      [-0.2334,  0.2561, -0.2805,  0.3154,  0.0502, -0.0320, -0.0326,  0.1095],\n",
       "                      [ 0.0210,  0.4363,  0.4005,  0.4971,  0.3038,  0.0106, -0.1938, -0.1856]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.time_idx.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.time_idx.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.price_regular.fc1.weight',\n",
       "              tensor([[-0.0530,  0.0597,  0.2080, -0.3030, -0.2492,  1.1958, -0.1236, -0.6045],\n",
       "                      [ 0.5344,  0.0482, -0.1212,  1.0317,  0.0972, -0.2603,  0.8340,  1.1287],\n",
       "                      [-0.8014,  0.1023,  0.5665, -0.3993,  0.0082, -0.3292, -0.9469,  0.8900],\n",
       "                      [-0.3595,  1.2270, -0.2206,  0.4384,  0.9830,  0.2601, -0.5049,  0.0263],\n",
       "                      [ 0.6472, -0.3265,  0.6945, -0.3240,  0.0354, -0.2950, -0.1428, -0.2458],\n",
       "                      [ 0.2456, -0.4139, -0.2107, -0.4762,  0.3657, -0.3906, -0.4466, -1.1088],\n",
       "                      [ 0.5270, -0.1537, -0.6117, -0.1729, -0.6016, -0.3292,  0.4077,  0.5517],\n",
       "                      [-0.3348,  0.0917, -0.3148,  0.4705, -0.6037,  1.1698,  0.1656,  0.2252]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.price_regular.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.price_regular.fc2.weight',\n",
       "              tensor([[ 0.3240,  0.4981, -0.0398, -0.9215,  0.6741, -0.9924,  0.6704, -0.0207],\n",
       "                      [-0.7286,  0.1687, -0.6640,  0.2298,  0.0985,  0.6687, -0.2825,  0.1497],\n",
       "                      [-0.3276,  0.0022,  0.0968, -0.0853, -0.3093, -0.3582, -0.2305,  0.6460],\n",
       "                      [-0.2438,  0.8577,  0.6716, -0.7732, -0.0807, -0.2681,  0.2072,  0.2419],\n",
       "                      [-0.1441, -1.1096,  0.7147,  0.1964, -0.0441, -0.1016,  0.9127,  1.0235],\n",
       "                      [ 0.9164, -0.7012, -0.8821, -0.1791,  0.3890,  0.2524,  0.8282,  0.3331],\n",
       "                      [ 0.4448, -0.3906, -0.4492,  0.8447, -0.0407, -0.2734, -0.0018,  0.4183],\n",
       "                      [ 0.1717,  0.2412,  0.7756, -0.5824, -0.4962, -0.7523, -0.5914,  0.7216]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.price_regular.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.price_regular.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.0146, -0.1869, -0.2067, -0.1858,  0.4307, -0.0021, -0.4729, -0.0062],\n",
       "                      [-0.0222,  0.4239, -0.4219,  0.0025,  0.3895,  0.0578, -0.0130, -0.4468],\n",
       "                      [-0.3799, -0.1518, -0.4158,  0.1872,  0.1505, -0.4207,  0.4954,  0.0575],\n",
       "                      [ 0.3288, -0.1869,  0.4138,  0.4200, -0.4437, -0.2019, -0.3612, -0.0033],\n",
       "                      [-0.3386, -0.2127,  0.1840,  0.2292,  0.3832,  0.4547,  0.1606, -0.1053],\n",
       "                      [ 0.1071,  0.4736,  0.4755, -0.4968,  0.4513, -0.1540, -0.1712, -0.4459],\n",
       "                      [ 0.2608,  0.1488,  0.3460, -0.2571,  0.3333, -0.4680,  0.3668,  0.3530],\n",
       "                      [-0.4462, -0.3957,  0.0967,  0.2376,  0.4891,  0.2542, -0.3438,  0.1630],\n",
       "                      [-0.4605, -0.2533,  0.0777,  0.1440, -0.4409, -0.1189, -0.4053, -0.4428],\n",
       "                      [-0.0030, -0.0282,  0.1081,  0.3223, -0.4844, -0.2836, -0.1597, -0.3783],\n",
       "                      [ 0.4549,  0.4713, -0.4870, -0.4338, -0.2693, -0.1494,  0.0385, -0.4888],\n",
       "                      [-0.0670, -0.4029,  0.4664, -0.2980,  0.0850,  0.4959, -0.3967,  0.0219],\n",
       "                      [ 0.4476,  0.0056, -0.3687, -0.2288, -0.4307, -0.2571, -0.3254,  0.2306],\n",
       "                      [ 0.2833, -0.1184,  0.3905, -0.3055,  0.1798, -0.4429,  0.2915, -0.4959],\n",
       "                      [ 0.2924, -0.0328, -0.4427,  0.4528,  0.0713, -0.3723,  0.1323, -0.3224],\n",
       "                      [-0.3634,  0.0095, -0.0755, -0.3443,  0.3609,  0.1209, -0.2477,  0.2563]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.price_regular.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.price_regular.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.price_regular.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.discount_in_percent.fc1.weight',\n",
       "              tensor([[ 0.6699,  0.3298,  0.1296, -0.3240,  0.1790, -0.7367,  0.1661, -0.8094],\n",
       "                      [-0.0925,  0.1924,  0.1805, -0.2239,  0.5794, -0.4530,  0.0520,  0.1963],\n",
       "                      [ 1.0865,  0.0444, -0.6018,  0.7460,  0.0695, -0.2137, -0.9462, -0.5018],\n",
       "                      [ 0.6006, -1.0204, -0.2789,  0.2873,  1.2242, -0.0665, -0.3555, -0.5507],\n",
       "                      [-0.0507,  1.1096,  0.4365,  0.6244,  0.4530, -0.9584,  0.6031,  0.0617],\n",
       "                      [ 1.0462,  0.0867,  0.6285, -0.0545,  0.3785,  0.8128,  0.1097, -0.2985],\n",
       "                      [-0.3976,  1.0136,  0.4016, -0.2348,  0.0482,  0.5126, -0.3733,  0.1618],\n",
       "                      [-0.1268,  1.6059,  0.8670, -0.3406, -0.4137,  0.0828, -0.3019, -0.0918]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.discount_in_percent.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.discount_in_percent.fc2.weight',\n",
       "              tensor([[ 0.5303, -0.1462,  0.0311, -0.4377, -0.7741, -0.5207, -0.1057,  1.2122],\n",
       "                      [ 0.5526, -0.2184,  0.1003, -0.3249,  0.5937,  0.1993,  0.0589, -0.8914],\n",
       "                      [ 0.2372, -0.3685, -0.2563, -0.2842,  0.5063,  0.1168, -0.3548, -0.1644],\n",
       "                      [ 0.3132, -0.2821, -0.1039, -0.1921, -0.1081,  0.2063,  0.2440,  0.5106],\n",
       "                      [ 0.1568, -0.4804, -0.6952,  0.5108, -0.5019,  0.8871, -0.9592,  0.7640],\n",
       "                      [-0.1913, -0.0475,  0.1060, -0.4598, -0.2255, -0.4328, -0.1240,  0.7117],\n",
       "                      [-0.2534, -0.7514,  0.8037,  0.5585, -0.1998, -0.2715, -0.1410,  0.1101],\n",
       "                      [-0.1478,  0.3025,  0.4482,  0.4856, -1.0342,  1.2705,  0.3843,  0.7144]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.discount_in_percent.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.discount_in_percent.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.3472, -0.2144,  0.2879, -0.3438, -0.1005, -0.2740,  0.0213, -0.0591],\n",
       "                      [ 0.1492, -0.3878, -0.4410,  0.3976, -0.3828,  0.1686, -0.4342,  0.0974],\n",
       "                      [-0.0106, -0.2459, -0.0103,  0.0614,  0.0140,  0.3783, -0.2864,  0.2264],\n",
       "                      [ 0.4605, -0.3591, -0.3916,  0.1690, -0.1775, -0.0113, -0.4664,  0.3054],\n",
       "                      [-0.0330,  0.0307, -0.1738,  0.1736, -0.0082, -0.1993,  0.1242, -0.1857],\n",
       "                      [ 0.1856, -0.4789, -0.1935, -0.3426,  0.2127, -0.3511,  0.3874,  0.1217],\n",
       "                      [ 0.3064, -0.3262, -0.4062, -0.0821, -0.2747, -0.1694,  0.4110,  0.2672],\n",
       "                      [-0.1477,  0.3036, -0.3349, -0.2905,  0.2215,  0.2159, -0.1446, -0.3412],\n",
       "                      [ 0.0782,  0.4823,  0.4921,  0.4102, -0.3750,  0.3314,  0.0916, -0.4058],\n",
       "                      [ 0.0321, -0.4829,  0.1073, -0.2749, -0.3364,  0.0243,  0.3372,  0.2806],\n",
       "                      [-0.3094,  0.2844,  0.1860, -0.3338, -0.1290, -0.1198, -0.4064, -0.4562],\n",
       "                      [-0.3395,  0.4545, -0.1329,  0.0480, -0.4152, -0.0860,  0.1889, -0.0101],\n",
       "                      [-0.0393, -0.0067,  0.3362, -0.3522, -0.4490, -0.4816,  0.2033, -0.2785],\n",
       "                      [-0.2187, -0.0661,  0.2931,  0.0043,  0.0979, -0.1404,  0.2721, -0.2494],\n",
       "                      [ 0.3854,  0.4116, -0.4498, -0.1583, -0.0603, -0.2692,  0.0268, -0.1641],\n",
       "                      [ 0.4139, -0.0396, -0.2795, -0.2483, -0.4673, -0.3073,  0.0971,  0.1510]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.discount_in_percent.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.discount_in_percent.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.discount_in_percent.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.weight',\n",
       "              tensor([[ 0.4340, -0.4634, -0.4952,  0.3661,  0.2243,  0.4089,  0.3447,  0.1954],\n",
       "                      [ 0.2537,  0.5665,  0.4694, -0.5353, -0.1685,  1.0058,  0.5390,  0.6512],\n",
       "                      [-0.4489,  0.2481, -0.2946, -0.2770,  1.0957,  0.7634,  0.1269, -0.3811],\n",
       "                      [-0.1467,  0.0154,  1.2445, -0.1213,  0.1225, -0.1564,  0.4174,  0.0319],\n",
       "                      [ 0.3693,  0.1169,  0.1321,  0.5459, -0.1257,  0.7133, -0.5506,  0.4538],\n",
       "                      [ 0.0826,  0.3976, -0.4011, -0.3993, -0.3018,  0.3218, -0.5342, -0.7372],\n",
       "                      [ 0.5134, -0.6834, -0.1839, -0.8403, -0.6220,  0.2643, -1.0016, -0.1436],\n",
       "                      [-0.2461, -0.5913, -0.2137,  0.3031, -0.2653, -0.3538, -0.3967, -0.0553]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.relative_time_idx.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.weight',\n",
       "              tensor([[ 0.3598,  0.3224, -0.4878, -0.6529,  0.9081,  0.5102, -0.2761,  0.2617],\n",
       "                      [ 0.7468,  0.2338, -0.0895, -0.4093,  0.7878, -0.0432, -0.5325,  0.7425],\n",
       "                      [-0.1192,  0.2942,  0.6213,  0.5122, -0.1966, -0.2843, -0.5095,  0.1053],\n",
       "                      [-1.0342, -0.6519, -0.0258,  0.3639, -0.2284, -0.4765,  0.9149, -0.3652],\n",
       "                      [ 0.5844,  0.2585, -0.2661,  0.6907, -0.2725,  0.4711,  0.5618,  0.0876],\n",
       "                      [-0.4998, -1.1087,  0.0782, -0.1655, -0.0052,  0.5280,  0.7350, -0.1746],\n",
       "                      [-0.0324,  0.1354, -0.0386, -0.4606, -0.8043,  0.1081, -0.5975, -0.6328],\n",
       "                      [ 0.2137, -0.4284,  1.0761,  0.7038,  0.9627,  0.7400,  0.0367,  0.5081]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.relative_time_idx.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.3616, -0.1744, -0.4001, -0.3754,  0.2215, -0.1510,  0.3270,  0.0462],\n",
       "                      [ 0.1761,  0.0532, -0.4686, -0.0754, -0.2746, -0.1981,  0.4023, -0.3869],\n",
       "                      [-0.3651, -0.1603, -0.2219,  0.1234,  0.3208,  0.0785,  0.0088,  0.2402],\n",
       "                      [ 0.2986,  0.0176, -0.3376, -0.4333,  0.4990,  0.1626,  0.4578, -0.1919],\n",
       "                      [ 0.1375, -0.2633, -0.2632, -0.2288,  0.4997,  0.3645, -0.3077, -0.3527],\n",
       "                      [ 0.1649, -0.1179,  0.0239,  0.0638, -0.4378,  0.1104, -0.0044, -0.3499],\n",
       "                      [-0.4945,  0.2553, -0.4572, -0.2252,  0.3039, -0.3332, -0.2368, -0.3151],\n",
       "                      [ 0.2943,  0.1547,  0.0516,  0.1761,  0.1430, -0.1056, -0.0461, -0.3130],\n",
       "                      [-0.2349,  0.0077, -0.0607,  0.1259,  0.2373,  0.3836,  0.4791, -0.0380],\n",
       "                      [ 0.1972, -0.4050,  0.2894, -0.1337, -0.3967, -0.3893, -0.4169, -0.2309],\n",
       "                      [ 0.2283, -0.4078, -0.0590, -0.0777,  0.1839, -0.2038,  0.2533, -0.3092],\n",
       "                      [ 0.2938, -0.4982, -0.3405,  0.1754,  0.0767,  0.3502,  0.2604, -0.4166],\n",
       "                      [ 0.3932, -0.1298, -0.0944, -0.2129, -0.0867, -0.4668,  0.0387,  0.3768],\n",
       "                      [-0.0999,  0.3845, -0.2260,  0.2020,  0.0494, -0.1941,  0.4874,  0.0411],\n",
       "                      [ 0.0223, -0.0540, -0.0271,  0.4031, -0.0761,  0.3003,  0.1813,  0.3261],\n",
       "                      [-0.3789, -0.4381, -0.1642, -0.1396,  0.4764,  0.4927, -0.1192, -0.2396]],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.single_variable_grns.relative_time_idx.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('decoder_variable_selection.prescalers.time_idx.weight',\n",
       "              tensor([[ 0.9337],\n",
       "                      [-0.4100],\n",
       "                      [-0.7154],\n",
       "                      [-0.5596],\n",
       "                      [-0.2772],\n",
       "                      [-0.4745],\n",
       "                      [-0.5189],\n",
       "                      [ 0.4039]], device='cuda:0')),\n",
       "             ('decoder_variable_selection.prescalers.time_idx.bias',\n",
       "              tensor([ 0.1699, -0.3201, -0.7769, -0.3149, -0.4220, -0.3254, -0.9021,  0.2154],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.prescalers.price_regular.weight',\n",
       "              tensor([[-0.7347],\n",
       "                      [-0.7788],\n",
       "                      [-0.8170],\n",
       "                      [ 0.4174],\n",
       "                      [-0.6020],\n",
       "                      [-0.4128],\n",
       "                      [ 0.7838],\n",
       "                      [ 0.5310]], device='cuda:0')),\n",
       "             ('decoder_variable_selection.prescalers.price_regular.bias',\n",
       "              tensor([ 0.5734, -0.9495, -0.7171, -0.3775,  0.8261,  0.1023, -0.7479,  0.0063],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.prescalers.discount_in_percent.weight',\n",
       "              tensor([[-0.7767],\n",
       "                      [-0.2191],\n",
       "                      [-0.2750],\n",
       "                      [ 0.8657],\n",
       "                      [ 0.3097],\n",
       "                      [-0.1744],\n",
       "                      [ 0.1689],\n",
       "                      [-0.2887]], device='cuda:0')),\n",
       "             ('decoder_variable_selection.prescalers.discount_in_percent.bias',\n",
       "              tensor([ 0.3929,  0.3956,  0.2685, -0.3898,  0.8532, -0.1444, -0.3893,  0.6263],\n",
       "                     device='cuda:0')),\n",
       "             ('decoder_variable_selection.prescalers.relative_time_idx.weight',\n",
       "              tensor([[ 0.8151],\n",
       "                      [ 0.9952],\n",
       "                      [ 0.2963],\n",
       "                      [-0.3409],\n",
       "                      [ 0.5079],\n",
       "                      [ 0.8580],\n",
       "                      [-0.9808],\n",
       "                      [-0.1239]], device='cuda:0')),\n",
       "             ('decoder_variable_selection.prescalers.relative_time_idx.bias',\n",
       "              tensor([-0.6820,  0.1864,  0.4136, -0.2066, -0.0837,  0.4501, -0.1681, -0.8398],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_variable_selection.fc1.weight',\n",
       "              tensor([[-0.1711,  0.4614,  0.0835,  0.5530, -0.3445,  0.1129, -0.1857,  1.4104],\n",
       "                      [ 0.1126,  0.1031,  0.8993,  1.3501,  0.3692,  0.1330,  0.3340, -0.3774],\n",
       "                      [-0.3908, -0.2517, -0.1007, -0.0282, -0.3245, -0.1190, -0.4085,  0.6492],\n",
       "                      [ 0.0061,  0.4312, -0.8652,  0.1259,  0.1738,  0.5400, -0.9754, -0.0052],\n",
       "                      [ 0.1561,  0.1894,  0.4783, -0.3175,  0.2717,  0.2646,  0.1397,  0.2272],\n",
       "                      [ 0.2028, -0.5260, -0.2891,  0.2068, -0.0603, -0.3145,  0.1958, -1.0036],\n",
       "                      [-0.6858,  0.9015, -0.2446,  0.3884,  0.2619,  0.7737, -0.1637,  0.0877],\n",
       "                      [ 0.1576, -0.5539, -0.0672, -0.9742,  0.5954,  0.2889, -0.3146, -0.9360]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_variable_selection.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_variable_selection.fc2.weight',\n",
       "              tensor([[ 0.7130,  0.4930, -0.9391, -0.2807,  0.5188,  0.5834,  0.3482,  0.2016],\n",
       "                      [ 0.0155, -0.5405,  0.0455, -0.2454,  0.6786,  0.5767, -0.2200, -0.2693],\n",
       "                      [-0.3690, -1.0267, -1.0666,  0.8898,  0.8320, -0.2938,  0.6895,  0.0059],\n",
       "                      [ 0.7743,  0.3103,  0.1647, -0.0384, -0.5431, -0.4470, -0.1485,  0.1908],\n",
       "                      [-0.6548,  0.1268,  0.1112,  0.6378, -0.7269, -0.3145, -0.3012,  0.7469],\n",
       "                      [ 0.1609, -0.1962,  0.1626, -0.5677,  0.1087,  0.4706,  0.0799,  0.6532],\n",
       "                      [ 0.4074,  0.2196,  0.0790, -0.1051, -0.5164, -0.8409, -0.3372, -0.3236],\n",
       "                      [ 0.3109,  0.5732, -0.2515, -0.8508,  1.2357, -0.0433,  0.1819, -0.0147]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_variable_selection.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_variable_selection.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.1379, -0.2970,  0.2146, -0.4992, -0.4297, -0.4407, -0.1717, -0.3856],\n",
       "                      [-0.0997, -0.2845,  0.3214,  0.4387,  0.1934, -0.1940,  0.2040, -0.4293],\n",
       "                      [-0.2501, -0.1048, -0.4675,  0.4689,  0.3276,  0.2316,  0.2350,  0.4920],\n",
       "                      [-0.1901,  0.1199, -0.1681, -0.0849, -0.4099,  0.2990, -0.3602, -0.2235],\n",
       "                      [ 0.4457, -0.2934,  0.0643, -0.4589, -0.2904,  0.4536,  0.2689,  0.0212],\n",
       "                      [-0.2493,  0.3813,  0.4706,  0.1002, -0.3223,  0.0172,  0.2436,  0.1460],\n",
       "                      [ 0.4499,  0.4503,  0.2533, -0.3478, -0.0270,  0.0968, -0.1668,  0.1496],\n",
       "                      [ 0.3264, -0.2701, -0.1524, -0.3803,  0.0777,  0.2993,  0.4522,  0.0262],\n",
       "                      [ 0.3256, -0.4829, -0.0109, -0.0943, -0.2303,  0.4629,  0.3122, -0.4167],\n",
       "                      [-0.4541, -0.2342,  0.1697,  0.2372,  0.2588,  0.3865, -0.3200,  0.0422],\n",
       "                      [-0.2228, -0.2426,  0.0048, -0.0440, -0.4051, -0.0073,  0.2404,  0.4484],\n",
       "                      [-0.1351,  0.3381, -0.1118, -0.3678,  0.4325, -0.1182, -0.1162, -0.0846],\n",
       "                      [ 0.4507, -0.2135, -0.1328,  0.0291, -0.3274,  0.1950,  0.4210,  0.1808],\n",
       "                      [-0.1202, -0.0957, -0.4900, -0.3942, -0.1371,  0.2772,  0.4651, -0.0350],\n",
       "                      [-0.0480,  0.3421, -0.1049, -0.3411,  0.2831, -0.2162, -0.3561,  0.0043],\n",
       "                      [-0.3327, -0.3900, -0.2756, -0.0434,  0.1664, -0.2072, -0.4782, -0.1702]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_variable_selection.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_variable_selection.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_context_variable_selection.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_initial_hidden_lstm.fc1.weight',\n",
       "              tensor([[-0.8666,  0.8050, -0.1142, -0.0055, -0.1782, -0.4793,  0.7412, -0.0051],\n",
       "                      [-0.3674, -0.1237, -0.5143, -0.5396,  0.2030,  0.1300,  0.3663,  0.1015],\n",
       "                      [ 0.3757, -0.6169, -0.7832,  0.1512,  0.0501, -0.2913, -0.0931, -0.2453],\n",
       "                      [ 0.5917, -0.4182, -0.4225, -0.3167, -0.7165, -0.2046, -0.2484, -0.3523],\n",
       "                      [-0.0875,  0.2206, -0.1741,  0.2887, -0.6274, -0.3831, -0.8423,  0.4039],\n",
       "                      [-0.0783, -0.3286, -0.1336,  0.1860, -0.2544, -1.2775, -0.4760, -0.1127],\n",
       "                      [ 0.3282, -0.2769,  1.0202,  0.1038, -0.2908, -0.4191,  0.4656,  1.1560],\n",
       "                      [-1.0669,  0.2190, -0.1410,  0.1273, -0.1928, -0.6565, -0.3810, -0.0786]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_initial_hidden_lstm.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_initial_hidden_lstm.fc2.weight',\n",
       "              tensor([[-0.4661, -0.4028, -0.6823, -0.8656, -0.5802,  0.5486,  0.4396, -0.2832],\n",
       "                      [-0.6810, -0.0035,  0.8343, -0.4246,  0.0121,  0.8236,  0.4900, -0.4740],\n",
       "                      [ 0.4167,  0.4065,  0.5343, -0.2823,  0.8650,  0.1592, -0.6080,  0.0744],\n",
       "                      [-0.0924,  0.4401,  1.0650,  0.9675, -0.0616, -0.8375, -0.7363, -0.2906],\n",
       "                      [ 0.0032,  0.0091,  0.0830,  0.4437,  0.0542, -0.0381, -0.2006,  0.1344],\n",
       "                      [-0.1065, -0.1077,  0.7255, -0.1698, -0.8181,  0.2774,  1.3316, -0.1221],\n",
       "                      [-0.0539, -0.0950, -0.7475,  0.4965,  0.0152,  0.6600, -0.6611,  0.3337],\n",
       "                      [ 0.4833, -0.6096,  0.3073, -0.6437, -0.3786, -0.7808,  0.3004, -0.6553]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_initial_hidden_lstm.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_initial_hidden_lstm.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.1688,  0.1780,  0.4626, -0.1188,  0.2166,  0.2013, -0.0799,  0.0995],\n",
       "                      [ 0.1661,  0.4464, -0.1887,  0.3846, -0.0323,  0.1972, -0.4054,  0.3360],\n",
       "                      [ 0.4214,  0.1165,  0.0153,  0.1305, -0.3949, -0.4310,  0.3724, -0.4490],\n",
       "                      [-0.1120, -0.3062, -0.4667, -0.2122, -0.0040, -0.4012, -0.3833, -0.4033],\n",
       "                      [-0.0181, -0.1332,  0.3674, -0.4786, -0.4367, -0.1524,  0.5000,  0.4554],\n",
       "                      [-0.0647, -0.1363,  0.0691,  0.0210,  0.0470, -0.2161, -0.0243,  0.0962],\n",
       "                      [ 0.2988, -0.3154, -0.1017,  0.2511,  0.3291,  0.2708, -0.1213,  0.1140],\n",
       "                      [-0.1711,  0.4247,  0.2840, -0.4512,  0.2429,  0.4908,  0.1337, -0.3966],\n",
       "                      [ 0.3216,  0.0268, -0.1342,  0.2182,  0.3882,  0.2269, -0.3942,  0.2087],\n",
       "                      [-0.3085, -0.4670, -0.2480,  0.2630,  0.3844,  0.1476,  0.3073, -0.4771],\n",
       "                      [-0.2435, -0.2853, -0.4248, -0.3122, -0.3570, -0.4178,  0.0730, -0.2331],\n",
       "                      [ 0.0206, -0.0801,  0.0344, -0.4542, -0.4101, -0.4521,  0.3480,  0.0166],\n",
       "                      [-0.4256, -0.1924, -0.0052, -0.3309,  0.4045,  0.3588,  0.1202, -0.0861],\n",
       "                      [ 0.2908,  0.1309,  0.0426,  0.0617, -0.4352,  0.1416,  0.1826,  0.3085],\n",
       "                      [ 0.2371,  0.4256, -0.2658,  0.0410, -0.3682,  0.4293, -0.0233, -0.4321],\n",
       "                      [ 0.3241,  0.0590, -0.1441,  0.4473, -0.2633, -0.2481, -0.1716,  0.0573]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_initial_hidden_lstm.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_initial_hidden_lstm.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_context_initial_hidden_lstm.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_initial_cell_lstm.fc1.weight',\n",
       "              tensor([[-0.7092, -0.3552, -0.0681,  0.7694,  0.8074, -0.2330, -0.5418,  1.2064],\n",
       "                      [ 0.2162,  0.5516,  0.0131,  0.4127,  0.2864,  0.1084,  1.0171, -0.4476],\n",
       "                      [-0.3190,  0.4224,  0.0556,  0.6263, -0.0585,  0.1216, -0.9516, -0.7560],\n",
       "                      [ 0.8292, -0.2133,  0.0234,  0.3726, -0.5501, -0.3451,  0.7325,  0.5161],\n",
       "                      [ 0.0832, -0.4477,  0.1169, -0.0465, -0.1884,  0.3121,  0.0624,  0.6832],\n",
       "                      [-0.0236,  0.5910, -0.5645, -0.2538,  0.1612,  0.8156,  0.1962,  0.0488],\n",
       "                      [ 0.5265, -0.1845, -0.4798, -0.4989, -0.3454,  0.1981, -1.2674, -0.6973],\n",
       "                      [-0.3841,  0.6661, -0.0323,  0.6938, -0.4401, -0.7000, -0.7285,  1.1110]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_initial_cell_lstm.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_initial_cell_lstm.fc2.weight',\n",
       "              tensor([[-0.4831, -0.1877, -0.1771, -0.4307,  0.3010,  0.2106, -0.7501,  0.2838],\n",
       "                      [-0.4536, -0.1856,  0.0318, -0.2855,  0.4603,  0.4551, -0.2900, -0.6747],\n",
       "                      [ 0.0932,  0.1346,  0.2540, -0.0208,  0.3193, -0.4626,  0.2397,  0.0397],\n",
       "                      [ 0.5996, -1.2360,  1.0519, -0.0045,  0.2348,  0.5884, -0.5155, -0.7412],\n",
       "                      [-0.0490,  0.8370,  0.1166,  0.1643, -1.1462, -0.4668, -0.5731, -0.7164],\n",
       "                      [-0.2695,  0.2669, -0.5142, -0.1861, -0.4667,  0.5798, -0.2716, -0.1563],\n",
       "                      [-0.3224,  0.1688,  0.6509, -0.1879, -0.6129, -0.4248,  0.8334,  0.2449],\n",
       "                      [ 0.5791,  0.2766, -0.6500,  0.5856, -0.0323,  0.0938, -0.8129,  0.1280]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_initial_cell_lstm.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_initial_cell_lstm.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.3616, -0.2162,  0.4302,  0.1986,  0.2799,  0.3332, -0.0050, -0.3339],\n",
       "                      [ 0.4791,  0.0824, -0.1799,  0.2012, -0.3511,  0.0176,  0.4643,  0.1648],\n",
       "                      [-0.4687,  0.4360,  0.1067, -0.1336,  0.3933,  0.2221,  0.2921,  0.2446],\n",
       "                      [-0.2800, -0.3613,  0.3591, -0.0309,  0.4060,  0.2484, -0.4820,  0.2733],\n",
       "                      [ 0.2493, -0.4814,  0.0295, -0.3995,  0.2449,  0.2661,  0.1522,  0.3130],\n",
       "                      [-0.2774, -0.0174, -0.1355,  0.3822,  0.3569, -0.1764, -0.4243, -0.0174],\n",
       "                      [ 0.3908, -0.1079,  0.1840, -0.3635, -0.3324, -0.4291, -0.4301, -0.2032],\n",
       "                      [-0.2132,  0.1931,  0.4121,  0.0614,  0.2015, -0.3195, -0.2166, -0.4671],\n",
       "                      [ 0.4682,  0.0534, -0.1370, -0.4569,  0.0937, -0.4907,  0.3361, -0.4690],\n",
       "                      [ 0.1070,  0.3103, -0.4040,  0.3672,  0.4800,  0.3494,  0.4540, -0.2339],\n",
       "                      [-0.0877,  0.4486,  0.2369, -0.3394,  0.4925, -0.0845, -0.1626,  0.0689],\n",
       "                      [ 0.4811, -0.2520,  0.0439, -0.0588, -0.1498,  0.2306,  0.0301, -0.4102],\n",
       "                      [-0.0123,  0.3159, -0.2371,  0.4442, -0.4119,  0.1693,  0.3101,  0.1753],\n",
       "                      [ 0.1975,  0.0735, -0.1053,  0.3583, -0.1108,  0.4202,  0.4783, -0.4329],\n",
       "                      [ 0.4066,  0.1244, -0.3410, -0.2779, -0.0690,  0.4674,  0.3053, -0.1330],\n",
       "                      [-0.2985, -0.3236, -0.2526, -0.0113, -0.4341, -0.4463, -0.3140,  0.1378]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_initial_cell_lstm.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_initial_cell_lstm.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_context_initial_cell_lstm.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_enrichment.fc1.weight',\n",
       "              tensor([[-4.6581e-01, -8.8444e-03,  6.3243e-01, -2.9451e-02, -1.1252e-01,\n",
       "                        7.1322e-02, -3.1697e-01,  6.3817e-01],\n",
       "                      [-8.1886e-04, -6.7031e-01,  9.9262e-01, -1.7047e-01,  5.4272e-01,\n",
       "                       -1.4183e-01,  3.3686e-01, -4.0965e-01],\n",
       "                      [-1.4428e-01,  3.4323e-01,  8.9370e-02, -3.7631e-01, -4.1443e-02,\n",
       "                       -2.3276e-01,  9.8813e-01,  4.2492e-01],\n",
       "                      [ 6.0635e-01,  6.6191e-01, -2.3824e-01,  5.3302e-01, -1.0071e+00,\n",
       "                       -9.3958e-02, -2.0829e-01,  6.3184e-01],\n",
       "                      [-3.3885e-01,  7.0398e-01,  4.6155e-03,  4.5503e-01, -4.0437e-01,\n",
       "                       -1.4512e+00,  7.9544e-01,  1.3188e-01],\n",
       "                      [-4.0775e-01, -3.7273e-01, -3.8302e-01, -1.3475e-01,  2.8989e-01,\n",
       "                       -4.6813e-01, -5.7065e-02, -3.3068e-02],\n",
       "                      [-4.3015e-02,  6.0891e-01, -2.3896e-01,  4.1862e-01, -3.0832e-01,\n",
       "                        5.3646e-01,  4.2855e-01, -3.6291e-01],\n",
       "                      [ 4.6469e-01, -3.0671e-01,  5.5697e-01, -1.1144e+00,  2.6362e-01,\n",
       "                        2.3132e-02,  6.2512e-01, -3.7771e-01]], device='cuda:0')),\n",
       "             ('static_context_enrichment.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_enrichment.fc2.weight',\n",
       "              tensor([[ 0.4078,  0.3599,  0.7435,  0.6495,  0.0202, -0.5196, -0.7166, -0.4735],\n",
       "                      [ 0.9000,  0.3890, -0.5662, -0.1618, -0.7893, -1.5456,  0.6373, -0.9314],\n",
       "                      [ 0.1611, -0.5653, -1.2196,  0.1170,  0.0036, -0.5471,  0.8359,  0.1216],\n",
       "                      [-0.3522, -0.0797, -0.4813, -0.2977, -0.2039,  0.0985,  0.1286, -0.0550],\n",
       "                      [-0.2062,  0.1036,  0.7417,  0.1332, -0.3647,  0.3482, -0.1526, -0.3129],\n",
       "                      [-0.4048, -0.3390, -0.0084,  0.9415, -0.5389, -0.0087,  0.0150,  0.7311],\n",
       "                      [ 0.0267,  0.5954, -0.1578,  0.2778, -0.0956,  0.4062,  0.4813,  0.7641],\n",
       "                      [-0.2395,  0.0116,  0.3424, -0.0989,  0.0575, -0.6691,  0.2181, -0.2116]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_enrichment.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_context_enrichment.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.4953,  0.4768, -0.4321,  0.3535, -0.1941, -0.3691, -0.1719,  0.2421],\n",
       "                      [ 0.3816, -0.4182, -0.3728,  0.1698,  0.2387, -0.3211,  0.2081, -0.0700],\n",
       "                      [-0.4363,  0.2801, -0.4188, -0.0283, -0.1081, -0.2298, -0.0808, -0.4463],\n",
       "                      [ 0.4426, -0.3740,  0.3086,  0.0173, -0.0223, -0.0364, -0.2134, -0.0906],\n",
       "                      [ 0.3598, -0.2375,  0.2281, -0.4034, -0.2472,  0.3458,  0.1829, -0.4541],\n",
       "                      [-0.3502,  0.3236, -0.0343,  0.4645, -0.4931,  0.1326, -0.4945,  0.2081],\n",
       "                      [-0.1693, -0.0530, -0.0617,  0.0643, -0.3365, -0.2774,  0.2179, -0.2893],\n",
       "                      [ 0.1399, -0.0591,  0.3158, -0.1258,  0.3524, -0.0133, -0.2778,  0.0944],\n",
       "                      [-0.3073,  0.1205, -0.2400,  0.0604, -0.0942, -0.1295, -0.4315, -0.1678],\n",
       "                      [ 0.4175,  0.2819, -0.2091,  0.0586,  0.1251,  0.3072,  0.3412, -0.2745],\n",
       "                      [-0.1187,  0.4104,  0.0512, -0.2769, -0.2513, -0.2478, -0.4713, -0.3355],\n",
       "                      [ 0.4965, -0.0602,  0.3335, -0.4626,  0.2358,  0.1927, -0.4678, -0.1211],\n",
       "                      [ 0.1309, -0.3929,  0.1922,  0.2911, -0.4550, -0.1925,  0.3507, -0.0445],\n",
       "                      [-0.2924,  0.1250, -0.4144,  0.1670, -0.2891,  0.1817, -0.2657, -0.1494],\n",
       "                      [-0.2321,  0.2614, -0.4585,  0.3027,  0.2597, -0.3521,  0.3376,  0.3710],\n",
       "                      [-0.3150,  0.0457,  0.1252, -0.0688,  0.3637, -0.1270, -0.1715,  0.1411]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_enrichment.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_context_enrichment.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_context_enrichment.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('lstm_encoder.weight_ih_l0',\n",
       "              tensor([[ 0.1899,  0.2793, -0.3520, -0.0877, -0.1564, -0.1293, -0.0963, -0.1990],\n",
       "                      [-0.2087, -0.1912, -0.2397,  0.1403,  0.1938, -0.1610,  0.3336,  0.1298],\n",
       "                      [-0.2683,  0.1681,  0.0315,  0.3006, -0.0309, -0.1426,  0.2749, -0.3250],\n",
       "                      [ 0.1516, -0.3024, -0.0846, -0.0355, -0.3326, -0.1962, -0.1415, -0.0484],\n",
       "                      [ 0.0724, -0.2456,  0.2887,  0.0537,  0.0437,  0.0794, -0.2232, -0.0055],\n",
       "                      [-0.3123,  0.3426, -0.1325, -0.3280,  0.0312, -0.2589, -0.3031, -0.2488],\n",
       "                      [-0.0523,  0.1246, -0.3534, -0.0527, -0.0809, -0.1540,  0.1464,  0.2475],\n",
       "                      [ 0.0427, -0.1354,  0.1113, -0.1580, -0.0219,  0.1993, -0.0691,  0.3406],\n",
       "                      [ 0.3500,  0.1014, -0.0339, -0.0846,  0.1444,  0.0533, -0.2984, -0.3015],\n",
       "                      [ 0.0025,  0.0888,  0.2203,  0.2512,  0.1124,  0.2618,  0.2605, -0.2594],\n",
       "                      [ 0.3358, -0.1700, -0.2238,  0.0463, -0.2385,  0.0264,  0.0124,  0.1079],\n",
       "                      [-0.2018,  0.1798,  0.2627,  0.0329,  0.1657, -0.2020,  0.1505, -0.2067],\n",
       "                      [-0.1256, -0.0667, -0.0022,  0.3197,  0.0521,  0.3499,  0.0834, -0.1104],\n",
       "                      [-0.1169, -0.0346, -0.2320,  0.1372,  0.3162,  0.2032,  0.2162,  0.3433],\n",
       "                      [ 0.0457, -0.0215, -0.1195, -0.2960, -0.2341, -0.0191, -0.2493, -0.2438],\n",
       "                      [ 0.0584, -0.2032, -0.2938, -0.2456,  0.1354,  0.0486, -0.3361, -0.2853],\n",
       "                      [ 0.1412,  0.3311,  0.1225,  0.1779, -0.0164,  0.1495,  0.1792, -0.1899],\n",
       "                      [ 0.1793, -0.0957,  0.1257, -0.3331, -0.1916, -0.2076, -0.1432,  0.3240],\n",
       "                      [-0.1737,  0.0934, -0.0326,  0.0558, -0.1580, -0.2046, -0.2875,  0.0288],\n",
       "                      [-0.3247, -0.3279,  0.3164,  0.1482, -0.0580, -0.1645,  0.3128, -0.0153],\n",
       "                      [-0.2946,  0.2524,  0.3290,  0.0645,  0.2543, -0.2834,  0.0098,  0.3466],\n",
       "                      [-0.3477, -0.3348,  0.0314,  0.0944,  0.0888, -0.1011,  0.2952,  0.2559],\n",
       "                      [-0.3492, -0.3360,  0.2999, -0.1439,  0.0678,  0.1249,  0.0813, -0.1823],\n",
       "                      [-0.2409, -0.2734,  0.1461, -0.0450, -0.2058, -0.2856,  0.1909,  0.0481],\n",
       "                      [-0.3388, -0.0193, -0.0963, -0.0099,  0.0875,  0.1232, -0.3324,  0.0515],\n",
       "                      [ 0.1828, -0.0826,  0.2719,  0.3463,  0.0983,  0.3393,  0.1503, -0.2362],\n",
       "                      [ 0.2210, -0.1507, -0.2537, -0.3187,  0.0311,  0.3182, -0.1218,  0.0566],\n",
       "                      [ 0.1149,  0.2186,  0.2986,  0.1875, -0.1259, -0.0100, -0.3389, -0.2741],\n",
       "                      [-0.1918,  0.2107,  0.0610, -0.0011,  0.2332, -0.0325,  0.2695,  0.3325],\n",
       "                      [-0.2871,  0.2808,  0.2238, -0.0401,  0.1062, -0.2376, -0.1118, -0.2012],\n",
       "                      [-0.2459, -0.0590, -0.3524, -0.0662,  0.2253, -0.2181, -0.1157,  0.0144],\n",
       "                      [-0.1536,  0.0325, -0.3259,  0.0955,  0.3308,  0.0216,  0.3445, -0.3114]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm_encoder.weight_hh_l0',\n",
       "              tensor([[-0.1837, -0.1074,  0.3022, -0.3239, -0.0643, -0.3166,  0.0680, -0.3071],\n",
       "                      [-0.2904, -0.2200, -0.1358,  0.2245,  0.0572, -0.3187,  0.3343, -0.0072],\n",
       "                      [ 0.1033, -0.1826, -0.1667, -0.2648, -0.2780, -0.1807,  0.1951, -0.1346],\n",
       "                      [-0.3000,  0.1036, -0.0929, -0.2534,  0.2863, -0.3299, -0.3438,  0.2043],\n",
       "                      [ 0.1965, -0.1353,  0.2499, -0.2325, -0.1663, -0.0509, -0.1183,  0.2286],\n",
       "                      [-0.3286,  0.2863,  0.2025, -0.1949, -0.1863,  0.0550, -0.0269, -0.3135],\n",
       "                      [ 0.2892,  0.2782,  0.2829,  0.1679, -0.2461, -0.1860, -0.1493,  0.0981],\n",
       "                      [ 0.1906, -0.0167, -0.3479, -0.2241, -0.1691, -0.2380,  0.1820,  0.0158],\n",
       "                      [-0.2523, -0.2145, -0.2583, -0.2449,  0.1326, -0.1857, -0.3027,  0.0255],\n",
       "                      [-0.0212, -0.2931,  0.0953,  0.0302,  0.0462,  0.1553, -0.1785, -0.3089],\n",
       "                      [ 0.2285,  0.3207,  0.3284,  0.1887,  0.3250,  0.0998, -0.3085,  0.1052],\n",
       "                      [-0.2704, -0.3331,  0.1368, -0.1873, -0.2554,  0.3339,  0.1127,  0.1511],\n",
       "                      [-0.1055,  0.1322, -0.0056, -0.0826, -0.0675,  0.2624, -0.2417, -0.1090],\n",
       "                      [ 0.2582, -0.0165,  0.1736, -0.1499,  0.2372, -0.2513, -0.1896, -0.3110],\n",
       "                      [-0.2824,  0.2226,  0.2286,  0.1895,  0.1750,  0.2398,  0.2151,  0.2081],\n",
       "                      [-0.1736,  0.2649,  0.2348,  0.1095, -0.0637,  0.3091, -0.0235, -0.3296],\n",
       "                      [-0.1328, -0.0090,  0.1681,  0.0951,  0.0612,  0.3008,  0.2311, -0.2008],\n",
       "                      [-0.1282, -0.0337, -0.0201, -0.2696, -0.0947,  0.2678, -0.3428,  0.0509],\n",
       "                      [ 0.0716, -0.1129, -0.1203, -0.1772, -0.3213, -0.3188,  0.1880, -0.0106],\n",
       "                      [-0.0154, -0.0580, -0.3344, -0.0577, -0.3260,  0.1742, -0.1241, -0.1201],\n",
       "                      [ 0.1245, -0.2423, -0.2301, -0.1962, -0.0797, -0.2234, -0.3522,  0.1581],\n",
       "                      [ 0.1922, -0.1459, -0.2719,  0.2393, -0.2147, -0.2741, -0.3189,  0.0876],\n",
       "                      [ 0.0802,  0.3365, -0.1390, -0.2209,  0.3454,  0.2430, -0.3129, -0.3311],\n",
       "                      [ 0.1316, -0.1761,  0.0616, -0.0232, -0.1100,  0.3018,  0.1159,  0.1064],\n",
       "                      [-0.2654, -0.1241,  0.1653,  0.1943,  0.0376, -0.3463, -0.1902,  0.3484],\n",
       "                      [ 0.2871,  0.1862, -0.2064, -0.1907,  0.1279, -0.2960, -0.0413,  0.1354],\n",
       "                      [ 0.1394,  0.1739,  0.0211,  0.2373, -0.3457, -0.1824, -0.1090,  0.2067],\n",
       "                      [-0.2760,  0.2607, -0.2048, -0.1068,  0.2616,  0.3461,  0.1060, -0.0755],\n",
       "                      [ 0.2501, -0.0171,  0.2131,  0.1432, -0.0077,  0.3336,  0.1704,  0.3320],\n",
       "                      [ 0.3339,  0.0683, -0.1654, -0.1189, -0.0563, -0.1154,  0.0369,  0.3437],\n",
       "                      [ 0.2329,  0.0968,  0.1838, -0.1996,  0.1421,  0.3097,  0.1143,  0.0054],\n",
       "                      [ 0.2855, -0.2907,  0.1996, -0.0685, -0.3259,  0.1982, -0.0707, -0.0794]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm_encoder.bias_ih_l0',\n",
       "              tensor([-0.1616, -0.1167, -0.0543, -0.3472,  0.1719,  0.0456,  0.1313,  0.3518,\n",
       "                      -0.0789, -0.2122, -0.2296, -0.0487, -0.0688,  0.1259,  0.0251,  0.1178,\n",
       "                      -0.1802, -0.3044,  0.0132,  0.0748, -0.1691, -0.1262, -0.0623, -0.3161,\n",
       "                       0.3300,  0.2547, -0.2581, -0.3369,  0.3078,  0.2935, -0.3175,  0.0749],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm_encoder.bias_hh_l0',\n",
       "              tensor([-0.2246, -0.2602, -0.2459,  0.0111,  0.3265,  0.1648, -0.3265,  0.1906,\n",
       "                       0.3209,  0.2495,  0.3266, -0.2056, -0.1799,  0.1965, -0.2785, -0.1000,\n",
       "                       0.2538,  0.1086, -0.0946,  0.1414, -0.1653, -0.1792,  0.1061, -0.1706,\n",
       "                       0.2460,  0.1576,  0.2147,  0.2538,  0.0446, -0.1305, -0.2970, -0.1024],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm_decoder.weight_ih_l0',\n",
       "              tensor([[-0.2974,  0.2149,  0.0275, -0.1502, -0.0110,  0.2551, -0.1549,  0.0682],\n",
       "                      [ 0.0425, -0.0479, -0.0822,  0.1324, -0.1141, -0.2903,  0.0798, -0.2056],\n",
       "                      [-0.1812,  0.0099,  0.1701, -0.1026, -0.2123,  0.1634, -0.2184,  0.0763],\n",
       "                      [ 0.1006, -0.0084, -0.0909, -0.0476, -0.2000,  0.2325, -0.0316, -0.1478],\n",
       "                      [-0.1937,  0.1562, -0.2182,  0.1460,  0.0011, -0.3265,  0.2259,  0.1393],\n",
       "                      [ 0.1493, -0.1586, -0.3075,  0.1667, -0.2755,  0.1677,  0.3063, -0.0439],\n",
       "                      [-0.2865,  0.2652, -0.3387, -0.1171, -0.2622,  0.1500,  0.3196, -0.2261],\n",
       "                      [-0.2030,  0.2867,  0.1736,  0.2475, -0.2534,  0.3304, -0.1284, -0.1954],\n",
       "                      [-0.1182,  0.0228,  0.2064, -0.0904, -0.2388,  0.0572, -0.3404, -0.2816],\n",
       "                      [ 0.0761,  0.3147, -0.2043,  0.2004, -0.2201, -0.1214,  0.3507,  0.0960],\n",
       "                      [-0.1492, -0.1592,  0.0778,  0.2198,  0.2658,  0.0260, -0.1784,  0.1763],\n",
       "                      [-0.2960, -0.0113, -0.3258, -0.0742, -0.0021,  0.2896,  0.0810, -0.2386],\n",
       "                      [ 0.1623,  0.0093, -0.2249, -0.2991,  0.0731, -0.2032, -0.1353, -0.1811],\n",
       "                      [-0.2633, -0.2288, -0.0526, -0.0087,  0.2387, -0.2902,  0.3026,  0.3265],\n",
       "                      [-0.3419,  0.2277,  0.2887, -0.2690,  0.1835,  0.1505,  0.1852, -0.1217],\n",
       "                      [-0.1841, -0.0022, -0.1083,  0.1570, -0.2633,  0.2999, -0.1130,  0.2028],\n",
       "                      [-0.1143, -0.0539,  0.0525, -0.3118,  0.1628,  0.3199, -0.2641,  0.1352],\n",
       "                      [-0.3215, -0.0139, -0.1609, -0.3058,  0.1549,  0.2211,  0.0482,  0.1191],\n",
       "                      [-0.1956,  0.2336, -0.2814, -0.0971, -0.1273, -0.1525,  0.2911,  0.2737],\n",
       "                      [ 0.1817, -0.1362, -0.2178, -0.0979, -0.1380,  0.0394,  0.1784,  0.3316],\n",
       "                      [ 0.2478, -0.2905,  0.3037, -0.3280,  0.0391,  0.0420, -0.0629, -0.1089],\n",
       "                      [-0.1525,  0.2027, -0.2254,  0.0697,  0.1276,  0.2702,  0.0068,  0.3045],\n",
       "                      [-0.3460, -0.1954, -0.3072, -0.0102, -0.2186,  0.2360, -0.1681,  0.0301],\n",
       "                      [ 0.2989, -0.3484,  0.1458, -0.3012,  0.1713, -0.0926, -0.3034,  0.0583],\n",
       "                      [ 0.0258,  0.1230,  0.2120, -0.0365, -0.1640,  0.3455, -0.1092,  0.3025],\n",
       "                      [ 0.2358, -0.3467, -0.1024,  0.0228, -0.2833,  0.0604, -0.1461, -0.1814],\n",
       "                      [ 0.2632,  0.1520,  0.3519, -0.0723, -0.1006, -0.2258,  0.0400,  0.2774],\n",
       "                      [-0.0387, -0.1225,  0.2260,  0.0123,  0.0502,  0.3332,  0.3386,  0.3380],\n",
       "                      [-0.3194,  0.0600,  0.2875,  0.3135, -0.3068,  0.2608, -0.1634, -0.1771],\n",
       "                      [-0.1991, -0.1879, -0.0553, -0.0063, -0.1549,  0.2272, -0.2030,  0.3150],\n",
       "                      [-0.3191,  0.1165, -0.2166, -0.1966,  0.0838, -0.0662, -0.2372, -0.0209],\n",
       "                      [-0.2548, -0.2103,  0.2090,  0.0219, -0.0998,  0.2831,  0.0435,  0.2557]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm_decoder.weight_hh_l0',\n",
       "              tensor([[ 0.1464,  0.0290, -0.1303, -0.1553,  0.3096,  0.0756,  0.3014,  0.2113],\n",
       "                      [-0.0200, -0.3258,  0.1426, -0.0784,  0.0709, -0.1288,  0.2778,  0.3403],\n",
       "                      [-0.2097, -0.0841, -0.2632,  0.1711, -0.2562, -0.2734, -0.2585, -0.2852],\n",
       "                      [ 0.2731, -0.1522,  0.2186, -0.0978, -0.1067, -0.0968, -0.2868,  0.1015],\n",
       "                      [-0.1422,  0.1058, -0.3013,  0.0553,  0.2872, -0.1087,  0.0754, -0.3490],\n",
       "                      [-0.1444,  0.2928,  0.1402,  0.1295,  0.1534, -0.0722, -0.1501,  0.3327],\n",
       "                      [-0.1296, -0.0282, -0.2679,  0.2710, -0.1155, -0.1318, -0.2199,  0.0823],\n",
       "                      [-0.2738,  0.3045,  0.2599, -0.2691, -0.3244,  0.0924, -0.2102, -0.3505],\n",
       "                      [ 0.2220, -0.0889,  0.0732,  0.0378, -0.2207, -0.1734,  0.1229, -0.3122],\n",
       "                      [-0.0486, -0.0311, -0.1960,  0.3494, -0.3133, -0.3031, -0.2556,  0.2005],\n",
       "                      [-0.3010,  0.2146,  0.3432,  0.3318,  0.3295,  0.0574, -0.3091,  0.0866],\n",
       "                      [ 0.1456, -0.0267, -0.3098,  0.2667,  0.0681,  0.2382, -0.0392, -0.3160],\n",
       "                      [ 0.3011, -0.3460, -0.2526,  0.3230, -0.1018,  0.1920,  0.2166, -0.0415],\n",
       "                      [-0.0711,  0.1571, -0.0717,  0.1461, -0.1120, -0.1940, -0.2233, -0.3514],\n",
       "                      [-0.1076, -0.1615,  0.1119,  0.0031, -0.2339, -0.2562, -0.0531,  0.1274],\n",
       "                      [ 0.0208,  0.0412, -0.1899, -0.1589, -0.0487,  0.1473, -0.3244,  0.1503],\n",
       "                      [ 0.1986, -0.3493,  0.1484,  0.0533,  0.1408, -0.1963,  0.2228, -0.2042],\n",
       "                      [-0.1538,  0.1138, -0.0761,  0.2464, -0.0409, -0.2756, -0.2946,  0.0182],\n",
       "                      [-0.2755,  0.3161,  0.3073,  0.2128, -0.2698, -0.0813,  0.2609,  0.0720],\n",
       "                      [ 0.0278, -0.0274, -0.1941, -0.1125,  0.2061, -0.0689, -0.0947,  0.1742],\n",
       "                      [-0.1702, -0.0525,  0.2937,  0.0506,  0.1610, -0.1744,  0.1709, -0.1915],\n",
       "                      [ 0.3461, -0.0979, -0.2581, -0.0764,  0.2604,  0.2774,  0.0250,  0.2459],\n",
       "                      [-0.1180, -0.0349,  0.2600, -0.0038,  0.0746,  0.2103,  0.0273, -0.2060],\n",
       "                      [ 0.0383, -0.0213, -0.0351,  0.3421,  0.3016, -0.3203, -0.1286, -0.0389],\n",
       "                      [ 0.2038, -0.0775, -0.0543, -0.0916, -0.2203, -0.3037, -0.2810,  0.0671],\n",
       "                      [ 0.1648, -0.0227,  0.3255, -0.0614,  0.2634, -0.0593, -0.1966,  0.0347],\n",
       "                      [-0.3525,  0.1325,  0.0749,  0.1648,  0.1844,  0.3036, -0.2319, -0.3331],\n",
       "                      [ 0.0301, -0.1561,  0.0018,  0.3063,  0.0376,  0.0425, -0.2941,  0.0019],\n",
       "                      [-0.2835, -0.0885,  0.2432, -0.0288,  0.1488,  0.1201,  0.2382,  0.1135],\n",
       "                      [-0.3136, -0.0273,  0.0323, -0.1487, -0.2666, -0.2281,  0.1633, -0.1218],\n",
       "                      [-0.0320,  0.1072,  0.2334,  0.1826,  0.1583,  0.3202,  0.0650, -0.1559],\n",
       "                      [ 0.1600, -0.0343,  0.3482, -0.2734, -0.2061,  0.2297, -0.2317,  0.1931]],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm_decoder.bias_ih_l0',\n",
       "              tensor([-0.2334,  0.1082,  0.3041,  0.1414, -0.2105,  0.1414, -0.0031, -0.0730,\n",
       "                      -0.3481, -0.2330, -0.1201,  0.2636, -0.2429, -0.3308, -0.2587,  0.1137,\n",
       "                      -0.3153, -0.3534,  0.0098, -0.3335,  0.0700, -0.0386,  0.3218, -0.1317,\n",
       "                      -0.3267, -0.2064, -0.0181, -0.1417,  0.3460, -0.2762, -0.3398,  0.1542],\n",
       "                     device='cuda:0')),\n",
       "             ('lstm_decoder.bias_hh_l0',\n",
       "              tensor([-0.0851,  0.2198,  0.0592,  0.1217,  0.2538, -0.0435, -0.1493, -0.1273,\n",
       "                      -0.0925, -0.3159,  0.2909,  0.1540, -0.1231,  0.2778,  0.1417,  0.1461,\n",
       "                       0.2072,  0.0560, -0.0278,  0.2662,  0.1130,  0.2367,  0.1982, -0.2358,\n",
       "                      -0.0880,  0.2755, -0.0631, -0.1535, -0.1528, -0.2801,  0.2067,  0.2041],\n",
       "                     device='cuda:0')),\n",
       "             ('post_lstm_gate_encoder.fc.weight',\n",
       "              tensor([[ 0.4464, -0.4348,  0.3413,  0.4441, -0.2812,  0.1520, -0.1927, -0.4704],\n",
       "                      [-0.4383, -0.0866, -0.3603, -0.0656,  0.2884,  0.2429, -0.4943,  0.1946],\n",
       "                      [-0.0035,  0.1715,  0.3197, -0.4168, -0.2591,  0.2143,  0.0830, -0.1414],\n",
       "                      [-0.2521,  0.0740, -0.1351,  0.1462, -0.2209,  0.4860,  0.0627, -0.1334],\n",
       "                      [-0.4126,  0.4868, -0.3748, -0.4357,  0.1959, -0.2579,  0.3648,  0.1000],\n",
       "                      [-0.2928, -0.4428, -0.3309,  0.4821,  0.0137, -0.2921,  0.4248,  0.1749],\n",
       "                      [ 0.3733,  0.3428,  0.3187,  0.2592,  0.2255,  0.2028,  0.2459, -0.1491],\n",
       "                      [-0.1213, -0.2158, -0.2732,  0.4249,  0.2991,  0.3824,  0.1986,  0.3509],\n",
       "                      [ 0.3035, -0.0464, -0.4649,  0.1939, -0.1554, -0.3198,  0.3734,  0.4390],\n",
       "                      [ 0.2996, -0.1621, -0.2221,  0.4228,  0.2980, -0.0869, -0.3820, -0.2223],\n",
       "                      [-0.1974, -0.3011, -0.4258, -0.1134,  0.3963, -0.0835,  0.2071,  0.0082],\n",
       "                      [-0.4322,  0.3994,  0.4277, -0.1073,  0.1780,  0.2027, -0.3183,  0.0952],\n",
       "                      [-0.2853,  0.2474, -0.3946,  0.0193, -0.1652, -0.4283,  0.0473, -0.1303],\n",
       "                      [-0.0346,  0.0282,  0.4025, -0.3533,  0.2165, -0.2889,  0.2278,  0.1793],\n",
       "                      [ 0.4112, -0.2154,  0.0501, -0.1133, -0.4034, -0.3970,  0.4721,  0.0162],\n",
       "                      [ 0.2946, -0.4526,  0.3984,  0.2824,  0.2568,  0.3264, -0.3305,  0.0281]],\n",
       "                     device='cuda:0')),\n",
       "             ('post_lstm_gate_encoder.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('post_lstm_gate_decoder.fc.weight',\n",
       "              tensor([[ 0.4464, -0.4348,  0.3413,  0.4441, -0.2812,  0.1520, -0.1927, -0.4704],\n",
       "                      [-0.4383, -0.0866, -0.3603, -0.0656,  0.2884,  0.2429, -0.4943,  0.1946],\n",
       "                      [-0.0035,  0.1715,  0.3197, -0.4168, -0.2591,  0.2143,  0.0830, -0.1414],\n",
       "                      [-0.2521,  0.0740, -0.1351,  0.1462, -0.2209,  0.4860,  0.0627, -0.1334],\n",
       "                      [-0.4126,  0.4868, -0.3748, -0.4357,  0.1959, -0.2579,  0.3648,  0.1000],\n",
       "                      [-0.2928, -0.4428, -0.3309,  0.4821,  0.0137, -0.2921,  0.4248,  0.1749],\n",
       "                      [ 0.3733,  0.3428,  0.3187,  0.2592,  0.2255,  0.2028,  0.2459, -0.1491],\n",
       "                      [-0.1213, -0.2158, -0.2732,  0.4249,  0.2991,  0.3824,  0.1986,  0.3509],\n",
       "                      [ 0.3035, -0.0464, -0.4649,  0.1939, -0.1554, -0.3198,  0.3734,  0.4390],\n",
       "                      [ 0.2996, -0.1621, -0.2221,  0.4228,  0.2980, -0.0869, -0.3820, -0.2223],\n",
       "                      [-0.1974, -0.3011, -0.4258, -0.1134,  0.3963, -0.0835,  0.2071,  0.0082],\n",
       "                      [-0.4322,  0.3994,  0.4277, -0.1073,  0.1780,  0.2027, -0.3183,  0.0952],\n",
       "                      [-0.2853,  0.2474, -0.3946,  0.0193, -0.1652, -0.4283,  0.0473, -0.1303],\n",
       "                      [-0.0346,  0.0282,  0.4025, -0.3533,  0.2165, -0.2889,  0.2278,  0.1793],\n",
       "                      [ 0.4112, -0.2154,  0.0501, -0.1133, -0.4034, -0.3970,  0.4721,  0.0162],\n",
       "                      [ 0.2946, -0.4526,  0.3984,  0.2824,  0.2568,  0.3264, -0.3305,  0.0281]],\n",
       "                     device='cuda:0')),\n",
       "             ('post_lstm_gate_decoder.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('post_lstm_add_norm_encoder.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('post_lstm_add_norm_encoder.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('post_lstm_add_norm_decoder.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('post_lstm_add_norm_decoder.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_enrichment.fc1.weight',\n",
       "              tensor([[ 0.3294,  0.2909,  0.5756,  0.3205,  0.3005,  0.3853, -0.6725, -0.0748],\n",
       "                      [ 0.6872, -0.1568, -0.5394,  0.1163,  0.7797,  0.1038, -0.2241,  0.0843],\n",
       "                      [ 0.0438, -0.3686,  0.1850, -0.5149,  0.0070, -0.1042, -0.5587,  0.0344],\n",
       "                      [ 0.5825,  0.6340,  0.6893, -0.0860, -0.6583,  0.1926,  0.8742,  0.1757],\n",
       "                      [-0.3367,  0.2369,  0.1219, -0.4931,  0.1244, -0.5557,  0.6795,  0.9741],\n",
       "                      [ 0.6846,  0.1626,  0.9982, -0.4785, -0.2100, -0.0563, -0.2423,  1.3992],\n",
       "                      [ 0.0373, -0.0199,  0.5696, -0.8105,  0.5082,  0.3883,  0.0396, -0.8577],\n",
       "                      [ 0.0106,  0.6429, -0.7195,  1.0300,  0.3438,  0.4008,  0.8303,  0.2993]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_enrichment.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_enrichment.context.weight',\n",
       "              tensor([[-0.0422, -0.5034,  0.5831,  0.0262,  0.5959, -0.2176,  0.4498,  0.1818],\n",
       "                      [-0.5549,  0.4268,  0.3947, -0.4557,  0.5035, -0.1255, -0.2481, -0.1844],\n",
       "                      [-0.4267,  0.5183, -0.2052, -0.3607,  0.5902, -0.6063, -0.4578,  0.1930],\n",
       "                      [ 0.5556, -0.3036, -0.3076, -0.3256,  0.3965, -0.0276, -0.4680, -0.2701],\n",
       "                      [-0.4945,  0.2384, -0.3052,  0.0438,  0.4167,  0.4320, -0.5993,  0.2966],\n",
       "                      [ 0.5438,  0.4832,  0.2203, -0.0297, -0.3573, -0.3113, -0.3466, -0.1757],\n",
       "                      [ 0.3386,  0.5928,  0.3544, -0.1631,  0.0603, -0.2337, -0.2004, -0.1270],\n",
       "                      [-0.0271,  0.0437,  0.2818,  0.2115,  0.4192,  0.0812, -0.4903,  0.0372]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_enrichment.fc2.weight',\n",
       "              tensor([[-0.3414, -0.0495,  0.3407, -0.1566,  0.1907,  0.0087, -0.0946,  0.4419],\n",
       "                      [-0.7021, -0.1617,  0.5035, -0.8982,  0.2352,  0.8140, -0.3142,  0.6262],\n",
       "                      [ 0.8043,  0.3345, -0.9212, -0.1884,  0.2492,  0.9915, -0.7594, -0.4296],\n",
       "                      [-0.3439, -0.7728, -1.0542,  0.2933,  0.6632, -0.3568, -0.0261,  0.2275],\n",
       "                      [ 0.0594,  0.3563, -0.4631,  0.0337, -0.3561,  0.3033,  0.0392, -1.0407],\n",
       "                      [-0.5841, -0.0910, -0.6710, -0.6919,  0.5744,  0.4273, -0.7424, -0.4662],\n",
       "                      [-0.0599,  0.2589, -0.5051, -0.4303,  0.4434, -0.8057,  0.3794, -0.4155],\n",
       "                      [ 0.5709, -0.5989,  0.5945, -0.3769,  0.6691, -1.1813,  0.3671, -0.2254]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_enrichment.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('static_enrichment.gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.2095, -0.0710,  0.3013, -0.4303,  0.2858,  0.0453,  0.2348, -0.3789],\n",
       "                      [-0.0471,  0.4026, -0.2239,  0.0427,  0.0482, -0.2809,  0.4790, -0.4843],\n",
       "                      [ 0.0554, -0.0974,  0.4462,  0.2966, -0.4052, -0.0559,  0.4510,  0.0460],\n",
       "                      [ 0.2454, -0.4075, -0.1351, -0.4899, -0.3603, -0.3565, -0.0842,  0.0652],\n",
       "                      [-0.4881, -0.1751, -0.0013,  0.4979, -0.1425, -0.3281,  0.0863,  0.0435],\n",
       "                      [ 0.0044, -0.1079, -0.0293,  0.3871, -0.3919,  0.2068, -0.2155,  0.1451],\n",
       "                      [-0.2624, -0.3907,  0.2104,  0.1400,  0.2450, -0.1814,  0.0972,  0.3587],\n",
       "                      [ 0.3760,  0.3238, -0.1023, -0.2578,  0.0422, -0.3353, -0.1463,  0.0636],\n",
       "                      [ 0.1775, -0.0520,  0.1910, -0.4275,  0.1900, -0.3269, -0.4089,  0.0518],\n",
       "                      [ 0.4406,  0.0727,  0.1780, -0.0669,  0.0268,  0.0540, -0.2215,  0.4052],\n",
       "                      [-0.3120,  0.2579,  0.3367, -0.2624,  0.4311,  0.2018,  0.4355,  0.1998],\n",
       "                      [-0.2939,  0.3066,  0.4040,  0.3065,  0.1796,  0.0841,  0.0346,  0.4919],\n",
       "                      [-0.2437,  0.1125, -0.0122,  0.4510,  0.2851, -0.3094,  0.2276, -0.1625],\n",
       "                      [ 0.3483, -0.4214, -0.4513,  0.2227, -0.1392,  0.1290,  0.4140, -0.3471],\n",
       "                      [-0.0630, -0.1769,  0.2706, -0.1894,  0.4221,  0.0166,  0.1446, -0.2475],\n",
       "                      [-0.0197, -0.4481, -0.2240, -0.1430, -0.4194, -0.0081,  0.2552, -0.2958]],\n",
       "                     device='cuda:0')),\n",
       "             ('static_enrichment.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('static_enrichment.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('static_enrichment.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('multihead_attn.v_layer.weight',\n",
       "              tensor([[-0.5496, -0.0880, -0.2891,  0.4654, -0.2205, -0.1408,  0.5268, -0.5350],\n",
       "                      [-0.2046,  0.5261,  0.4303, -0.1744, -0.1152, -0.2918,  0.1212,  0.1795],\n",
       "                      [ 0.4137,  0.2688,  0.3089, -0.0975, -0.4377,  0.3381, -0.0106, -0.4007],\n",
       "                      [ 0.0548,  0.6059, -0.0516, -0.5115,  0.3698,  0.4554, -0.3913, -0.5356],\n",
       "                      [-0.4382,  0.2518, -0.2513, -0.6015, -0.0439, -0.3111, -0.1813, -0.2417],\n",
       "                      [-0.2055, -0.3987, -0.1243, -0.3859, -0.0809, -0.3815,  0.0402,  0.4342],\n",
       "                      [-0.2493, -0.0805, -0.1041, -0.2027, -0.4242,  0.1551, -0.0520,  0.0315],\n",
       "                      [-0.1574, -0.3899, -0.2234,  0.3149,  0.4239, -0.1955,  0.3210, -0.3512]],\n",
       "                     device='cuda:0')),\n",
       "             ('multihead_attn.v_layer.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('multihead_attn.q_layers.0.weight',\n",
       "              tensor([[-0.0347, -0.5528, -0.0856,  0.1785,  0.3733,  0.2143,  0.2889, -0.1314],\n",
       "                      [ 0.6023, -0.5080, -0.1380, -0.0961,  0.4115,  0.1194,  0.5980, -0.4131],\n",
       "                      [ 0.2035, -0.5149,  0.1942, -0.2809, -0.2686,  0.0673,  0.0609,  0.6036],\n",
       "                      [ 0.4909,  0.0316,  0.2090,  0.1260, -0.1314, -0.4427, -0.4919,  0.0591],\n",
       "                      [-0.2383,  0.5602, -0.2686,  0.1665, -0.2958,  0.6099,  0.2628,  0.3363],\n",
       "                      [ 0.1662, -0.0887, -0.2091, -0.2736, -0.5269, -0.1026, -0.2466,  0.5565],\n",
       "                      [ 0.5837, -0.4036,  0.0453, -0.4942,  0.3000,  0.4627, -0.3479, -0.4326],\n",
       "                      [-0.1096,  0.4950,  0.4321, -0.3201,  0.0289, -0.4677,  0.5726,  0.2675]],\n",
       "                     device='cuda:0')),\n",
       "             ('multihead_attn.q_layers.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('multihead_attn.k_layers.0.weight',\n",
       "              tensor([[-0.2475,  0.2791,  0.0442, -0.3643, -0.5919,  0.3759, -0.4576,  0.4048],\n",
       "                      [-0.1829,  0.3502,  0.2526,  0.3809, -0.2722,  0.3018,  0.1450,  0.0106],\n",
       "                      [-0.0047,  0.0100,  0.3569,  0.3643, -0.2263, -0.0131, -0.1373, -0.2205],\n",
       "                      [ 0.2692,  0.5660,  0.3094, -0.1538,  0.3664,  0.5932,  0.1608,  0.5403],\n",
       "                      [ 0.1977, -0.1226,  0.2050,  0.1473,  0.1799, -0.1500, -0.4485, -0.5665],\n",
       "                      [-0.3947,  0.3701, -0.1461, -0.4964,  0.4660, -0.5625,  0.1096,  0.5282],\n",
       "                      [-0.3046, -0.0110,  0.6080,  0.5238,  0.4390, -0.1100,  0.3617,  0.2461],\n",
       "                      [ 0.0333,  0.5651,  0.1740,  0.3829, -0.4635,  0.1844, -0.5641,  0.1023]],\n",
       "                     device='cuda:0')),\n",
       "             ('multihead_attn.k_layers.0.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('multihead_attn.w_h.weight',\n",
       "              tensor([[ 0.1646,  0.3632,  0.3257, -0.2729,  0.3641, -0.6111,  0.5095,  0.2942],\n",
       "                      [-0.0940,  0.1799,  0.3375, -0.4911,  0.3974,  0.1828,  0.5960,  0.0270],\n",
       "                      [ 0.0611,  0.1408,  0.4953, -0.5101,  0.3386,  0.3524, -0.0494, -0.4163],\n",
       "                      [ 0.4728,  0.3726, -0.1419,  0.1064, -0.1875, -0.2760,  0.6083,  0.2465],\n",
       "                      [ 0.0390,  0.3893,  0.4098,  0.3276,  0.2726, -0.4580, -0.2453,  0.5090],\n",
       "                      [ 0.1863,  0.1682, -0.4015, -0.2928, -0.2299,  0.2916, -0.2461,  0.4681],\n",
       "                      [-0.4345, -0.1052,  0.5199, -0.2570,  0.0110, -0.1799,  0.2161, -0.3090],\n",
       "                      [-0.4627, -0.2305,  0.2470, -0.1588, -0.4696, -0.1278, -0.2672,  0.5091]],\n",
       "                     device='cuda:0')),\n",
       "             ('post_attn_gate_norm.glu.fc.weight',\n",
       "              tensor([[ 0.4501, -0.1938,  0.4013, -0.0573,  0.4847, -0.4995, -0.2878, -0.1062],\n",
       "                      [-0.4936, -0.0454, -0.3970,  0.3125,  0.4247, -0.0341,  0.2921,  0.2476],\n",
       "                      [ 0.1990,  0.0627, -0.3269, -0.4442,  0.2002, -0.3387,  0.3853,  0.1037],\n",
       "                      [-0.2531, -0.2105,  0.1220, -0.0188,  0.4378, -0.1901, -0.2947, -0.4569],\n",
       "                      [ 0.0935, -0.3727, -0.0507,  0.4915, -0.2203,  0.4425,  0.3043, -0.3065],\n",
       "                      [ 0.2648, -0.1978,  0.2696, -0.2921,  0.1321,  0.2812,  0.3673, -0.1860],\n",
       "                      [ 0.2943,  0.3578, -0.1260,  0.3492, -0.1062, -0.2848,  0.1752,  0.1402],\n",
       "                      [-0.4542, -0.2064, -0.1240,  0.3289, -0.0340, -0.4764,  0.0793,  0.1326],\n",
       "                      [ 0.0822,  0.4038, -0.4912,  0.0526, -0.2743, -0.2236, -0.3208, -0.1175],\n",
       "                      [-0.4688, -0.4643,  0.3372,  0.3065, -0.1874, -0.1634, -0.1780,  0.1235],\n",
       "                      [-0.1986,  0.2062, -0.0013,  0.1272, -0.2511, -0.2471,  0.2145,  0.3814],\n",
       "                      [-0.2711,  0.2608, -0.0360,  0.4930, -0.2147,  0.4247,  0.2055,  0.3859],\n",
       "                      [-0.0028,  0.3389,  0.0052,  0.0075, -0.0882,  0.1431,  0.4820,  0.4004],\n",
       "                      [-0.2749, -0.2084,  0.2721, -0.1902, -0.1600,  0.1066, -0.2863, -0.3619],\n",
       "                      [ 0.4019, -0.4524, -0.3017,  0.2258, -0.0726,  0.2508, -0.0683,  0.0009],\n",
       "                      [-0.0966,  0.1414,  0.1391, -0.0670,  0.3382, -0.3096, -0.1253,  0.0380]],\n",
       "                     device='cuda:0')),\n",
       "             ('post_attn_gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('post_attn_gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('post_attn_gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('pos_wise_ff.fc1.weight',\n",
       "              tensor([[ 8.5885e-01, -3.1150e-01,  5.6349e-01, -6.2756e-01,  9.1620e-02,\n",
       "                        4.1955e-01, -3.4200e-01, -4.0222e-01],\n",
       "                      [-3.9161e-01,  4.2078e-01, -2.1108e-01,  8.7780e-01, -6.8484e-01,\n",
       "                       -1.5440e-01,  7.5455e-01,  1.0320e-01],\n",
       "                      [ 4.2669e-02, -8.2913e-01, -1.5721e-03,  9.4462e-01, -3.0092e-01,\n",
       "                        4.1876e-01, -3.6559e-01,  1.9142e-01],\n",
       "                      [-3.8267e-01,  1.3062e-01, -4.4637e-01,  3.7804e-01,  7.9782e-02,\n",
       "                       -1.4629e-01,  3.2837e-01,  1.0861e+00],\n",
       "                      [ 1.6584e-01,  9.6488e-01,  5.5397e-01,  3.4699e-01, -1.9767e-01,\n",
       "                       -7.4130e-01,  4.7180e-01, -1.7056e+00],\n",
       "                      [-3.5500e-01,  4.3320e-01, -3.4400e-01,  6.0543e-01,  3.4185e-01,\n",
       "                       -3.8143e-01,  3.4301e-01,  2.6672e-01],\n",
       "                      [-1.8768e-01,  4.6356e-01,  2.2794e-02,  4.5434e-01, -7.0016e-01,\n",
       "                        1.6671e-01,  6.2306e-01,  4.5229e-02],\n",
       "                      [ 3.1930e-01,  1.3084e-01, -5.8581e-01,  2.5390e-01, -2.6337e-01,\n",
       "                       -4.4313e-01, -1.6995e-01,  5.8236e-01]], device='cuda:0')),\n",
       "             ('pos_wise_ff.fc1.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('pos_wise_ff.fc2.weight',\n",
       "              tensor([[ 0.3459, -0.1615,  0.0469,  0.5536, -0.0753,  0.2497, -0.4712,  0.5717],\n",
       "                      [-1.0766, -0.3273, -0.3332, -0.3478,  0.4169, -0.1921, -0.5357, -0.9340],\n",
       "                      [ 0.0746,  0.6514, -0.5397, -0.0939, -0.2232,  0.3031, -0.4579,  0.1697],\n",
       "                      [-0.0436,  0.2338, -0.1757, -0.5712, -0.1520, -0.4508, -0.1875, -0.4137],\n",
       "                      [ 0.5374, -0.1425,  0.1878,  0.1471, -0.2640, -0.2539, -0.1581,  0.2267],\n",
       "                      [ 0.6131,  0.2675,  0.0340,  0.3501,  0.2194, -0.0512, -0.6669, -0.0830],\n",
       "                      [-0.2627,  0.1755,  0.0596,  0.1355, -0.4466, -1.1007, -0.4756,  0.2591],\n",
       "                      [-0.4325, -0.2886, -0.3172, -0.2366, -0.8152, -0.4583,  0.5140, -0.6484]],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_wise_ff.fc2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('pos_wise_ff.gate_norm.glu.fc.weight',\n",
       "              tensor([[ 1.4221e-01, -3.8262e-01, -2.6457e-01, -8.3587e-02,  2.6393e-01,\n",
       "                        3.6143e-01,  4.6100e-01,  1.1132e-01],\n",
       "                      [-1.2347e-01, -4.2836e-01,  2.1452e-04,  7.0160e-02, -2.0150e-01,\n",
       "                        2.0404e-01, -3.4503e-01,  7.8859e-02],\n",
       "                      [-4.8993e-03, -3.5919e-01, -4.6153e-01, -4.0133e-01,  4.7694e-01,\n",
       "                       -1.8125e-01,  1.2528e-01, -1.5854e-01],\n",
       "                      [ 9.4306e-02, -4.1711e-01,  2.3183e-01,  4.0199e-01, -2.5124e-02,\n",
       "                        3.1073e-02, -4.1251e-01, -3.0338e-01],\n",
       "                      [-3.9099e-01,  4.5967e-01, -2.4444e-02,  1.6323e-01, -6.2603e-02,\n",
       "                        2.3591e-01,  3.6853e-01, -3.7060e-01],\n",
       "                      [-3.3725e-01, -1.4348e-01,  3.2888e-02, -9.3879e-02,  2.1467e-01,\n",
       "                        2.2722e-01,  1.0663e-01, -4.3033e-01],\n",
       "                      [-3.0832e-01,  2.5846e-01, -1.8727e-01, -3.4282e-01, -1.1118e-01,\n",
       "                        3.8486e-01,  1.2668e-01, -2.0541e-01],\n",
       "                      [ 4.2281e-01, -8.6040e-02,  4.1044e-01,  4.8765e-01, -3.7941e-01,\n",
       "                       -1.0583e-01,  3.8225e-01, -4.7818e-01],\n",
       "                      [ 3.5378e-01,  4.0437e-01,  4.6539e-01, -1.8877e-01,  4.1634e-01,\n",
       "                        1.1826e-01,  4.0981e-01,  2.0233e-01],\n",
       "                      [ 1.5894e-02, -4.8943e-01, -3.0639e-01,  4.1096e-01,  1.9678e-01,\n",
       "                       -1.4820e-01,  4.8293e-01, -3.6722e-01],\n",
       "                      [ 3.4032e-01,  4.8960e-01, -1.8598e-01,  1.3939e-01,  3.1341e-01,\n",
       "                       -1.1850e-01,  1.0888e-01,  2.4529e-01],\n",
       "                      [-1.4324e-01, -2.8392e-01,  1.5433e-01, -4.3440e-01, -4.3987e-01,\n",
       "                        7.7746e-03, -2.4467e-01,  1.4413e-01],\n",
       "                      [ 9.9892e-02, -4.0347e-01, -2.8750e-01,  4.8550e-01, -3.5250e-02,\n",
       "                       -6.8464e-02, -2.2579e-01,  1.8675e-01],\n",
       "                      [ 1.8884e-01,  1.9419e-01, -1.8148e-01,  2.5223e-01,  3.2253e-01,\n",
       "                        4.6731e-01, -4.7633e-01,  1.8303e-01],\n",
       "                      [-1.7966e-01, -1.4173e-01, -3.6594e-01,  1.4203e-01, -3.9966e-01,\n",
       "                       -2.9355e-01, -2.1753e-02,  1.8305e-01],\n",
       "                      [ 2.2095e-01,  3.1499e-01, -4.9335e-01, -2.3969e-01,  8.4125e-02,\n",
       "                       -3.5731e-01, -2.7131e-01, -2.0323e-01]], device='cuda:0')),\n",
       "             ('pos_wise_ff.gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('pos_wise_ff.gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('pos_wise_ff.gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('pre_output_gate_norm.glu.fc.weight',\n",
       "              tensor([[-0.3544, -0.4269,  0.0831,  0.1556, -0.1141,  0.3287,  0.4801, -0.0574],\n",
       "                      [ 0.1691, -0.4682, -0.0589, -0.3932,  0.4091,  0.1556,  0.2627, -0.1964],\n",
       "                      [ 0.2173,  0.1866, -0.2254, -0.0907,  0.2777,  0.1231, -0.0202, -0.0090],\n",
       "                      [-0.3451, -0.0711,  0.0512,  0.2052, -0.1824,  0.1809,  0.0765,  0.4565],\n",
       "                      [ 0.1943, -0.4936, -0.1220, -0.0349, -0.2190, -0.1797,  0.0227, -0.0116],\n",
       "                      [-0.1312, -0.2056, -0.2247,  0.1687,  0.1608,  0.0911,  0.3581,  0.0424],\n",
       "                      [ 0.4640, -0.1033,  0.0048, -0.2602, -0.3963, -0.2154,  0.1188,  0.0375],\n",
       "                      [ 0.2061,  0.1600, -0.4868,  0.4152, -0.1372, -0.3869,  0.1950,  0.1311],\n",
       "                      [-0.2824,  0.0066,  0.4210,  0.1333, -0.1404, -0.1199,  0.1620,  0.4758],\n",
       "                      [-0.1390,  0.4419, -0.2001,  0.3513,  0.0482, -0.2114,  0.4178,  0.3652],\n",
       "                      [-0.0946, -0.4761, -0.2566, -0.0285, -0.4287, -0.3816, -0.0406, -0.1230],\n",
       "                      [ 0.0165, -0.2566, -0.2520,  0.1626,  0.0249,  0.3281, -0.2757, -0.2140],\n",
       "                      [-0.2307, -0.3270,  0.2722, -0.0817,  0.4973,  0.2876, -0.2446, -0.1258],\n",
       "                      [ 0.2178, -0.3548,  0.4359,  0.0808,  0.1434,  0.4303, -0.4306, -0.1763],\n",
       "                      [-0.2234, -0.3274,  0.3263,  0.3275,  0.3790,  0.4774, -0.2453,  0.0036],\n",
       "                      [ 0.1285, -0.1540,  0.2817,  0.4876, -0.4926, -0.1031,  0.2950, -0.3551]],\n",
       "                     device='cuda:0')),\n",
       "             ('pre_output_gate_norm.glu.fc.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                     device='cuda:0')),\n",
       "             ('pre_output_gate_norm.add_norm.norm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1.], device='cuda:0')),\n",
       "             ('pre_output_gate_norm.add_norm.norm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')),\n",
       "             ('output_layer.weight',\n",
       "              tensor([[-6.2968e-02,  2.2739e-01,  8.7327e-02, -1.8762e-01, -8.8999e-02,\n",
       "                       -2.4213e-04,  3.3495e-01, -2.3042e-01],\n",
       "                      [-2.7126e-02, -7.3375e-02,  3.5145e-01,  2.6716e-01, -5.0070e-02,\n",
       "                       -1.5754e-01,  3.4830e-01, -4.1971e-02],\n",
       "                      [-9.7320e-02,  2.8003e-01,  1.0496e-01,  3.8448e-02,  3.1827e-01,\n",
       "                       -1.7754e-01,  2.8078e-01,  1.7674e-01],\n",
       "                      [-2.2609e-01,  3.2322e-01,  1.2251e-01, -2.5677e-01,  3.0282e-01,\n",
       "                       -2.8832e-01,  4.7791e-02,  1.6190e-01],\n",
       "                      [ 1.8828e-01, -3.1137e-01,  3.0963e-01,  3.0955e-01,  2.0706e-01,\n",
       "                        1.2106e-01, -2.2719e-01,  2.6552e-01],\n",
       "                      [ 2.1758e-02, -5.0565e-02, -1.1168e-01,  2.2732e-02, -7.3738e-02,\n",
       "                       -2.6456e-01, -2.3147e-01, -1.2534e-01],\n",
       "                      [-6.4047e-02, -1.8260e-01, -1.0238e-01, -2.7083e-01, -2.5070e-01,\n",
       "                        2.1152e-01, -1.1011e-01, -1.1273e-01]], device='cuda:0')),\n",
       "             ('output_layer.bias',\n",
       "              tensor([ 9.1669e-05,  5.5721e-02, -2.2933e-01,  1.6129e-01,  1.5172e-01,\n",
       "                       1.5720e-01, -2.5720e-01], device='cuda:0'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer[\"state_dict\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba39aad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
